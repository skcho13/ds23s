[
  {
    "objectID": "contents/eda.html",
    "href": "contents/eda.html",
    "title": "Plots",
    "section": "",
    "text": "source: R for Data Science\n\nTransform (데이터 변형)\n\n데이터의 변수들 중 일부를 선택하기\n필요한 부분를 필터링하기\n기존의 변수들로 새로운 변수 만들기\n요약자료를 계산하기\n\nVisualise (시각화)\n\n시각화를 통해 데이터가 품고 있는 정보를 파악하여 데이터에 대한 이해를 높임\n\nModel (모형)\n\n시각화와 데이터 변형의 두 가지를 병행하면서 호기심과 의구심을 갖고 연구자가 자신의 관심사에 답을 구하는 탐색적 분석을 하는 과정\n이 과정에서 모형을 세우고 데이터를 얼마나 잘 설명하는지를 살펴보고, 모형을 수정해 나가는 과정을 거침"
  },
  {
    "objectID": "contents/eda.html#first-steps",
    "href": "contents/eda.html#first-steps",
    "title": "Plots",
    "section": "First steps",
    "text": "First steps\n\n\nLoad packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\n\n\nData: Fuel economy data from 1999 to 2008 for 38 popular models of cars\n\n\n# import the dataset\nmpg_data = sm.datasets.get_rdataset(\"mpg\", \"ggplot2\")\nmpg = mpg_data.data\n\n\n# Description\nprint(mpg_data.__doc__)\n\n\nmpg\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns\n\n\n\nQ: 엔진의 크기(displ)와 연비(hwy)는 어떤 관계에 있는가?\n\n# Scatter plot: 산포도\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\") # empty plot을 생성하고, x, y축에 mapping할 mpg 데이터의 변수를 지정\n    .add(so.Dot()) # layer를 추가하여, points들을 Dot이라는 mark object를 써서 표현\n)\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nLayer-specific mappings\n다음과 같이 첫번째 layer 안에서 x, y를 mapping하는 경우, 이후 새로 추가되는 layer에는 그 mapping이 적용되지 않음\n(\n    so.Plot(mpg)\n    .add(so.Dot(), x=\"displ\", y=\"hwy\") # 이 layer에서만 mapping이 유효\n)\n\n\n\n\n\n\n\n\nTip\n\n\n\n다음과 같이 x, y를 생략하거나 간략히 할 수 있으나…\nso.Plot(mpg, \"displ\", \"hwy\").add(so.Dot())\n\n\n\n카테고리 변수인 경우\n\ncyl (실린더 개수), hwy (고속도로 연비)의 관계를 scatterplot으로 살펴볼 수 있는가? (left)\nclass (차량 타입), drv (전륜 구동, 후륜 구동, 4륜 구동 타입)의 관계는 어떠한가? (right)"
  },
  {
    "objectID": "contents/eda.html#aesthetic-mappings",
    "href": "contents/eda.html#aesthetic-mappings",
    "title": "Plots",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\nQ: 엔진의 크기와 연비와의 관계에서 보이는 트렌드 라인에서 심하게 벗어난 것이 있는가?\n\n\n\n\n\n 변수들을 x, y라는 position에 mapping하는 것에 추가하여 다음과 같은 속성(aesthetic)에 mapping할 수 있음\n색(color), 크기(pointsize), 모양(marker), 선 종류(linestyle), 투명도(alpha)\n\n\nColor\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nPointsize\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", pointsize=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nMarker\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", marker=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nAlpha\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", alpha=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nLinestyle\n\nhealthexp = sns.load_dataset(\"healthexp\")\n\np = so.Plot(healthexp, x=\"Spending_USD\", y=\"Life_Expectancy\", linestyle=\"Country\")\np.add(so.Line())\n\n\n\n\n\n\n두 가지 이상의 속성\nex. color & marker\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\", marker=\"drv\")\n    .add(so.Dot())\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\", pointsize=\"drv\")\n    .add(so.Dot())\n    .scale(pointsize=(5, 15)) # pointsize의 range설정\n)\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n어떤 속성을 어떤 변수에 할당하는 것이 적절한지를 선택하는 것이 기술\n예를 들어, 아래 두 플랏은 동일한 정보를 품고 있으나, 시각적 인식에 큰 차이를 만듦\n\n\n\n\n\n\n\n\n\n\n\n\n연속 vs. 카테고리 변수 여부에 따라 다르게 작동\n\nleft = so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\").add(so.Dot()).layout(engine=\"constrained\")\n\nright = so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"cty\").add(so.Dot()).layout(engine=\"constrained\")\n\n\n\n\n\n\n\n\n(a) type of car\n\n\n\n\n\n\n\n(b) city miles per gallon\n\n\n\n\nFigure 1: Categorical vs. Continuous\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"cty\")\n    .add(so.Dot())\n    .scale(color=so.Continuous(\"crest\", norm=(0, 50), trans=\"sqrt\"))\n)"
  },
  {
    "objectID": "contents/eda.html#setting-properties",
    "href": "contents/eda.html#setting-properties",
    "title": "Plots",
    "section": "Setting properties",
    "text": "Setting properties\nSetting properties vs. mapping properties (aesthetic)\n\n변수에 속성을 할당하는 것이 아니라, graphical objects (Marks)의 속성을 지정\nMarks (.Dot, .Line, .Bar, …) 마다 설정할 수 있는 속성이 다름\n주로 쓰이는 속성들: color, pointsize, alpha\n\n.Dot()의 경우\nclass seaborn.objects.Dot(artist_kws=, marker=<‘o’>, pointsize=<6>, stroke=<0.75>, color=<‘C0’>, alpha=<1>, fill=, edgecolor=, edgealpha=, edgewidth=<0.5>, edgestyle=<‘-’>)\n.Dots()의 경우\nclass seaborn.objects.Dots(artist_kws=, marker=<rc:scatter.marker>, pointsize=<4>, stroke=<0.75>, color=<‘C0’>, alpha=<1>, fill=, fillcolor=, fillalpha=<0.2>)\nseaborn reference\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\"deepskyblue\")) # Mark object 안에 지정!\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\"deepskyblue\", pointsize=12, edgecolor=\"white\", edgewidth=1)) # Mark object 안에 지정!\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\"orange\", pointsize=12, marker=\">\", alpha=.4)) # Mark object 안에 지정!\n)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n다양한 Mark properties에 대해서는 홈페이지 참고\nProperties of Mark objects"
  },
  {
    "objectID": "contents/eda.html#faceting",
    "href": "contents/eda.html#faceting",
    "title": "Plots",
    "section": "Faceting",
    "text": "Faceting\n카테고리 변수들이 지니는 카테고리들(레벨)로 나누어 그리기\nData: palmerpenguins\n\n\n\n Artwork by @allison_horst\n\n\n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\") # load a dataset: penguins\npenguins.head()\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      Male\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      Female\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      Female\n    \n    \n      3\n      Adelie\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      Adelie\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      Female\n    \n  \n\n\n\n\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .facet(\"sex\") # 기본적으로 columns으로 나누어져 그림\n    .add(so.Dot(alpha=.5))\n)\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .facet(col=\"species\", row=\"sex\")\n    .add(so.Dot(alpha=.5))\n)\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFacet과 Color 중 어떤 방식으로 표현하는 것이 유리한가? 밸런스를 잘 선택!\n\n\n\nleft = (\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .facet(col=\"species\")\n    .add(so.Dot(alpha=.5))\n)\nright = (\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\", color=\"species\")\n    .add(so.Dot(alpha=.5))\n)\n\n\n\n\n\n\n\n\n(a) faceting\n\n\n\n\n\n\n\n(b) color mapping\n\n\n\n\nFigure 2: faceting vs. color mapping\n\n\n\nPairing\nFaceting이 변수 내에 다른 레벨에 따라 그려지는데 반해,\nparing은 x, y축에 다른 변수를 지정하여 그림\n\n(\n    so.Plot(penguins, y=\"body_mass_g\", color=\"species\") # y축은 공유\n    .pair(x=[\"bill_length_mm\", \"bill_depth_mm\"]) # x축에 다른 변수를 mapping\n    .add(so.Dots()) # .Dots()! overploting에 유리. .Dot(alpha=.)로도 비슷\n)\n\n\n\n\nFacet & pair 동시\n\n(\n    so.Plot(penguins, y=\"body_mass_g\", color=\"sex\")\n    .pair(x=[\"bill_length_mm\", \"bill_depth_mm\"])\n    .facet(row=\"species\")\n    .add(so.Dots())\n)\n\n\n\n\n\n\nMultiple plots\n개발 중…? Matplotlib을 이용\n\nimport matplotlib as mpl\n\nf = mpl.figure.Figure(figsize=(8, 4))\nsf1, sf2 = f.subfigures(1, 2)\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .add(so.Dots())\n    .on(sf1)\n    .plot()\n)\n(\n    so.Plot(penguins, x=\"bill_length_mm\", y=\"flipper_length_mm\")\n    .facet(row=\"sex\")\n    .add(so.Dots())\n    .on(sf2)\n    .plot()\n)\n\n\n\n\nSave plots\np.save(\"data/filename.png\") # p: a plot oject"
  },
  {
    "objectID": "contents/eda.html#geometric-objects",
    "href": "contents/eda.html#geometric-objects",
    "title": "Plots",
    "section": "Geometric objects",
    "text": "Geometric objects\n\nDot marks: Dot, Dots\nLine marks: Line, Lines, Path, Paths, Dash, Range\nBar marks: Bar, Bars\nFill marks: Area, Band\nText marks: Text"
  },
  {
    "objectID": "contents/eda.html#layer-specific-mappings",
    "href": "contents/eda.html#layer-specific-mappings",
    "title": "Exploratory data analysis",
    "section": "Layer-specific mappings",
    "text": "Layer-specific mappings\n\npenguins = sns.load_dataset(\"penguins\")\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"species\", color=\"island\")\n    .facet(col=\"sex\")\n    .add(so.Dot(), so.Jitter(.5))\n    .share(x=False)\n    .limit(y=(2.5, -.5))\n    .label(\n        x=\"Body mass (g)\", y=\"\",\n        color=str.capitalize,\n        title=\"{} penguins\".format,\n    )\n)\n\n\n\n\n\nhealthexp = sns.load_dataset(\"healthexp\")\n\n(\n    so.Plot(healthexp, x=\"Year\", y=\"Spending_USD\", color=\"Country\")\n    .add(so.Lines())\n)\n\n\n\n\n\n(\n    so.Plot(healthexp, x=\"Year\", y=\"Spending_USD\", color=\"Country\")\n    .add(so.Lines(), so.Norm(where=\"x == x.min()\", percent=True))\n    .label(y=\"Percent change in spending from 1970 baseline\")\n)\n\n\n\n\n\nhealthexp.tail(6).sort_values(\"Spending_USD\")\n\n\n\n\n\n  \n    \n      \n      Year\n      Country\n      Spending_USD\n      Life_Expectancy\n    \n  \n  \n    \n      272\n      2020\n      Japan\n      4665.641\n      84.7\n    \n    \n      271\n      2020\n      Great Britain\n      5018.700\n      80.4\n    \n    \n      270\n      2020\n      France\n      5468.418\n      82.3\n    \n    \n      268\n      2020\n      Canada\n      5828.324\n      81.7\n    \n    \n      269\n      2020\n      Germany\n      6938.983\n      81.1\n    \n    \n      273\n      2020\n      USA\n      11859.179\n      77.0"
  },
  {
    "objectID": "contents/resources.html",
    "href": "contents/resources.html",
    "title": "NumPy and pandas",
    "section": "",
    "text": "refer to here\nfigure reference"
  },
  {
    "objectID": "contents/resources.html#cross-reference",
    "href": "contents/resources.html#cross-reference",
    "title": "NumPy and pandas",
    "section": "Cross-reference",
    "text": "Cross-reference\ncrossref is Table 1 and Table 2"
  },
  {
    "objectID": "contents/customizing.html",
    "href": "contents/customizing.html",
    "title": "Customizing",
    "section": "",
    "text": "Load packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\n\n\n\nCustomizing\nCustomizing limits, labels, and titles Plot has a number of methods for simple customization, including Plot.label(), Plot.limit(), and Plot.share():\n\ndiamonds = sns.load_dataset(\"diamonds\")\n\n(\n    so.Plot(diamonds, x=\"carat\", y=\"price\", color=\"carat\", marker=\"cut\")\n    .add(so.Dots())\n    .scale(\n        color=so.Continuous(\"crest\", norm=(0, 3), trans=\"sqrt\"),\n    )\n)\n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\")\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"species\", color=\"island\")\n    .facet(col=\"sex\")\n    .add(so.Dot(), so.Jitter(.5))\n    .share(x=False)\n    .limit(y=(2.5, -.5))\n    .label(\n        x=\"Body mass (g)\", y=\"\",\n        color=str.capitalize,\n        title=\"{} penguins\".format,\n    )\n)"
  },
  {
    "objectID": "contents/inspection.html",
    "href": "contents/inspection.html",
    "title": "Inspecting data",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm"
  },
  {
    "objectID": "contents/seaborn.html",
    "href": "contents/seaborn.html",
    "title": "The seaborn.objects interface",
    "section": "",
    "text": "The seaborn.objects interface\nThe grammer of graphics의 데이터 시각화 이론을 잘 반영하고 있으며 아직 발전 중\n기존 seaborn modules을 완전히 대체하지는 못하므로 필요시 병행하여 사용\n\nv0.12.0 (September 2022)\nIntroduction of the objects interface\nThis release debuts the seaborn.objects interface, an entirely new approach to making plots with seaborn. It is the product of several years of design and 16 months of implementation work. The interface aims to provide a more declarative, composable, and extensible API for making statistical graphics. It is inspired by Wilkinson’s grammar of graphics, offering a Pythonic API that is informed by the design of libraries such as ggplot2 and vega-lite along with lessons from the past 10 years of seaborn’s development.\n\n\n\n\n\n\n\nCaution\n\n\n\nThe objects interface is currently experimental and incomplete. It is stable enough for serious use, but there certainly are some rough edges and missing features.\n\n\n\nThe seaborn.objects interface tutorial\nAPI reference"
  },
  {
    "objectID": "contents/setup.html",
    "href": "contents/setup.html",
    "title": "환경설정",
    "section": "",
    "text": "Conda Cheatsheet: 기본적인 conda 명령어 요약\n\n\nAnaconda보다는 기본 패키지들이 미리 설치되지 않는 miniconda를 추천: miniconda install page\n\nWindows 경우: 설치시 물어보는 “add Miniconda to your PATH variable” 옵션을 켜고 설치할 것\n\nShell 사용에 대해서는 아래 3. Command Line Tool 참고\n\n# Terminal (Mac) or Miniconda Powershell Prompt (Windows)\n\n#> conda info # 콘다 정보 \n#> conda update conda # 콘다 업데이트\n\n\n\n\nconda managing channels\n다음을 통해 .condarc 환경파일에 configuration 추가\n\n#> conda config --add channels conda-forge\n#> conda config --set channel_priority strict  # 다른 채널 검색 안함\n\nPython update\n\n#> conda install python=3.10  # python update\n\n\n\n\nuser guide\n환경 생성: miniconda에서 자체 제공하는 가상환경으로 다른 가상환경 툴인 pyenv나 venv 사용하지 않음\n\n#$ conda create --name myenv\n\n# 특정 버전의 파이썬 설치시\n#$ conda create --name myenv python=3.9\n\n환경 확인\n\n#$ conda env list\n\n#> conda environments:\n#>  base         */.../miniconda3\n#>                /.../miniconda3/envs/myenv\n\n환경 제거\n\n#> conda env remove --name myenv\n\n환경 activate/deactivate\n\n#> conda activate myenv\n#> conda deactivate  # activated 환경 내에서\n\n\n\n\n\n# 특정 환경을 activate한 후\n#> conda install <package name1> <package name2> ...\n#> conda install --channel conda-forge <package name> # 특정 conda-forge 채널을 통한 설치\n\n# 제거\n#> conda remove <package name1> <package name2> ...\n\n# update\n#> conda update <package name1> <package name2> ...\n#> conda update --all # all packages\n\n# 패키지 리스트\n#> conda list\n\n\n# pip을  이용한  패키지 설치: conda repository에 없는 패키지들을 설치하는 경우. 충돌의 우려 있음\n#> pip install <package name1> <package name2> ...\n\n\n# 수업에 필요한 기본 패키지 설치\n#> conda install jupyter jupyterlab numpy pandas matplotlib seaborn\n#> conda install -c plotly plotly=5.13.0"
  },
  {
    "objectID": "contents/setup.html#vs-code-설치",
    "href": "contents/setup.html#vs-code-설치",
    "title": "환경설정",
    "section": "VS Code 설치",
    "text": "VS Code 설치\n개인마다 선호하는 text editor가 있으나 본 수업에서는 VS Code로 진행: download and install here"
  },
  {
    "objectID": "contents/setup.html#mac의-경우-기본-bash-shell인-terminal-대신-다음-zsh을-추천",
    "href": "contents/setup.html#mac의-경우-기본-bash-shell인-terminal-대신-다음-zsh을-추천",
    "title": "환경설정",
    "section": "Mac의 경우: 기본 bash shell인 terminal 대신 다음 zsh을 추천",
    "text": "Mac의 경우: 기본 bash shell인 terminal 대신 다음 zsh을 추천\nOh-My-Zsh!: 링크\n\n이 경우 miniconda 설치시 bash의 추가된 conda setup을 zsh로 가져와야 함: minconda를 zsh 설치 후에 설치하는 경우는 miniconda가 추가시키니 신경쓸 필요 없음\n\nhome directory에 있는 .bash_profile 을 열면 # >>> conda initialize >>> 로 시작해서 # <<< conda initialize <<< 부분까지를 복사한 후 .zshrc 파일을 열어 맨 뒤에 붙여넣음\n위 파일을 VS Code에서 쉽게 열어보려면 아래 그림처럼 VS Code에서 Sehll Command: Install 'Code' command in PATH 실행하고 나면\nshell 환경에서 code .zshrc를 실행하면 VS Code에서 편집할 수 있음"
  },
  {
    "objectID": "contents/setup.html#windows의-경우-windows-terminal-추천",
    "href": "contents/setup.html#windows의-경우-windows-terminal-추천",
    "title": "환경설정",
    "section": "Windows의 경우: Windows Terminal 추천",
    "text": "Windows의 경우: Windows Terminal 추천\n\n설치 링크는 구글링…\n명령프롬프트(CMD) vs. Powershell\nPowershell에서 conda를 사용하기 위해서는 몇 가지 설정 필요: 블로그 링크"
  },
  {
    "objectID": "contents/setup.html#extensions",
    "href": "contents/setup.html#extensions",
    "title": "환경설정",
    "section": "Extensions",
    "text": "Extensions\n\nPython\nDocs View\nPython Environment Manager"
  },
  {
    "objectID": "contents/setup.html#preferences",
    "href": "contents/setup.html#preferences",
    "title": "환경설정",
    "section": "Preferences",
    "text": "Preferences\n\nthemes\nfont, font size (notebook, results)\n\nundo: cell 안과 밖\nvariables viewer, data viewer"
  },
  {
    "objectID": "contents/temp.html",
    "href": "contents/temp.html",
    "title": "Temp",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\n# import statsmodels.api as sm\n\n\ntips = sns.load_dataset(\"tips\")\npenguins = sns.load_dataset(\"penguins\")\n\ndf1 = penguins.describe(include=\"object\")\ndf2 = tips.describe(include=\"category\")\n\ndf1\ndf2\n\n\n\n\n\n\nTable 1:  Planets1 \n  \n    \n      \n      sex\n      smoker\n      day\n      time\n    \n  \n  \n    \n      count\n      244\n      244\n      244\n      244\n    \n    \n      unique\n      2\n      2\n      4\n      2\n    \n    \n      top\n      Male\n      No\n      Sat\n      Dinner\n    \n    \n      freq\n      157\n      151\n      87\n      176\n    \n  \n\n\n\n\n\n\n\nimport plotly.express as px\nimport plotly.io as pio\n#pio.renderers.default = \"plotly_mimetype+notebook\"\n\ngapminder = px.data.gapminder()\ngapminder2007 = gapminder.query(\"year == 2007\")\nfig = px.scatter(gapminder2007, \n                 x=\"gdpPercap\", y=\"lifeExp\", color=\"continent\", \n                 size=\"pop\", size_max=60,\n                 hover_name=\"country\")\nfig.show(renderer=\"notebook\")\n\n\n                                                \n\n\n\ngapminder2007\n\n\n\n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n      iso_alpha\n      iso_num\n    \n  \n  \n    \n      11\n      Afghanistan\n      Asia\n      2007\n      43.828\n      31889923\n      974.580338\n      AFG\n      4\n    \n    \n      23\n      Albania\n      Europe\n      2007\n      76.423\n      3600523\n      5937.029526\n      ALB\n      8\n    \n    \n      35\n      Algeria\n      Africa\n      2007\n      72.301\n      33333216\n      6223.367465\n      DZA\n      12\n    \n    \n      47\n      Angola\n      Africa\n      2007\n      42.731\n      12420476\n      4797.231267\n      AGO\n      24\n    \n    \n      59\n      Argentina\n      Americas\n      2007\n      75.320\n      40301927\n      12779.379640\n      ARG\n      32\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1655\n      Vietnam\n      Asia\n      2007\n      74.249\n      85262356\n      2441.576404\n      VNM\n      704\n    \n    \n      1667\n      West Bank and Gaza\n      Asia\n      2007\n      73.422\n      4018332\n      3025.349798\n      PSE\n      275\n    \n    \n      1679\n      Yemen, Rep.\n      Asia\n      2007\n      62.698\n      22211743\n      2280.769906\n      YEM\n      887\n    \n    \n      1691\n      Zambia\n      Africa\n      2007\n      42.384\n      11746035\n      1271.211593\n      ZMB\n      894\n    \n    \n      1703\n      Zimbabwe\n      Africa\n      2007\n      43.487\n      12311143\n      469.709298\n      ZWE\n      716\n    \n  \n\n142 rows × 8 columns\n\n\n\n\nimport plotly.express as px\nimport plotly.io as pio\ngapminder = px.data.gapminder()\ndef gapminder_plot(year):\n    gapminderYear = gapminder.query(\"year == \" + \n                                    str(year))\n    fig = px.scatter(gapminderYear, \n                     x=\"gdpPercap\", y=\"lifeExp\",\n                     size=\"pop\", size_max=60,\n                     hover_name=\"country\")\n    fig.show()\n    \ngapminder_plot(1957)\ngapminder_plot(2007)\n\n\n\n\n\n\n                                                \n(a) Gapminder: 1957\n\n\n\n\n\n                                                \n(b) Gapminder: 2007\n\n\n\nFigure 1: Life Expectancy and GDP\n\n\n\n\nwdi = pd.read_csv(\"data/WDIData.csv\")\n\n\nwdi_small = wdi.iloc[:, :7]\nwdi_small = wdi_small.sample(10000)\nwdi_small[\"Indicator Name\"].value_counts()\n\nDepth of credit information index (0=low to 8=high)                                 16\nAdults (ages 15+) and children (ages 0-14) newly infected with HIV                  16\nNet financial flows, multilateral (NFL, current US$)                                15\nHouseholds and NPISHs final consumption expenditure: linked series (current LCU)    14\nEmployers, female (% of female employment) (modeled ILO estimate)                   14\n                                                                                    ..\nHouseholds and NPISHs Final consumption expenditure (current LCU)                    1\nTariff rate, most favored nation, simple mean, primary products (%)                  1\nCapture fisheries production (metric tons)                                           1\nPrevalence of undernourishment (% of population)                                     1\nNet bilateral aid flows from DAC donors, Norway (current US$)                        1\nName: Indicator Name, Length: 1437, dtype: int64"
  },
  {
    "objectID": "contents/vis.html",
    "href": "contents/vis.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Python의 시각화 라이브러리는 다양하게 개발되어지고 있으며, 각기 특성이 달라 하나로만 쓰기 어려운 상황임\nR의 ggplot2라는 매우 강력한 시각화 도구와 비교하면 이에 상응할 만한 Python 시각화 도구는 찾기 어려움\n\n\n\nMatplotlib\n가장 오래된 Python과 잘 통합된 널리 사용되는 라이브러리\n거의 가능한 모든 플랏을 그릴 수 있음\n한편, 디테일한 부분을 모두 specify해야 함으로써 많은 코딩이 요구되며, interactive 또는 web graphs에 취약함\npandas\nMatplotlib로 구현된 DataFrame의 method로 간략하게 시각화가 가능하며, 빠르게 데이터를 들여다볼 수 있음\nSeaborn & the seaborn.objects interface\nMatplotlib 위에 개발된 간결한 문법의 high-level 언어\nDecalative: 변수들이 어떤 시각화 속성과 위치를 지니는지만 specify\n“Grammer of graphics”라는 시각화 문법에 충실하고자 the seaborn.objects로 새롭게 변화 중\n\n\n\nAltair\n“Grammer of graphics”를 충실히 따라 설계됨\n각 plot이 이미지가 아닌 data + specification으로 이루어짐: 이미지가 저장되지 않고, 브라우저에서 이미지로 complie되어 생성됨\nWeb-based interactive 시각화인 D3에 그 모체를 두며, Vega/Vega-Lite로부터 파생됨\njavascript-based로 interactive 시각화에 용이하나 Python과 연계가 부족한 부분이 있고, 개발이 더딘 듯\nBokeh\nPlotly\n다양한 언어(R, Python, Julia)을 지원하며, 기업 수준의 상용화 제품들도 있으며, 지원군 많음\n\n\nJake VanderPlas의 2017년 발표 자료 중: The Python Visualization Landscape\n\nSource: Jake VanderPlas - The Python Visualization Landscape PyCon 2017"
  },
  {
    "objectID": "contents/vis.html#bertins-semiology-of-graphics-1967",
    "href": "contents/vis.html#bertins-semiology-of-graphics-1967",
    "title": "Data Visualization",
    "section": "Bertin’s Semiology of Graphics (1967)",
    "text": "Bertin’s Semiology of Graphics (1967)"
  },
  {
    "objectID": "contents/vis.html#the-grammer-of-graphics",
    "href": "contents/vis.html#the-grammer-of-graphics",
    "title": "Data Visualization",
    "section": "The Grammer of Graphics",
    "text": "The Grammer of Graphics\na coherent system for describing and building graphs\nFundamentals of Data Visualization by Claus O. Wilke\nAesthetics and types of data\n\n같은 정보를 품고 있으나 더 적절한 representation이 존재…"
  },
  {
    "objectID": "contents/vis.html#탐색적-exploratory-vs.-정보전달-communicative",
    "href": "contents/vis.html#탐색적-exploratory-vs.-정보전달-communicative",
    "title": "Data Visualization",
    "section": "탐색적 (Exploratory) vs. 정보전달 (Communicative)",
    "text": "탐색적 (Exploratory) vs. 정보전달 (Communicative)"
  },
  {
    "objectID": "contents/vis.html#interative-plots",
    "href": "contents/vis.html#interative-plots",
    "title": "Data Visualization",
    "section": "Interative Plots",
    "text": "Interative Plots\nAltair\n\n\n\n\n\n\n\nPlotly"
  },
  {
    "objectID": "contents/pandas.html",
    "href": "contents/pandas.html",
    "title": "NumPy and pandas",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\nNumpy & pandas\nPython 언어는 수치 계산을 위해 디자인되지 않았기 때문에, 데이터 분석에 대한 효율적이고 빠른 계산이 요구되면서 C/C++이라는 언어로 구현된 NumPy (Numerical Python)가 탄생하였고, Python 생태계 안에 통합되었음. 기본적으로 Python 언어 안에 새로운 언어라고 볼 수 있음. 데이터 사이언스에서의 대부분의 계산은 NumPy의 ndarray (n-dimensioal array)와 수학적 operator들을 통해 계산됨.\n데이터 사이언스가 발전함에 따라 단일한 floating-point number들을 성분으로하는 array들의 계산에서 벗어나 칼럼별로 다른 데이터 타입(string, integer, object..)을 포함하는 tabular형태의 데이터를 효율적으로 처리해야 할 필요성이 나타났고, 이를 다룰 수 있는 새로운 언어를 NumPy 위에 개발한 것이 pandas임. 이는 기본적으로 Wes Mckinney에 의해 독자적으로 개발이 시작되었으며, 디자인적으로 불만족스러운 점이 지적되고는 있으나 데이터 사이언스의 기본적인 언어가 되었음.\nNumPy와 pandas에 대한 자세한 내용은 Python for Data Analysis by Wes MacKinney 참고\n특히, NumPy는 Ch.4 & appendices"
  },
  {
    "objectID": "contents/pandas.html#numpy",
    "href": "contents/pandas.html#numpy",
    "title": "NumPy and pandas",
    "section": "NumPy",
    "text": "NumPy\n\n수학적 symbolic 연산에 대한 구현이라고 볼 수 있으며,\n행렬(matrix) 또는 벡터(vector)를 ndarray (n-dimensional array)이라는 이름으로 구현함.\n\n사실상 정수(int)나 실수(float)의 한가지 타입으로 이루어짐.\n\n고차원의 arrays 가능\n\nSource: Medium.com\n\n\n가령, 다음과 같은 행렬 연산이 있다면,\n\\(\\begin{bmatrix}1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix} \\begin{bmatrix}2 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix}0 \\\\ 2 \\\\ 4 \\end{bmatrix}\\)\n\n\nA = np.array([[1, 2],\n              [3, 4],\n              [5, 6]]) # 3x2 matrix\nX = np.array([[2],\n              [-1]]) # 2x1 matrix\n\nA @ X  # A * X : matrix multiplication\n\narray([[0],\n       [2],\n       [4]])\n\n\n\nA.dot(X)\n\narray([[0],\n       [2],\n       [4]])\n\n\nVector vs. Matrix\n\nprint(np.array([0, 2, 4])) # 1-dim matrix: vector\nprint(np.array([0, 2, 4]).reshape(3, 1)) # 3x1 matrix\n\n[0 2 4]\n[[0]\n [2]\n [4]]\n\n\n\narr = np.array([0, 2, 4])\narr.reshape(3, -1).T\n\narray([[0, 2, 4]])\n\n\n\nX2 = np.array([2, -1])\nA @ X2  # same as A.dot(X2)\n\narray([0, 2, 4])\n\n\n\nprint(A.shape)\nprint(A.ndim)\nprint(A.dtype)\n\n(3, 2)\n2\nint64\n\n\n\nA + A # element-wise addition\n\narray([[ 2,  4],\n       [ 6,  8],\n       [10, 12]])\n\n\n\n2 * A - 1 # recycling rule\n\narray([[ 1,  3],\n       [ 5,  7],\n       [ 9, 11]])\n\n\n\nnp.exp(A) # element-wise\n\narray([[  2.72,   7.39],\n       [ 20.09,  54.6 ],\n       [148.41, 403.43]])\n\n\n\nPython vs. NumPy\n\n2**31 + 1\n\n2147483649\n\n\n\na = np.array([2**31-1], dtype='int32')\na + 1\n\narray([-2147483648], dtype=int32)"
  },
  {
    "objectID": "contents/pandas.html#pandas-series-dataframe",
    "href": "contents/pandas.html#pandas-series-dataframe",
    "title": "NumPy and pandas",
    "section": "pandas : Series & DataFrame",
    "text": "pandas : Series & DataFrame\n\nSeries\n1개의 칼럼으로 이루어진 데이터 포멧 - DataFrame의 각 칼럼들을 Series로 이해할 수 있음\n\nSource: Practical Data Science\n\n\nDataFrame\n각 칼럼들이 한 가지 데이터 타입으로 이루어진 tabular형태 (2차원)의 데이터 포맷\n\n각 칼럼은 기본적으로 한 가지 데이터 타입인 것이 이상적이나, 다른 타입이 섞여 있을 수 있음\nNumPy의 2차원 array의 각 칼럼에 labels을 부여한 것으로 볼 수도 있으나, 여러 다른 기능들이 추가됨\nNumPy의 경우 고차원의 array를 다룰 수 있음: ndarray\n\n고차원의 DataFrame과 비슷한 것은 xarray가 존재\n\nLabels와 index를 제외한 데이터 값은 거의 NumPy ndarray로 볼 수 있음\n(pandas.array 존재)\n\n\nSource: Practical Data Science\n\n\n\nndarray로부터 DataFrame을 생성\n\ndf = pd.DataFrame(A, columns=[\"A1\", \"A2\"])\ndf\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n      A2\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n    \n    \n      2\n      5\n      6\n    \n  \n\n\n\n\n\n\n\n# 데이터 값들은 NumPy array\ndf.values # 또는 df.to_numpy()\n\narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n\n\ntype(df)\n\npandas.core.frame.DataFrame\n\n\n\n\nDataFrame의 columns: Series로 추출\n\ns = df[\"A1\"] # A1 칼럼 선택\ns\n# DataFrame의 column 이름이 Series의 name으로 전환\n\n0    1\n1    3\n2    5\nName: A1, dtype: int64\n\n\n\ntype(s)\n\npandas.core.series.Series\n\n\n\n1개의 칼럼만을 가진 DataFrame도 가능\n\ns2 = df[[\"A1\"]] # A1 칼럼 선택\ns2\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n    \n  \n  \n    \n      0\n      1\n    \n    \n      1\n      3\n    \n    \n      2\n      5\n    \n  \n\n\n\n\n\n\n\ntype(s2)\n\npandas.core.frame.DataFrame\n\n\n\n\n\nIndex object\n\nframe1 = pd.DataFrame(np.arange(6).reshape((2, 3)),\n                     index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n                     columns=pd.Index([\"one\", \"two\", \"three\"], name=\"number\"))\nframe1\n\n\n\n\n\n\n\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Ohio\n      0\n      1\n      2\n    \n    \n      Colorado\n      3\n      4\n      5\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n“number”: columns의 이름 (columns도 index object임)\n“state”: index의 이름\nframe1.columns.name #> ‘number’\nframe1.index.name #> ‘state’\n\n\n\nIndex는 여러 levels을 지닐 수 있음: MultiIndex ojbect\n\nframe1.stack() # stack()은 long form으로 변환\n# 2 levels의 index를 가진 Series\n\nstate     number\nOhio      one       0\n          two       1\n          three     2\nColorado  one       3\n          two       4\n          three     5\ndtype: int64\n\n\n\n# MultiIndex를 직접 구성\npd.DataFrame(np.arange(12).reshape((4, 3)),\n        index=pd.MultiIndex.from_arrays([[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]], names=[\"idx1\", \"idx2\"]),\n        columns=pd.MultiIndex.from_arrays([[\"Ohio\", \"Ohio\", \"Colorado\"], [\"Green\", \"Red\", \"Green\"]], names=[\"state\", \"color\"]))\n\n\n\n\n\n\n\n  \n    \n      \n      state\n      Ohio\n      Colorado\n    \n    \n      \n      color\n      Green\n      Red\n      Green\n    \n    \n      idx1\n      idx2\n      \n      \n      \n    \n  \n  \n    \n      a\n      1\n      0\n      1\n      2\n    \n    \n      2\n      3\n      4\n      5\n    \n    \n      b\n      1\n      6\n      7\n      8\n    \n    \n      2\n      9\n      10\n      11\n    \n  \n\n\n\n\n\n\nTime Series에 특화\n\nfb = pd.read_csv('data/fb_stock_prices_2018.csv', index_col='date', parse_dates=True)\nfb.head()\n\n\n\n\n\n  \n    \n      \n      open\n      high\n      low\n      close\n      volume\n    \n    \n      date\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2018-01-02\n      177.68\n      181.58\n      177.55\n      181.42\n      18151903\n    \n    \n      2018-01-03\n      181.88\n      184.78\n      181.33\n      184.67\n      16886563\n    \n    \n      2018-01-04\n      184.90\n      186.21\n      184.10\n      184.33\n      13880896\n    \n    \n      2018-01-05\n      185.59\n      186.90\n      184.93\n      186.85\n      13574535\n    \n    \n      2018-01-08\n      187.20\n      188.90\n      186.33\n      188.28\n      17994726\n    \n  \n\n\n\n\n\nfb.plot(kind='line', y=['high', 'low'], figsize=(7, 4), title='Facebook Stock 2018')\nplt.show()\n\n\n\n\nindex없이 분석 가능?\nindex의 활용은 강의 후반부에…\nIndex를 column으로 전환시켜 분석할 수 있음\n\nfb.reset_index()\n\n\n\n\n\n  \n    \n      \n      date\n      open\n      high\n      low\n      close\n      volume\n    \n  \n  \n    \n      0\n      2018-01-02\n      177.68\n      181.58\n      177.55\n      181.42\n      18151903\n    \n    \n      1\n      2018-01-03\n      181.88\n      184.78\n      181.33\n      184.67\n      16886563\n    \n    \n      2\n      2018-01-04\n      184.90\n      186.21\n      184.10\n      184.33\n      13880896\n    \n    \n      3\n      2018-01-05\n      185.59\n      186.90\n      184.93\n      186.85\n      13574535\n    \n    \n      4\n      2018-01-08\n      187.20\n      188.90\n      186.33\n      188.28\n      17994726\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      246\n      2018-12-24\n      123.10\n      129.74\n      123.02\n      124.06\n      22066002\n    \n    \n      247\n      2018-12-26\n      126.00\n      134.24\n      125.89\n      134.18\n      39723370\n    \n    \n      248\n      2018-12-27\n      132.44\n      134.99\n      129.67\n      134.52\n      31202509\n    \n    \n      249\n      2018-12-28\n      135.34\n      135.92\n      132.20\n      133.20\n      22627569\n    \n    \n      250\n      2018-12-31\n      134.45\n      134.64\n      129.95\n      131.09\n      24625308\n    \n  \n\n251 rows × 6 columns\n\n\n\n\n\n\n\nDataFrame의 연산\nNumPy의 ndarray들이 연산되는 방식과 동일하게 series나 DataFrame들의 연산 가능함\n\ndf + 2 * df\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n      A2\n    \n  \n  \n    \n      0\n      3\n      6\n    \n    \n      1\n      9\n      12\n    \n    \n      2\n      15\n      18\n    \n  \n\n\n\n\n\n\n\nnp.log(df)\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n      A2\n    \n  \n  \n    \n      0\n      0.00\n      0.69\n    \n    \n      1\n      1.10\n      1.39\n    \n    \n      2\n      1.61\n      1.79\n    \n  \n\n\n\n\n\n\n사실 연산은 index를 align해서 시행됨\n\n\n\n\n\n\nframe1\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Ohio\n      0\n      1\n      2\n    \n    \n      Colorado\n      3\n      4\n      5\n    \n  \n\n\n\n\n\n\n\nframe2\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Ohio\n      0\n      2\n      4\n    \n    \n      Floria\n      6\n      8\n      10\n    \n  \n\n\n\n\n\n\nframe1 + frame2\n\n\n\n\n\n\n\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Colorado\n      NaN\n      NaN\n      NaN\n    \n    \n      Floria\n      NaN\n      NaN\n      NaN\n    \n    \n      Ohio\n      0.00\n      3.00\n      6.00\n    \n  \n\n\n\n\n\n\n\n\n(참고) Mixed Data Type\n\ns = pd.Series([1, 2, \"3\"])\n\n\ns.dtype\n\ndtype('O')\n\n\n\ns + s\n\n0     2\n1     4\n2    33\ndtype: object\n\n\n\ns_int = s.astype(\"int\")\ns_int + s_int\n\n0    2\n1    4\n2    6\ndtype: int64\n\n\n\ns2 = pd.Series([1, 2, 3.1])\ns2.dtype\n\ndtype('float64')\n\n\n\ns2.astype(\"int\")\n\n0    1\n1    2\n2    3\ndtype: int64"
  },
  {
    "objectID": "contents/pandas.html#copy-vs.-view",
    "href": "contents/pandas.html#copy-vs.-view",
    "title": "NumPy and pandas",
    "section": "Copy vs. View",
    "text": "Copy vs. View"
  },
  {
    "objectID": "contents/others.html",
    "href": "contents/others.html",
    "title": "class2301",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\n\n\nwdi_data = (\n    \"https://raw.githubusercontent.com/nickeubank/\"\n    \"practicaldatascience/master/Example_Data/wdi_plotting.csv\"\n)\nworld = pd.read_csv(wdi_data)\n\nnames = world.columns[3:].to_list()\n\nnames.append(\"GDP per capita (constant 2015 US$)\")\n\ncountries = world[\"Country Code\"].unique()\n\n\nwdi = pd.read_parquet(\"data/wdi.parquet\")\nwdi2 = wdi[wdi[\"Indicator Name\"].isin(names) & wdi[\"Country Code\"].isin(countries)].copy()\n\nindic_name = wdi2[\"Indicator Name\"].unique()\n\nwdi2.columns = wdi2.columns.str.replace(\" \", \"_\")\nwdi2.rename(str.lower, axis=1, inplace=True)\n\ndic = dict(zip(indic_name, [\"CO2\", \"GDP\", \"life_exp\", \"literacy\", \"mortality\", \"child_mortality\", \"polution\", \"pop\"]))\nwdi2 = wdi2.replace({\"indicator_name\": dic})\n\nyears = wdi2.loc[:, '1960':'2021'].columns\n\nwdi2_long1 = wdi2.melt(\n    id_vars=wdi2.columns[:4], \n    value_vars=years, \n    value_name=\"values\",\n    var_name=\"year\"\n)\n\nwdi2_long1 = wdi2_long1.drop(columns=\"indicator_code\")\n\nwdi2_long2 = wdi2_long1.pivot(\n    index=[\"country_name\",  \"country_code\", \"year\"], columns=\"indicator_name\", \n    values=\"values\"\n)\n\nwdi2_long2.columns.name = \"\"\nwdi2_long2 = wdi2_long2.reset_index()\nwdi2_long2[\"year\"] = wdi2_long2.year.astype(int)\n\n\n\nindicators = wdi[\"Indicator Name\"].unique()\nindicators = pd.Series(indicators)\n\nindicators[indicators.str.contains(\"region\")]\n\n751    Merchandise exports to low- and middle-income ...\n752    Merchandise exports to low- and middle-income ...\n764    Merchandise imports from low- and middle-incom...\n765    Merchandise imports from low- and middle-incom...\ndtype: object\n\n\n\nwdi_country = pd.read_csv(\"data/WDICountry.csv\")\n\nwdi2_long2 = wdi2_long2.merge(wdi_country[[\"Country Code\", \"Short Name\", \"Region\"]], left_on=\"country_code\", right_on=\"Country Code\", how=\"left\")\n\nwdi2_long2.drop(columns=[\"Country Code\"], inplace=True)\n\nwdi2_long2.rename(columns={\"Region\": \"region\", \"Short Name\": \"country\"}, inplace=True)\n\n\nwdi2_long2.region.value_counts(dropna=False)\n\nEurope & Central Asia         3596\nSub-Saharan Africa            2976\nLatin America & Caribbean     2604\nEast Asia & Pacific           2294\nMiddle East & North Africa    1302\nSouth Asia                     496\nNorth America                  186\nName: region, dtype: int64\n\n\n\nwdi_2020 = wdi2_long2.query('year == 2020')\n\nwdi_2020 = wdi_2020.assign(\n    log_gdp = lambda x: np.log(x.GDP),\n    log_child_mortality = lambda x: np.log(x.child_mortality),\n)\n\n\nbig_countries = wdi_2020.nlargest(10, \"pop\")[\"country\"]\nidx = wdi_2020[\"country\"].isin(big_countries)\nwdi_2020_big = wdi_2020[idx]\n\n\n(\n    so.Plot(wdi_2020, x=\"log_gdp\", y=\"child_mortality\")\n    .add(so.Dot(edgecolor=\"white\", alpha=.5), pointsize=\"pop\", color=\"region\")\n    .scale(pointsize=(6, 50), color=\"Set2\")\n    .layout(size=(8, 8))\n    .add(so.Text(halign=\"left\", offset=20), \n         x=wdi_2020_big.log_gdp, \n         y=wdi_2020_big.child_mortality, \n         text=wdi_2020_big.country)\n)\n\n\n\n\n\nwdi_2020_2 = wdi_2020.dropna(subset=[\"log_gdp\", \"log_child_mortality\", \"pop\"])\n\nimport plotly.express as px\nimport plotly.io as pio\n#pio.renderers.default = \"plotly_mimetype+notebook\"\n\nfig = px.scatter(wdi_2020_2, \n                 x=\"log_gdp\", y=\"child_mortality\", \n                 size=\"pop\", size_max=40,\n                 hover_name=\"country_name\")\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nwdi_2020.head()\n\n\n\n\n\n  \n    \n      \n      country_name\n      country_code\n      year\n      CO2\n      GDP\n      child_mortality\n      life_exp\n      literacy\n      mortality\n      polution\n      pop\n      country\n      region\n      log_gdp\n      log_child_mortality\n    \n  \n  \n    \n      60\n      Afghanistan\n      AFG\n      2020\n      NaN\n      553.036479\n      58.0\n      62.575\n      NaN\n      NaN\n      NaN\n      38972230.0\n      Afghanistan\n      South Asia\n      6.315424\n      4.060443\n    \n    \n      122\n      Albania\n      ALB\n      2020\n      NaN\n      4410.455165\n      9.8\n      76.989\n      NaN\n      NaN\n      NaN\n      2837849.0\n      Albania\n      Europe & Central Asia\n      8.391733\n      2.282382\n    \n    \n      184\n      Algeria\n      DZA\n      2020\n      NaN\n      3873.510015\n      22.7\n      74.453\n      NaN\n      NaN\n      NaN\n      43451666.0\n      Algeria\n      Middle East & North Africa\n      8.261916\n      3.122365\n    \n    \n      246\n      American Samoa\n      ASM\n      2020\n      NaN\n      14303.627033\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      46189.0\n      American Samoa\n      East Asia & Pacific\n      9.568268\n      NaN\n    \n    \n      308\n      Andorra\n      AND\n      2020\n      NaN\n      34394.277553\n      2.5\n      NaN\n      NaN\n      NaN\n      NaN\n      77700.0\n      Andorra\n      Europe & Central Asia\n      10.445645\n      0.916291\n    \n  \n\n\n\n\n\nwdi_2020.to_csv(\"data/wdi_2020.csv\", index=False)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "contents/eda.html#statistical-transformations",
    "href": "contents/eda.html#statistical-transformations",
    "title": "Plots",
    "section": "Statistical transformations",
    "text": "Statistical transformations\nAgg, Est, Count, Hist, KDE, Perc, PolyFit\n\n\n\n\n\n\nImportant\n\n\n\n위의 methods들을 이용하여 변형된 데이터 값을 geometric objects에 mapping하여 다양한 플랏을 그릴 수 있음\n\n\n\n\n\n\n\n\nNote\n\n\n\n현재 seaborn.objects에서 다음 두 가지 중요한 statistical transformations이 제공되지 않고 있음\n\nFitted line을 보여주는 loess line\n분포의 간략한 summary인 boxplot\n\n이 부분에 대해서는 다음 몇 가지 대안이 있음: alternative plots 섹션 참고\n\n\n\n\n\n\n\n\nNote\n\n\n\nData에 fitted curve를 구하는 방식에는 여러 방법이 있음\n\nLinear fit: 1차 함수형태로 fit\nSmoothing fit\n\nPolynominal fit: n차 다항함수형태로 fit\nLoess/lowess: locally estimated/weighted scatterplot smoothing\nGAM: generalized additive model\nSpine: piece-wise polynominal regression\n\n\n나중에 좀 더 자세히 알아봄\n현재 seaborn.objects에서는 polynomial fit만 제공\n\n\n\nFitted lines\n\nseaborn.objects\n\nleft = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot())\n    .add(so.Line(), so.PolyFit(5)) # PolyFit(n): n차 다항식으로 fit\n)\n\nright = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Line(), so.PolyFit(5)) # PolyFit(n): n차 다항식으로 fit\n)\n\n\n\n\n\n\n\n\n(a) Scatterplot + trendline\n\n\n\n\n\n\n\n(b) Trendline only\n\n\n\n\nFigure 3: 데이터로부터 계산을 한 후 플랏이 그려짐\n\n\n\nleft = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"drv\") # color mapping이 이후 모든 layer에 적용\n    .add(so.Dot())\n    .add(so.Line(), so.PolyFit(5))\n)\n\nright = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(), color=\"drv\") # color mapping이 이 layer에만 적용\n    .add(so.Line(), so.PolyFit(5))\n)\n\n\n\n\n\n\n\n\n(a) color가 모든 layers에 적용: global mapping\n\n\n\n\n\n\n\n(b) color가 두번째 layer에만 적용: local mapping\n\n\n\n\nFigure 4: Inherited mapping\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(), color=\"drv\")\n    .add(so.Line(), so.PolyFit(5), group=\"drv\") # color가 아닌 group으로 grouping\n)\n\n\n\n\nLinear fit vs. smoothing fit:\n선형적인 트렌드에서 얼마나 벗어나는가?\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\".6\"))\n    .add(so.Line(), so.PolyFit(5))\n    .add(so.Line(), so.PolyFit(1))\n)\n\n\n\n\n다른 대안으로는 plotly, seaborn: alternative plots 섹션 참고"
  },
  {
    "objectID": "contents/visualizatioin.html",
    "href": "contents/visualizatioin.html",
    "title": "class2301",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\n\nimport seaborn.objects as so\nimport seaborn as sns\n\nimport statsmodels.api as sm\n\nimport plotly.express as px\n\n# defeif\n\n\ndiamonds = sm.datasets.get_rdataset(\"diamonds\", \"ggplot2\").data\ndiamonds.head()\n\n\n\n\n\n  \n    \n      \n      carat\n      cut\n      color\n      clarity\n      depth\n      table\n      price\n      x\n      y\n      z\n    \n  \n  \n    \n      0\n      0.23\n      Ideal\n      E\n      SI2\n      61.5\n      55.0\n      326\n      3.95\n      3.98\n      2.43\n    \n    \n      1\n      0.21\n      Premium\n      E\n      SI1\n      59.8\n      61.0\n      326\n      3.89\n      3.84\n      2.31\n    \n    \n      2\n      0.23\n      Good\n      E\n      VS1\n      56.9\n      65.0\n      327\n      4.05\n      4.07\n      2.31\n    \n    \n      3\n      0.29\n      Premium\n      I\n      VS2\n      62.4\n      58.0\n      334\n      4.20\n      4.23\n      2.63\n    \n    \n      4\n      0.31\n      Good\n      J\n      SI2\n      63.3\n      58.0\n      335\n      4.34\n      4.35\n      2.75\n    \n  \n\n\n\n\n\nflights = sm.datasets.get_rdataset(\"flights\", \"nycflights13\").data\nflights.head()\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n      time_hour\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n      517.0\n      515\n      2.0\n      830.0\n      819\n      11.0\n      UA\n      1545\n      N14228\n      EWR\n      IAH\n      227.0\n      1400\n      5\n      15\n      2013-01-01 05:00:00\n    \n    \n      1\n      2013\n      1\n      1\n      533.0\n      529\n      4.0\n      850.0\n      830\n      20.0\n      UA\n      1714\n      N24211\n      LGA\n      IAH\n      227.0\n      1416\n      5\n      29\n      2013-01-01 05:00:00\n    \n    \n      2\n      2013\n      1\n      1\n      542.0\n      540\n      2.0\n      923.0\n      850\n      33.0\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.0\n      1089\n      5\n      40\n      2013-01-01 05:00:00\n    \n    \n      3\n      2013\n      1\n      1\n      544.0\n      545\n      -1.0\n      1004.0\n      1022\n      -18.0\n      B6\n      725\n      N804JB\n      JFK\n      BQN\n      183.0\n      1576\n      5\n      45\n      2013-01-01 05:00:00\n    \n    \n      4\n      2013\n      1\n      1\n      554.0\n      600\n      -6.0\n      812.0\n      837\n      -25.0\n      DL\n      461\n      N668DN\n      LGA\n      ATL\n      116.0\n      762\n      6\n      0\n      2013-01-01 06:00:00\n    \n  \n\n\n\n\n\nmpg = sm.datasets.get_rdataset(\"mpg\", \"ggplot2\").data\nmpg.head()\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n  \n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\")\npenguins.head()\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      Male\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      Female\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      Female\n    \n    \n      3\n      Adelie\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      Adelie\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      Female\n    \n  \n\n\n\n\n\ntips = sns.load_dataset(\"tips\")\ntips.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n    \n  \n\n\n\n\n\nhealthexp = sns.load_dataset(\"healthexp\")\nhealthexp.head()\n\n\n\n\n\n  \n    \n      \n      Year\n      Country\n      Spending_USD\n      Life_Expectancy\n    \n  \n  \n    \n      0\n      1970\n      Germany\n      252.311\n      70.6\n    \n    \n      1\n      1970\n      France\n      192.143\n      72.2\n    \n    \n      2\n      1970\n      Great Britain\n      123.993\n      71.9\n    \n    \n      3\n      1970\n      Japan\n      150.437\n      72.0\n    \n    \n      4\n      1970\n      USA\n      326.961\n      70.9\n    \n  \n\n\n\n\n\n(\n    so.Plot(tips, x=\"total_bill\", y=\"tip\", color=\"time\")\n    .add(so.Dots())\n    .add(so.Line(), so.PolyFit())\n    .add(so.Line(), so.PolyFit(1))\n)\n\n\n\n\n\nsns.lmplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\", lowess=True, col=\"sex\", height=5, aspect=2/3, scatter_kws={\"alpha\":.8, \"s\":5})\n\n<seaborn.axisgrid.FacetGrid at 0x158621e90>\n\n\n\n\n\n\n# https://plotly.com/python/linear-fits/\npx.scatter(tips, x=\"total_bill\", y=\"tip\", color=\"time\", trendline=\"lowess\", \ntrendline_options=dict(frac=3/10)) # default: 2/3\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\ng = sns.catplot(data=tips, x=\"day\", y=\"total_bill\", kind=\"violin\", inner=None)\n\n\n\n\n\nsns.swarmplot(data=tips, x=\"day\", y=\"total_bill\", color=\"k\", size=3, ax=g.ax)\n\n<AxesSubplot: xlabel='day', ylabel='total_bill'>\n\n\n\npenguins = sns.load_dataset(\"penguins\")\n\nsns.set_palette(\"Set3\")\n\nsns.lmplot(data=penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\", lowess=True, col=\"sex\", height=3, scatter_kws={\"alpha\":.5, \"s\":5})\n\n<seaborn.axisgrid.FacetGrid at 0x16583df50>\n\n\n\n\n\n\n(\n    so.Plot(x=penguins[\"bill_length_mm\"], y=penguins[\"bill_depth_mm\"])\n    .add(so.Dots(), color=penguins[\"species\"])\n    .add(so.Line(), so.PolyFit())\n    .add(so.Line(), so.PolyFit(1))\n)\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\")\n    .add(so.Dots())\n    .add(so.Line(), so.PolyFit())\n    .facet(col=\"sex\")\n)\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\")\n    .add(so.Dots())\n    .add(so.Line(), so.PolyFit())\n    .facet(col=\"sex\")\n)\n\n\n\n\n\n\npx.scatter(penguins.query('~@pd.isna(sex)'), x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\", opacity=.3,\n     facet_col=\"sex\", trendline=\"lowess\")\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\npx.scatter(penguins.dropna(subset=\"sex\"), x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\",\n     facet_col=\"sex\", trendline=\"lowess\")\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\npenguins\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      Male\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      Female\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      Female\n    \n    \n      3\n      Adelie\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      Adelie\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      Female\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      339\n      Gentoo\n      Biscoe\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      340\n      Gentoo\n      Biscoe\n      46.8\n      14.3\n      215.0\n      4850.0\n      Female\n    \n    \n      341\n      Gentoo\n      Biscoe\n      50.4\n      15.7\n      222.0\n      5750.0\n      Male\n    \n    \n      342\n      Gentoo\n      Biscoe\n      45.2\n      14.8\n      212.0\n      5200.0\n      Female\n    \n    \n      343\n      Gentoo\n      Biscoe\n      49.9\n      16.1\n      213.0\n      5400.0\n      Male\n    \n  \n\n344 rows × 7 columns\n\n\n\n\n(\n    so.Plot(penguins, x=\"bill_length_mm\", color=\"species\")\n    #.add(so.Dots(), so.Hist())\n    .add(so.Line(marker=\".\"), so.Hist(binwidth=2))\n    #.add(so.Line(), so.PolyFit())\n    .facet(col=\"sex\")\n)\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"bill_length_mm\", color=\"species\")\n    .add(so.Area(), so.Hist(binwidth=2))\n    .facet(col=\"sex\")\n)\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"flipper_length_mm\")\n    .add(so.Bars(), so.Hist(binwidth=10))\n)\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"species\")\n    .add(so.Bar(), so.Count())\n)\n\n\n\n\n\nhealthexp = sns.load_dataset(\"healthexp\")\np = so.Plot(healthexp, \"Spending_USD\", \"Life_Expectancy\", color=\"Country\")\np.add(so.Path())\n\n\n\n\n\nhealthexp = sns.load_dataset(\"healthexp\")\np = so.Plot(healthexp, \"Spending_USD\", \"Life_Expectancy\", color=\"Country\")\np.add(so.Line())\n\n\n\n\n\nhealthexp = sns.load_dataset(\"healthexp\")\np = so.Plot(healthexp, \"Spending_USD\", \"Life_Expectancy\")\n\nhline = pd.DataFrame({\"x\": [0, 12000], \"y\": [80, 80]})\n\n(\n    p.add(so.Line(), color=\"Country\")\n    .add(so.Line(linestyle=\":\", color=\"red\"), x=hline.x, y=hline.y)\n)\n\n\n\n\n\nimport plotly.express as px\n\ndf = px.data.tips()\npx.scatter(df, x=\"total_bill\", y=\"tip\", color=\"day\", \n     facet_col=\"day\", facet_col_wrap=2, trendline=\"lowess\")\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nsns.jointplot(tips, x=\"total_bill\", y=\"tip\", kind=\"hex\")\n\n<seaborn.axisgrid.JointGrid at 0x16530f310>\n\n\n\n\n\n\nsns.histplot(penguins, x=\"bill_depth_mm\", y=\"body_mass_g\", hue=\"species\")\n\n<AxesSubplot: xlabel='bill_depth_mm', ylabel='body_mass_g'>\n\n\n\n\n\n\ndiamonds = sns.load_dataset(\"diamonds\")\ndiamonds.head()\n\n\n\n\n\n  \n    \n      \n      carat\n      cut\n      color\n      clarity\n      depth\n      table\n      price\n      x\n      y\n      z\n    \n  \n  \n    \n      0\n      0.23\n      Ideal\n      E\n      SI2\n      61.5\n      55.0\n      326\n      3.95\n      3.98\n      2.43\n    \n    \n      1\n      0.21\n      Premium\n      E\n      SI1\n      59.8\n      61.0\n      326\n      3.89\n      3.84\n      2.31\n    \n    \n      2\n      0.23\n      Good\n      E\n      VS1\n      56.9\n      65.0\n      327\n      4.05\n      4.07\n      2.31\n    \n    \n      3\n      0.29\n      Premium\n      I\n      VS2\n      62.4\n      58.0\n      334\n      4.20\n      4.23\n      2.63\n    \n    \n      4\n      0.31\n      Good\n      J\n      SI2\n      63.3\n      58.0\n      335\n      4.34\n      4.35\n      2.75\n    \n  \n\n\n\n\n\nsns.histplot(diamonds, x=\"carat\", y=\"price\", bins=20)\n\n<AxesSubplot: xlabel='carat', ylabel='price'>\n\n\n\n\n\n\ng = sns.relplot(diamonds, x=\"carat\", y=\"price\", kind=\"scatter\", color=\"red\")\nsns.histplot(diamonds, x=\"carat\", y=\"price\", bins=20, ax=g.ax, alpha=.5)\n\n<AxesSubplot: xlabel='carat', ylabel='price'>\n\n\n\n\n\n\npenguins.groupby([\"sex\", \"species\"]).size()\n\nsex     species  \nFemale  Adelie       73\n        Chinstrap    34\n        Gentoo       58\nMale    Adelie       73\n        Chinstrap    34\n        Gentoo       61\ndtype: int64\n\n\n\ndf = penguins[[\"sex\", \"species\"]].value_counts(sort=False).reset_index(name=\"n\")\ndf[\"prop\"] = df[\"n\"] / df.groupby(\"sex\")[\"n\"].transform(\"sum\")\n\n(\n    so.Plot(df, x=\"species\", y=\"prop\", color=\"species\")\n    .add(so.Bar())\n    .facet(\"sex\")\n    .scale(\n        y=so.Continuous().label(like=\"{x:.1%}\"),\n        color=\"Set1\"\n    )\n)\n\n#     .scale(\n#         x=so.Continuous(trans=\"sqrt\").tick(every=.5),\n#         y=so.Continuous().label(like=\"${x:,.1%}\"),\n#         color=so.Continuous(\"ch:.2\").tick(upto=4).label(unit=\"m\"),\n\n\n\n\n\n(\n    so.Plot(data=penguins, x=\"species\", color=\"island\")\n    .add(so.Bars(width=.8), so.Hist(stat=\"proportion\", common_norm=[\"x\"]), so.Stack())\n)\n\n/Users/georgeair/miniconda3/envs/envconda/lib/python3.11/site-packages/seaborn/_stats/counting.py:228: UserWarning:\n\nUndefined variable(s) passed for Hist.common_norm: 'x'.\n\n\n\n\n\n\n\ntips.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n    \n  \n\n\n\n\n\n(\n    so.Plot(data=tips, x=\"day\", color=\"smoker\")\n    .add(so.Bars(width=.8), so.Hist(stat=\"proportion\", common_norm=[\"x\"]), so.Stack())\n)\n\n/Users/georgeair/miniconda3/envs/envconda/lib/python3.11/site-packages/seaborn/_stats/counting.py:228: UserWarning:\n\nUndefined variable(s) passed for Hist.common_norm: 'x'.\n\n\n\n\n\n\n\n(\n    so.Plot(data=tips, x=\"day\", color=\"smoker\")\n    .add(so.Bars(width=.8), so.Hist(stat=\"proportion\", common_norm=[\"col\", \"x\"]), so.Stack())\n    .facet(\"sex\")\n    .label(col=\"Sex:\")\n)\n\n/Users/georgeair/miniconda3/envs/envconda/lib/python3.11/site-packages/seaborn/_stats/counting.py:228: UserWarning:\n\nUndefined variable(s) passed for Hist.common_norm: 'x'.\n\n\n\n\n\n\n\np = so.Plot(penguins, \"flipper_length_mm\")\np = p.facet(\"island\")\n\np.add(so.Bars(width=.8, ), so.Hist(stat=\"proportion\", common_norm=[\"col\"]), so.Dodge(), color=\"sex\")\n\n\n\n\n\np.add(so.Bars(), so.Hist(stat=\"proportion\", common_norm=[\"sex\"]), color=\"sex\")\n\n/Users/georgeair/miniconda3/envs/envconda/lib/python3.11/site-packages/seaborn/_stats/counting.py:228: UserWarning:\n\nUndefined variable(s) passed for Hist.common_norm: 'sex'.\n\n\n\n\n\n\n\np = (\n    so.Plot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\")\n    .facet(col=\"species\", row=\"sex\")\n    .add(so.Dots())\n)\np.share(x=False, y=True)\n\n\n\n\n\n(\n    so.Plot(penguins, y=\"flipper_length_mm\")\n    .pair(x=[\"bill_length_mm\", \"bill_depth_mm\"])\n    .add(so.Dots())\n    .share(x=True)\n)\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\np = so.Plot(diamonds, \"carat\", \"price\").add(so.Dots())\nq = so.Plot(diamonds, \"carat\", \"price\").add(so.Line(), so.PolyFit())\n\nf = mpl.figure.Figure(figsize=(7, 4))\nsf1, sf2 = f.subfigures(1, 2)\n\np.on(sf1).plot()\nq.on(sf2).plot()\n\n\n\n\n\n(\n    so.Plot(tips, x=\"total_bill\", y=\"size\", color=\"time\")\n    .add(so.Dot(alpha=.5), so.Jitter(.4), orient=\"y\")\n)\n\n\n\n\n\ng = sns.FacetGrid(tips, col=\"time\",  row=\"sex\")\ng.map_dataframe(sns.histplot, x=\"total_bill\")\n\n<seaborn.axisgrid.FacetGrid at 0x16336a550>\n\n\n\n\n\n\ng = sns.FacetGrid(tips, col=\"time\")\ng.map_dataframe(sns.boxplot, x=\"day\", y=\"total_bill\", hue=\"day\")\n\n<seaborn.axisgrid.FacetGrid at 0x284013690>\n\n\n\n\n\n\ng = sns.FacetGrid(tips, col=\"time\", margin_titles=True)\ng.map_dataframe(sns.scatterplot, x=\"total_bill\", y=\"tip\")\ng.refline(y=tips[\"tip\"].median())\n\n<seaborn.axisgrid.FacetGrid at 0x28450b8d0>\n\n\n\n\n\n\npx.box(tips, x=\"day\", y=\"total_bill\", \n    color=\"day\", points=\"all\", facet_col=\"time\",\n    category_orders={\"day\": tips.day.values.categories.values})\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n# https://plotly.com/python/axes/\n(\n  px.scatter(tips, x=\"total_bill\", y=\"tip\", color=\"day\", \n     facet_col=\"day\", facet_col_wrap=2, trendline=\"ols\")\n    .update_yaxes(scaleanchor = \"x\", scaleratio = 3)\n    #.update_xaxes(range=[10, 40], constrain=\"domain\")\n    .update_xaxes(range=[10, 40])\n    .add_hline(y=5, fillcolor=\"white\")\n    .update_layout(width=800, height=500)\n)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n# https://plotly.com/python/axes/\n(\n  px.scatter(tips, x=\"total_bill\", y=\"tip\", color=\"day\", \n     facet_col=\"day\", facet_col_wrap=2, trendline=\"ols\")\n    .update_yaxes(scaleanchor = \"x\", scaleratio = 3)\n    .update_xaxes(range=[10, 40], constrain=\"domain\")\n    #.update_xaxes(range=[10, 40])\n    .add_hline(y=2, line_color=\"white\", line_width=3, line_dash=\"dash\")\n    .update_layout(width=800, height=500)\n)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n#https://plotly.com/python/creating-and-updating-figures/\n\nfrom plotly.subplots import make_subplots\n\nfig = make_subplots(rows=1, cols=1)\n\nfig.add_scatter(y=[4, 2, 1], mode=\"lines\", row=1, col=1)\nfig.add_bar(y=[2, 1, 3], row=1, col=1)\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n# https://seaborn.pydata.org/generated/seaborn.objects.Plot.scale.html\n\n(\n    so.Plot(mpg, x=\"cyl\")\n    .add(so.Bar(), so.Hist())\n    .scale(x=so.Nominal())\n    .label(x=\"cylinder\", y=\"count\",\n        title=\"the number of cars by cylinder\")\n)\n\n\n\n\n\nimport matplotlib.pyplot as plt\nsns.set(style=\"darkgrid\")\ndf = sns.load_dataset('iris')\n\n# Usual boxplot\nax = sns.boxplot(x='species', y='sepal_length', data=df)\n \n# Add jitter with the swarmplot function\nax = sns.swarmplot(x='species', y='sepal_length', data=df, color=\"grey\")\nplt.show()\n\n\n\n\n\nax = sns.stripplot(data=tips, x=\"day\", y=\"total_bill\", alpha=.5)\nax = sns.boxplot(data=tips, x=\"day\", y=\"total_bill\")\nax = sns.violinplot(data=tips, x=\"day\", y=\"total_bill\")\n\nplt.show()\n\n\n\n\n\nsns.pairplot(penguins, hue=\"species\", kind=\"reg\",\n    markers=[\".\", \".\", \".\"])\n\n<seaborn.axisgrid.PairGrid at 0x163058810>\n\n\n\n\n\n\ncor_mat.head()\n\n\n\n\n\n  \n    \n      \n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n    \n  \n  \n    \n      bill_length_mm\n      1.000000\n      -0.235053\n      0.656181\n      0.595110\n    \n    \n      bill_depth_mm\n      -0.235053\n      1.000000\n      -0.583851\n      -0.471916\n    \n    \n      flipper_length_mm\n      0.656181\n      -0.583851\n      1.000000\n      0.871202\n    \n    \n      body_mass_g\n      0.595110\n      -0.471916\n      0.871202\n      1.000000\n    \n  \n\n\n\n\n\ncor_mat = penguins.corr(numeric_only=True)\nsns.heatmap(cor_mat, annot=True, cmap=\"crest\", vmin=-1, vmax=1)\n\n<AxesSubplot: >\n\n\n\n\n\n\nmask = np.triu(np.ones_like(cor_mat, dtype=bool))\nnp.fill_diagonal(mask, False)\nmask\n\narray([[False,  True,  True,  True],\n       [False, False,  True,  True],\n       [False, False, False,  True],\n       [False, False, False, False]])\n\n\n\ndef cor_heatmap(df, font=10, abs=False):\n    if abs:\n        df = np.abs(df)\n    mask = np.triu(np.ones_like(df, dtype=bool))\n    np.fill_diagonal(mask, False)\n    cmap = sns.diverging_palette(205, 12, s=100, l=55, as_cmap=True)\n    \n    ax = sns.heatmap(df, annot=True, cmap=cmap, vmin=-1, vmax=1, mask=mask,\n    annot_kws={\"size\": font})\n    ax.set(xlabel=\"\", ylabel=\"\")\n    ax.set_xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=45, ha='right')\n\ncor_heatmap(cor_mat)\n\n\n\n\n\nmtcars = sm.datasets.get_rdataset(\"mtcars\").data\n\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 6))\ncor_heatmap(mtcars.corr(), 9, abs=True)\n\n\n\n\n\nfrom vega_datasets import data\ngapminder = data.gapminder()\ngap = gapminder[[\"country\", \"year\", \"life_expect\", \"cluster\"]]\n\n\ngap.iloc[:,:-1].set_index([\"country\", \"year\"]).unstack().head()\n\n\n\n\n\n  \n    \n      \n      life_expect\n    \n    \n      year\n      1955\n      1960\n      1965\n      1970\n      1975\n      1980\n      1985\n      1990\n      1995\n      2000\n      2005\n    \n    \n      country\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Afghanistan\n      30.332\n      31.997\n      34.020\n      36.088\n      38.438\n      39.854\n      40.822\n      41.674\n      41.763\n      42.129\n      43.828\n    \n    \n      Argentina\n      64.399\n      65.142\n      65.634\n      67.065\n      68.481\n      69.942\n      70.774\n      71.868\n      73.275\n      74.340\n      75.320\n    \n    \n      Aruba\n      64.381\n      66.606\n      68.336\n      70.941\n      71.830\n      74.116\n      74.494\n      74.108\n      73.011\n      73.451\n      74.239\n    \n    \n      Australia\n      70.330\n      70.930\n      71.100\n      71.930\n      73.490\n      74.740\n      76.320\n      77.560\n      78.830\n      80.370\n      81.235\n    \n    \n      Austria\n      67.480\n      69.540\n      70.140\n      70.630\n      72.170\n      73.180\n      74.940\n      76.040\n      77.510\n      78.980\n      79.829\n    \n  \n\n\n\n\n\ngap_wide = gap.pivot(index=[\"country\"], columns=\"year\", values=\"life_expect\")\ngap_wide.head()\n\n\n\n\n\n  \n    \n      year\n      1955\n      1960\n      1965\n      1970\n      1975\n      1980\n      1985\n      1990\n      1995\n      2000\n      2005\n    \n    \n      country\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Afghanistan\n      30.332\n      31.997\n      34.020\n      36.088\n      38.438\n      39.854\n      40.822\n      41.674\n      41.763\n      42.129\n      43.828\n    \n    \n      Argentina\n      64.399\n      65.142\n      65.634\n      67.065\n      68.481\n      69.942\n      70.774\n      71.868\n      73.275\n      74.340\n      75.320\n    \n    \n      Aruba\n      64.381\n      66.606\n      68.336\n      70.941\n      71.830\n      74.116\n      74.494\n      74.108\n      73.011\n      73.451\n      74.239\n    \n    \n      Australia\n      70.330\n      70.930\n      71.100\n      71.930\n      73.490\n      74.740\n      76.320\n      77.560\n      78.830\n      80.370\n      81.235\n    \n    \n      Austria\n      67.480\n      69.540\n      70.140\n      70.630\n      72.170\n      73.180\n      74.940\n      76.040\n      77.510\n      78.980\n      79.829\n    \n  \n\n\n\n\n\nsns.clustermap(gap_wide, col_cluster=False, cmap=\"crest\", cbar_pos=(1, 0.1, .02, .5))\n\n<seaborn.matrix.ClusterGrid at 0x117f97850>\n\n\n\n\n\n\nR for Data Science\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\")\n    .add(so.Dot(alpha=.2))\n)\n\n\n\n\n\nmpg.head()\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n  \n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", pointsize=\"class\")\n    .add(so.Dots(alpha=.5, fill=True))\n    .scale(pointsize=(1, 20))\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", alpha=\"class\")\n    .add(so.Dot(pointsize=10))\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", marker=\"class\")\n    .add(so.Dots(pointsize=10))\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", stroke=\"class\")\n    .add(so.Dots())\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\"blue\"))\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dots(stroke=2, pointsize=10, fill=False))\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot())\n    .facet(\"class\", wrap=4) # default: col\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot())\n    .facet(row=\"class\", wrap=3)\n)\n\n\n\n\n\n(\n    so.Plot(tips, x=\"total_bill\", y=\"tip\", pointsize=\"size\", color=\"size\")\n    .add(so.Dot(edgecolor=\"white\"))\n    .scale(pointsize=(3, 20))\n\n)\n\n\n\n\n\n# parsing function\ndef make_datetime_100(data, time):\n    date_data = (data[['year', 'month', 'day', time]].\n        assign(\n            hour = lambda x: x[time] // 100,\n            minute = lambda x: x[time] % 100).\n        filter(['year', 'month', 'day', 'hour', 'minute'])\n    )\n    \n    out = pd.to_datetime(date_data)\n\n    return out\n\n# data table\nflights_dt = (flights.\n    query('(dep_time.notna()) & (arr_time.notna())').\n    assign(\n        dep_time = lambda x: make_datetime_100(x, 'dep_time'),\n        arr_time = lambda x: make_datetime_100(x, 'arr_time'),\n        sched_dep_time = lambda x: make_datetime_100(x, 'sched_dep_time'),\n        sched_arr_time = lambda x: make_datetime_100(x, 'sched_arr_time')\n    ).\n    filter( regex = 'origin|dest|delay$|time$')\n)\n\n\nflights_dt.head()\n\n\n\n\n\n  \n    \n      \n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      origin\n      dest\n      air_time\n    \n  \n  \n    \n      0\n      2013-01-01 05:17:00\n      2013-01-01 05:15:00\n      2.0\n      2013-01-01 08:30:00\n      2013-01-01 08:19:00\n      11.0\n      EWR\n      IAH\n      227.0\n    \n    \n      1\n      2013-01-01 05:33:00\n      2013-01-01 05:29:00\n      4.0\n      2013-01-01 08:50:00\n      2013-01-01 08:30:00\n      20.0\n      LGA\n      IAH\n      227.0\n    \n    \n      2\n      2013-01-01 05:42:00\n      2013-01-01 05:40:00\n      2.0\n      2013-01-01 09:23:00\n      2013-01-01 08:50:00\n      33.0\n      JFK\n      MIA\n      160.0\n    \n    \n      3\n      2013-01-01 05:44:00\n      2013-01-01 05:45:00\n      -1.0\n      2013-01-01 10:04:00\n      2013-01-01 10:22:00\n      -18.0\n      JFK\n      BQN\n      183.0\n    \n    \n      4\n      2013-01-01 05:54:00\n      2013-01-01 06:00:00\n      -6.0\n      2013-01-01 08:12:00\n      2013-01-01 08:37:00\n      -25.0\n      LGA\n      ATL\n      116.0\n    \n  \n\n\n\n\n\nplot_dat = (flights_dt.assign(\n    minute = lambda x: x.dep_time.dt.minute).\n    groupby('minute').\n    agg(\n        avg_delay = ('arr_delay', np.mean),\n        n = ('arr_delay', 'size')\n    ).reset_index()\n)\n\nso.Plot(plot_dat, x=\"minute\", y=\"avg_delay\").add(so.Line(marker=\"o\", edgecolor=\"red\", linewidth=2), linestyle=None)\n\n\n\n\n\n\n(\n    px.scatter(mpg, x=\"displ\", y=\"hwy\", color=\"drv\", \n    trendline=\"lowess\", trendline_options=dict(frac=.5))\n    .update_layout(width=600, height=400)\n)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n(\n    px.scatter(mpg, x=\"displ\", y=\"hwy\", \n    trendline=\"lowess\", trendline_options=dict(frac=.5))\n    .update_layout(width=600, height=400)\n)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"drv\")\n    .add(so.Dot())\n    .add(so.Line(linewidth=2), so.PolyFit(5))\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"drv\")\n    .add(so.Dot())\n    .add(so.Band(alpha=.7), so.Est())\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", linestyle=\"drv\")\n    .add(so.Line(linewidth=2), so.PolyFit(5))\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", linestyle=\"drv\", color=\"drv\")\n    .add(so.Line(linewidth=2), so.PolyFit(5))\n)\n\n\n\n\n\nmpg_subcpt = mpg[mpg[\"class\"] == \"subcompact\"]\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(), color=\"class\")\n    .add(so.Line(linewidth=2), so.PolyFit(5), \n        x=mpg_subcpt.displ,\n        y=mpg_subcpt.hwy)\n    .scale(color=\"Set2\")\n)\n\n\n\n\n\nmpg.head()\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n  \n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"drv\")\n    .add(so.Dot(pointsize=10, edgecolor=\"white\", edgewidth=3))\n)\n\n\n\n\n\nsmaller = diamonds.query('carat < 3')\n\n(\n    so.Plot(smaller, x=\"carat\", color=\"cut\")\n    .add(so.Line(marker=\".\"), so.Hist(binwidth=.1))\n)\n\n\n\n\n\n(\n    so.Plot(smaller, x=\"carat\", color=\"cut\")\n    .add(so.Line(marker=\".\"), so.Hist(stat=\"probability\", binwidth=.1, common_norm=[\"color\"]))\n)\n\n\n\n\n\ncl = mpg.groupby(\"class\")[\"hwy\"].median().sort_values().index.values\npx.box(mpg, x=\"class\", y=\"hwy\", category_orders={\"class\": cl})\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\ncl = mpg.groupby(\"class\")[\"hwy\"].median().sort_values().index.values\n\npx.box(mpg, y=\"class\", x=\"hwy\", category_orders={\"class\": cl})\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\ncl = mpg.groupby(\"class\")[\"hwy\"].median().sort_values().index.values\n\n(\n    so.Plot(mpg, x=\"class\", y=\"hwy\")\n    .add(so.Dot(pointsize=10), so.Agg(\"median\"))\n    .scale(x=so.Nominal(order=cl))\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"class\", y=\"hwy\")\n    #.add(so.Dot(alpha=.3, pointsize=5), so.Jitter(width=.5))\n    .add(so.Dots(pointsize=5, color=\"dodgerblue\"), so.Jitter(width=.5))\n    .add(so.Range(color=\"orangered\"), so.Est(errorbar=\"sd\"))\n    .add(so.Dot(pointsize=8, color=\"orangered\"), so.Agg())\n    .add(so.Line(color=\"orangered\"), so.Agg())\n    .scale(x=so.Nominal(order=cl))\n)\n\n\n\n\n\nsns.boxplot(mpg, x=\"class\", y=\"hwy\")\n\n<AxesSubplot: xlabel='class', ylabel='hwy'>\n\n\n\n\n\n\nmpg.groupby(\"class\").boxplot(column=\"hwy\", subplots=False)\n\n<AxesSubplot: >\n\n\n\n\n\n\nsns.histplot(diamonds, x=\"color\", y=\"cut\", cbar=True)\n\n<AxesSubplot: xlabel='color', ylabel='cut'>\n\n\n\n\n\n\nsns.jointplot(diamonds, x=\"color\", y=\"cut\", cbar=True, kind=\"hist\")\n\n<seaborn.axisgrid.JointGrid at 0x28531a910>\n\n\n\n\n\n\ndia_sum = diamonds.groupby([\"color\", \"cut\"]).size().reset_index(name=\"count\")\n\n(\n    so.Plot(dia_sum, x=\"cut\", y=\"color\", pointsize=\"count\")\n    .add(so.Dot())\n    .scale(pointsize=(5, 20))\n)\n\n\n\n\n\ndia_sum = diamonds.groupby([\"color\", \"cut\"]).size().reset_index(name=\"count\")\n\n(\n    so.Plot(dia_sum, x=\"color\", y=\"cut\", color=\"count\")\n    .add(so.Dot(pointsize=30))\n    .scale(color=(\"deepskyblue\", \"blue\"))\n)\n\n\n\n\n\n(\n    so.Plot(diamonds, x=\"carat\", y=\"price\")\n    .add(so.Dot(alpha=.01))\n)\n\n\n\n\n\nsmaller = (\n    diamonds\n    .query('carat < 3')\n    .assign(\n        carat_cat=lambda x:pd.cut(x.carat, 30, labels=False)\n    )\n)\n\n(\n    px.box(smaller, x=\"carat_cat\", y=\"price\",\n        title=\"price vs. carat\",\n        labels={\"carat_cat\": \"carat discretized\"})\n)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n(\n    px.box(smaller, x=\"carat_cat\", y=\"price\")\n    .update_layout(\n        title_text=\"price vs. carat\",\n        xaxis_title=\"Carat\",\n        yaxis_title=\"Price\")\n)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nsmaller = (\n    diamonds\n    .query('carat < 3')\n    .assign(\n        carat_cat2=lambda x:pd.qcut(x.carat, 25, labels=False)\n    )\n)\n\npx.box(smaller, x=\"carat_cat2\", y=\"price\")\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nsns.boxplot(smaller, x=\"carat_cat2\", y=\"price\")\n\n<AxesSubplot: xlabel='carat_cat2', ylabel='price'>\n\n\n\n\n\n\nsmaller.head()\n\n\n\n\n\n  \n    \n      \n      carat\n      cut\n      color\n      clarity\n      depth\n      table\n      price\n      x\n      y\n      z\n      carat_cat2\n    \n  \n  \n    \n      0\n      0.23\n      Ideal\n      E\n      SI2\n      61.5\n      55.0\n      326\n      3.95\n      3.98\n      2.43\n      0\n    \n    \n      1\n      0.21\n      Premium\n      E\n      SI1\n      59.8\n      61.0\n      326\n      3.89\n      3.84\n      2.31\n      0\n    \n    \n      2\n      0.23\n      Good\n      E\n      VS1\n      56.9\n      65.0\n      327\n      4.05\n      4.07\n      2.31\n      0\n    \n    \n      3\n      0.29\n      Premium\n      I\n      VS2\n      62.4\n      58.0\n      334\n      4.20\n      4.23\n      2.63\n      0\n    \n    \n      4\n      0.31\n      Good\n      J\n      SI2\n      63.3\n      58.0\n      335\n      4.34\n      4.35\n      2.75\n      1\n    \n  \n\n\n\n\n\n(\n    so.Plot(smaller, x=\"carat_cat\", y=\"price\")\n    .add(so.Dot(alpha=.01, color=\"deepskyblue\"))\n    .add(so.Range(color=\"orangered\"), so.Est(errorbar=\"sd\"))\n    .add(so.Dot(pointsize=8, color=\"orangered\"), so.Agg())\n    .add(so.Line(color=\"orangered\"), so.Agg())\n    .add(so.Line(color=\"blue\"), so.PolyFit(3))\n)\n\n# colors: https://matplotlib.org/3.1.0/gallery/color/named_colors.html\n\n\n\n\n\nsns.jointplot(diamonds, x=\"carat\", y=\"price\", kind=\"hex\")\n\n<seaborn.axisgrid.JointGrid at 0x1544d1090>\n\n\n\n\n\n\npx.density_heatmap(diamonds, x=\"carat\", y=\"price\",\n    nbinsx=20, nbinsy=20, color_continuous_scale=\"Viridis\")\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "contents/Untitled.html",
    "href": "contents/Untitled.html",
    "title": "class2301",
    "section": "",
    "text": "import plotly.express as px\ndf = px.data.tips()\nfig = px.scatter(df, x=\"total_bill\", y=\"tip\", color=\"smoker\", facet_col=\"sex\")\nfig.show()"
  },
  {
    "objectID": "contents/trendlines.html",
    "href": "contents/trendlines.html",
    "title": "class2301",
    "section": "",
    "text": "import pandas as pd  # for data manipulation\nimport numpy as np  # for data manipulation\nfrom sklearn.linear_model import LinearRegression  # to build a LR model for comparison\nimport plotly.graph_objects as go  # for data visualization\nimport plotly.express as px  # for data visualization\nimport statsmodels.api as sm  # to build a LOWESS model\nfrom scipy.interpolate import interp1d  # for interpolation of new data points\n\n\n# Read in data\ndf = pd.read_csv(\"data/Real estate.csv\", encoding=\"utf-8\")\n# Print Dataframe\ndf\n\n\n\n\n\n  \n    \n      \n      No\n      X1 transaction date\n      X2 house age\n      X3 distance to the nearest MRT station\n      X4 number of convenience stores\n      X5 latitude\n      X6 longitude\n      Y house price of unit area\n    \n  \n  \n    \n      0\n      1\n      2012.917\n      32.0\n      84.87882\n      10\n      24.98298\n      121.54024\n      37.9\n    \n    \n      1\n      2\n      2012.917\n      19.5\n      306.59470\n      9\n      24.98034\n      121.53951\n      42.2\n    \n    \n      2\n      3\n      2013.583\n      13.3\n      561.98450\n      5\n      24.98746\n      121.54391\n      47.3\n    \n    \n      3\n      4\n      2013.500\n      13.3\n      561.98450\n      5\n      24.98746\n      121.54391\n      54.8\n    \n    \n      4\n      5\n      2012.833\n      5.0\n      390.56840\n      5\n      24.97937\n      121.54245\n      43.1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      409\n      410\n      2013.000\n      13.7\n      4082.01500\n      0\n      24.94155\n      121.50381\n      15.4\n    \n    \n      410\n      411\n      2012.667\n      5.6\n      90.45606\n      9\n      24.97433\n      121.54310\n      50.0\n    \n    \n      411\n      412\n      2013.250\n      18.8\n      390.96960\n      7\n      24.97923\n      121.53986\n      40.6\n    \n    \n      412\n      413\n      2013.000\n      8.1\n      104.81010\n      5\n      24.96674\n      121.54067\n      52.5\n    \n    \n      413\n      414\n      2013.500\n      6.5\n      90.45606\n      9\n      24.97433\n      121.54310\n      63.9\n    \n  \n\n414 rows × 8 columns\n\n\n\n\n# Create a scatter plot\nfig = px.scatter(\n    df,\n    x=df[\"X3 distance to the nearest MRT station\"],\n    y=df[\"Y house price of unit area\"],\n    opacity=0.8,\n    color_discrete_sequence=[\"black\"],\n)\n\n# Change chart background color\nfig.update_layout(dict(plot_bgcolor=\"white\"))\n\n# Update axes lines\nfig.update_xaxes(\n    showgrid=True,\n    gridwidth=1,\n    gridcolor=\"lightgrey\",\n    zeroline=True,\n    zerolinewidth=1,\n    zerolinecolor=\"lightgrey\",\n    showline=True,\n    linewidth=1,\n    linecolor=\"black\",\n)\n\nfig.update_yaxes(\n    showgrid=True,\n    gridwidth=1,\n    gridcolor=\"lightgrey\",\n    zeroline=True,\n    zerolinewidth=1,\n    zerolinecolor=\"lightgrey\",\n    showline=True,\n    linewidth=1,\n    linecolor=\"black\",\n)\n\n# Set figure title\nfig.update_layout(\n    title=dict(\n        text=\"House Price Based on Distance from the Nearest MRT\",\n        font=dict(color=\"black\"),\n    )\n)\n\n# Update marker size\nfig.update_traces(marker=dict(size=3))\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n# ------- Select variables -------\n# x values for Linear Regression\nX = df[\"X3 distance to the nearest MRT station\"].values.reshape(\n    -1, 1\n)  # Note, we need X to be a 2D array, hence reshape\n# x values for LOWESS\nx = df[\"X3 distance to the nearest MRT station\"].values\n# y values for both\ny = df[\"Y house price of unit area\"].values\n\n\n# ------- Linear Regression -------\n# Define and fit the model\nmodel1 = LinearRegression()\nLR = model1.fit(X, y)\n\n# Predict a few points with Linear Regression model for the grpah\n# Create 20 evenly spaced points from smallest X to largest X\nx_range = np.linspace(X.min(), X.max(), 20)\n# Predict y values for our set of X values\ny_range = model1.predict(x_range.reshape(-1, 1))\n\n\n# ------- LOWESS -------\n# Generate y_hat values using lowess, try a couple values for hyperparameters\nlowess = sm.nonparametric.lowess\ny_hat1 = lowess(y, x)  # note, default frac=2/3\ny_hat2 = lowess(y, x, frac=1 / 5)\n\n\n\n# Create a scatter plot\nfig = px.scatter(\n    df,\n    x=df[\"X3 distance to the nearest MRT station\"],\n    y=df[\"Y house price of unit area\"],\n    opacity=0.8,\n    color_discrete_sequence=[\"black\"],\n)\n\n# Add the prediction line\nfig.add_traces(\n    go.Scatter(\n        x=x_range, y=y_range, name=\"Linear Regression\", line=dict(color=\"limegreen\")\n    )\n)\nfig.add_traces(\n    go.Scatter(\n        x=y_hat1[:, 0], y=y_hat1[:, 1], name=\"LOWESS, frac=2/3\", line=dict(color=\"red\")\n    )\n)\nfig.add_traces(\n    go.Scatter(\n        x=y_hat2[:, 0],\n        y=y_hat2[:, 1],\n        name=\"LOWESS, frac=1/5\",\n        line=dict(color=\"orange\"),\n    )\n)\n\n# Change chart background color\nfig.update_layout(dict(plot_bgcolor=\"white\"))\n\n# Update axes lines\nfig.update_xaxes(\n    showgrid=True,\n    gridwidth=1,\n    gridcolor=\"lightgrey\",\n    zeroline=True,\n    zerolinewidth=1,\n    zerolinecolor=\"lightgrey\",\n    showline=True,\n    linewidth=1,\n    linecolor=\"black\",\n)\n\nfig.update_yaxes(\n    showgrid=True,\n    gridwidth=1,\n    gridcolor=\"lightgrey\",\n    zeroline=True,\n    zerolinewidth=1,\n    zerolinecolor=\"lightgrey\",\n    showline=True,\n    linewidth=1,\n    linecolor=\"black\",\n)\n\n# Set figure title\nfig.update_layout(\n    title=dict(\n        text=\"House Price Based on Distance from the Nearest MRT with Model Predictions\",\n        font=dict(color=\"black\"),\n    )\n)\n\n# Update marker size\nfig.update_traces(marker=dict(size=3))\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n# ------- Define interploation functions -------\n# Linear - draws a line between the two nearest points and calculates y value based on the slope of that line\nf_linear = interp1d(\n    y_hat1[:, 0],\n    y=y_hat1[:, 1],\n    bounds_error=False,\n    kind=\"linear\",\n    fill_value=\"extrapolate\",\n)\n# Nearest - finds the nearest available point and takes its y value\nf_nearest = interp1d(\n    y_hat1[:, 0],\n    y=y_hat1[:, 1],\n    bounds_error=False,\n    kind=\"nearest\",\n    fill_value=\"extrapolate\",\n)\n\n# Create a new set of points with x values\nxnew = [300, 600, 900, 1200, 1500, 1800, 2100, 6400]\n\n# Find y values based on the two different interpolation methods\nynew_linear = f_linear(xnew)\nynew_nearest = f_nearest(xnew)\n\n# Print results\nprint(ynew_linear)\nprint(ynew_nearest)\n\n[45.17484583 38.88067785 33.63954152 30.70005122 28.90428712 27.31620311\n 26.02059902 11.5419846 ]\n[45.02258129 38.86385487 33.43419447 31.09566559 28.91596696 27.30837281\n 26.0121316  11.55394747]"
  },
  {
    "objectID": "contents/alt_plots.html",
    "href": "contents/alt_plots.html",
    "title": "Alternative plots",
    "section": "",
    "text": "alternatives: plotly, seaborn\n\n\n\nimport plotly.express as px\n\npx.scatter(mpg, x=\"displ\", y=\"hwy\", color=\"drv\", trendline=\"lowess\")\n\n\n                                                \n\n\n다음과 같이 smoothing parameter를 지정할 수 있음\n자세한 옵션은 여기 참조: plotly linear fits\n\n(\n    px.scatter(mpg, x=\"displ\", y=\"hwy\", color=\"drv\", \n               trendline=\"lowess\", trendline_options=dict(frac=0.3)) # smoothing parameter \n    .update_layout(width=600, height=500)\n)\n\n\n                                                \n\n\n\n(\n    px.scatter(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\",\n               trendline=\"lowess\", trendline_options=dict(frac=0.5),\n               facet_col=\"island\", # faceting\n               opacity=0.5) # alpha\n    .update_layout(width=900, height=400)\n)\n\n\n                                                \n\n\n\n\n\n\n\nsns.lmplot(mpg, x=\"displ\", y=\"hwy\", hue=\"drv\", # color대신 hue\n           lowess=True, \n           scatter_kws={\"alpha\":.5, \"s\":20}, # s: point size\n           height=3, aspect=5/3) \nplt.show() # 생략해도 무방\n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\")\n\nsns.lmplot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\", \n           lowess=True, \n           col=\"sex\", # faceting: col, row\n           height=3, scatter_kws={\"alpha\":.5, \"s\":5})\n\n<seaborn.axisgrid.FacetGrid at 0x12fbb6700>"
  },
  {
    "objectID": "contents/eda.html#visualizing-distributions",
    "href": "contents/eda.html#visualizing-distributions",
    "title": "Plots",
    "section": "Visualizing distributions",
    "text": "Visualizing distributions\n분포를 살펴보는데 변수가 연속인지 카테고리인지에 따라 다른 방식\n\nA categorical variable\n\ntips = sns.load_dataset(\"tips\")\ntips.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   total_bill  244 non-null    float64 \n 1   tip         244 non-null    float64 \n 2   sex         244 non-null    category\n 3   smoker      244 non-null    category\n 4   day         244 non-null    category\n 5   time        244 non-null    category\n 6   size        244 non-null    int64   \ndtypes: category(4), float64(2), int64(1)\nmemory usage: 7.4 KB\n\n\n\n(\n    so.Plot(tips, x=\"day\")\n    .add(so.Bar(), so.Count()) # category type의 변수는 순서가 존재. 그렇지 않은 경우 알바벳 순서로 \n)\n\n\n\n\n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\") # load a dataset: penguins\n\n# Species에 inherent order가 없음\n(\n    so.Plot(penguins, x=\"species\")\n    .add(so.Bar(), so.Count())\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n표시 순서를 변경하는 일은 의미있는 플랏을 만드는데 중요\n나중에 좀 더 자세히 다룸\n\n\n\ncl = penguins[\"species\"].value_counts().index.values\n#> array(['Adelie', 'Gentoo', 'Chinstrap'], dtype=object)\n\n(\n    so.Plot(penguins, x=\"species\")\n    .add(so.Bar(), so.Count())\n    .scale(x=so.Nominal(order=cl)) # x축의 카테고리 순서를 변경\n)\n\n\n\n\n\n\n\n\n\n\nA numerical variable\n\n(\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Bars(), so.Hist()) # Histogram\n    # .Bars()는 .Bar()에 비해 연속변수에 더 적합: 얇은 경계선으로 나란히 붙혀서 그려짐\n)\n\n\n\n\n\n\n\n\n\nleft = (\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Bars(), so.Hist(binwidth=100)) # binwidth vs. bins\n)\nright = (\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Bars(), so.Hist(bins=10)) # binwidth vs. bins\n)\n\n\n\n\n\n\n\n\n(a) binwidth=2\n\n\n\n\n\n\n\n(b) bins=5\n\n\n\n\nFigure 5: binwidth vs. bins\n\n\n\n(\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Area(), so.KDE()) # Density plot\n)\n\n\n\n\n\n\n\n\n\n# Density plot: 넓이가 1이 되도록\n(\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Line(), so.KDE(bw_adjust=.2)) # Density bandwidth: binwidth에 대응\n    .add(so.Bars(alpha=.3), so.Hist(\"density\")) # y축이 count가 아니 density\n)"
  },
  {
    "objectID": "contents/eda.html#visualizing-relationships",
    "href": "contents/eda.html#visualizing-relationships",
    "title": "Plots",
    "section": "Visualizing relationships",
    "text": "Visualizing relationships\n\nA numerical and a categorical variable\nboxplot, frequency polygon, density plot\nBoxplot\n\nsource: R for Data Science\n\nsns.boxplot(penguins, x=\"species\", y=\"body_mass_g\")\nplt.show() # 생략해도 무방\n\n\n\n\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"species\", y=\"body_mass_g\")\n    .add(so.Dots(), so.Jitter())\n    .add(so.Range(color=\"orangered\"), so.Est(errorbar=\"sd\"))\n    .add(so.Dot(pointsize=8, color=\"orangered\"), so.Agg())\n)\n\n\n\n\n\n\n\n\nFrequency polygon\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", color=\"species\")\n    .add(so.Line(marker=\".\"), so.Hist(binwidth=200))\n)\n\n\n\n\n\n\n\n\nGrouped density plot\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", color=\"species\")\n    .add(so.Area(), so.KDE(common_norm=[\"color\"])) # Density plot, species별로 넓이가 1이 되도록\n)\n\n\n\n\n\n\n\n\n\n\nTwo categorical variables\n\np = so.Plot(penguins, x=\"island\", color=\"species\")\np.add(so.Bar(), so.Count()) # Bar() mark + Count() transformation\n\n\n\n\n\n\n\n\n\nleft = p.add(so.Bar(), so.Count(), so.Dodge()) # 나란히 표시\nright = p.add(so.Bar(), so.Count(), so.Stack()) # stacking\n\n\n\n\n\n\n\n\n(a) dodge\n\n\n\n\n\n\n\n(b) stack\n\n\n\n\nFigure 6: dodge vs. stack\n\n\nCount 대신 proportion을 표시하는 경우\n\np.add(\n    so.Bar(width=.5), so.Hist(stat=\"proportion\", common_norm=[\"x\"]), # proportion\n    so.Stack() # stacking\n)\n\n/Users/georgeair/miniconda3/envs/envconda/lib/python3.11/site-packages/seaborn/_stats/counting.py:228: UserWarning: Undefined variable(s) passed for Hist.common_norm: 'x'.\n  self._check_grouping_vars(\"common_norm\", grouping_vars)\n\n\n\n\n\n\n\n\n\n\np.add(\n    so.Bar(width=.8), so.Hist(stat=\"proportion\", common_norm=[\"x\", \"col\"]), # proportion\n    so.Stack(), # stacking\n).facet(col=\"sex\") # faceting\n\n/Users/georgeair/miniconda3/envs/envconda/lib/python3.11/site-packages/seaborn/_stats/counting.py:228: UserWarning: Undefined variable(s) passed for Hist.common_norm: 'x'.\n  self._check_grouping_vars(\"common_norm\", grouping_vars)\n\n\n\n\n\n\n\nTwo numerical variables\nScatterplot\n\n(\n    so.Plot(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\n\n\n\n\nThree or more variables\n\n(\n    so.Plot(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\",\n            color=\"species\", marker=\"island\")\n    .add(so.Dot())\n    .layout(size=(6, 4))\n)\n\n\n\n\nFacet의 활용\n\n(\n    so.Plot(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\",\n            color=\"species\")\n    .add(so.Dot(alpha=.5))\n    .facet(\"island\")\n    .layout(size=(8, 4))\n)\n\n\n\n\n\n\nTime series\n\nhealthexp = sns.load_dataset(\"healthexp\")\n\n(\n    so.Plot(healthexp, x=\"Year\", y=\"Spending_USD\", color=\"Country\")\n    .add(so.Lines())\n)\n\n\n\n\n\n(\n    so.Plot(healthexp, x=\"Year\", y=\"Life_Expectancy\")\n    .add(so.Line(alpha=.3), group=\"Country\", col=None)\n    .add(so.Line(linewidth=3))\n    .facet(\"Country\", wrap=3)\n)\n\n\n\n\n\nfmri = sns.load_dataset(\"fmri\")\np = so.Plot(fmri, \"timepoint\", \"signal\", color=\"region\", linestyle=\"event\")\np.add(so.Line(), so.Agg())\n\n\n\n\n\np.add(so.Line(marker=\"o\", edgecolor=\"w\"), so.Agg(), linestyle=None)"
  },
  {
    "objectID": "contents/alt_plots.html#box-plot",
    "href": "contents/alt_plots.html#box-plot",
    "title": "Alternative plots",
    "section": "Box plot",
    "text": "Box plot\n\npenguins = sns.load_dataset(\"penguins\")\n\n\nimport plotly.express as px\npx.box(penguins.dropna(subset=[\"sex\"]), x=\"species\", y=\"bill_length_mm\", color=\"island\",  facet_col=\"sex\")\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nsns.catplot(\n    data=penguins, x=\"species\", y=\"bill_length_mm\", hue=\"island\", col=\"sex\",\n    kind=\"box\", height=4, aspect=.6,\n)\nplt.show()"
  },
  {
    "objectID": "contents/eda.html#overploting",
    "href": "contents/eda.html#overploting",
    "title": "Plots",
    "section": "Overploting",
    "text": "Overploting\n대표적으로 다음과 같은 방식으로 해결할 수 있음.\nalpha property: 투명도를 조절\n.jitter() mark: 흐트려뜨려 그리기\n.facet() facet: 다른 면에 그리기\n특별히 overplotting에 특화된 plots도 있음. 예를 들어,\n\nsns.catplot(\n    data=penguins, kind=\"swarm\",\n    x=\"species\", y=\"body_mass_g\", hue=\"sex\", col=\"island\",\n    aspect=.6\n)\nplt.show()\n\n\n\n\n\nsns.histplot(penguins, x=\"bill_depth_mm\", y=\"body_mass_g\")\nplt.show()"
  },
  {
    "objectID": "contents/inspection.html#useful-methods",
    "href": "contents/inspection.html#useful-methods",
    "title": "Inspecting data",
    "section": "Useful methods",
    "text": "Useful methods\n.head(), .tail(), .sample()\n.info(), .describe(),\n.value_counts(),\n.sort_values(), .nlargest()\n\nLoading a Dataset: Tips\n일정기간 한 웨이터가 얻은 팁에 대한 데이터\n\ntips = sns.load_dataset(\"tips\")\ntips\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n    \n  \n\n244 rows × 7 columns\n\n\n\n\n# \ntips.values\n\narray([[16.99, 1.01, 'Female', ..., 'Sun', 'Dinner', 2],\n       [10.34, 1.66, 'Male', ..., 'Sun', 'Dinner', 3],\n       [21.01, 3.5, 'Male', ..., 'Sun', 'Dinner', 3],\n       ...,\n       [22.67, 2.0, 'Male', ..., 'Sat', 'Dinner', 2],\n       [17.82, 1.75, 'Male', ..., 'Sat', 'Dinner', 2],\n       [18.78, 3.0, 'Female', ..., 'Thur', 'Dinner', 2]], dtype=object)\n\n\n\ntips.head() # 처음 N개 나열\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n    \n  \n\n\n\n\n\ntips.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   total_bill  244 non-null    float64 \n 1   tip         244 non-null    float64 \n 2   sex         244 non-null    category\n 3   smoker      244 non-null    category\n 4   day         244 non-null    category\n 5   time        244 non-null    category\n 6   size        244 non-null    int64   \ndtypes: category(4), float64(2), int64(1)\nmemory usage: 7.4 KB\n\n\n\ntips.describe() # numerical type만 나열\n\n\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      size\n    \n  \n  \n    \n      count\n      244.00\n      244.00\n      244.00\n    \n    \n      mean\n      19.79\n      3.00\n      2.57\n    \n    \n      std\n      8.90\n      1.38\n      0.95\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      50%\n      17.80\n      2.90\n      2.00\n    \n    \n      75%\n      24.13\n      3.56\n      3.00\n    \n    \n      max\n      50.81\n      10.00\n      6.00\n    \n  \n\n8 rows × 3 columns\n\n\n\n\n\n\ntips.describe(include=\"all\") # all types 나열\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      count\n      244.00\n      244.00\n      244\n      244\n      244\n      244\n      244.00\n    \n    \n      unique\n      NaN\n      NaN\n      2\n      2\n      4\n      2\n      NaN\n    \n    \n      top\n      NaN\n      NaN\n      Male\n      No\n      Sat\n      Dinner\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      50%\n      17.80\n      2.90\n      NaN\n      NaN\n      NaN\n      NaN\n      2.00\n    \n    \n      75%\n      24.13\n      3.56\n      NaN\n      NaN\n      NaN\n      NaN\n      3.00\n    \n    \n      max\n      50.81\n      10.00\n      NaN\n      NaN\n      NaN\n      NaN\n      6.00\n    \n  \n\n11 rows × 7 columns\n\n\n\n\ntips.describe(include=\"category\")\n\n\n\n\n\n\n\n  \n    \n      \n      sex\n      smoker\n      day\n      time\n    \n  \n  \n    \n      count\n      244\n      244\n      244\n      244\n    \n    \n      unique\n      2\n      2\n      4\n      2\n    \n    \n      top\n      Male\n      No\n      Sat\n      Dinner\n    \n    \n      freq\n      157\n      151\n      87\n      176\n    \n  \n\n\n\n\n\n\n\ns1 = tips[\"day\"].value_counts() # \"day\" 칼럼을 선택 후 각 카테고리별 counts\ns2 = tips[\"day\"].value_counts(normalize=True) # 카테고리별 비율\n\ns3 = tips[[\"sex\", \"smoker\"]].value_counts() # \"sex\", \"smoker\" 칼럼을 선택 후 유니크한 카테고리별 counts\n\n\ndisplay(s1); display(s2)\ndisplay(s3)\n\n\n\nSat     87\nSun     76\nThur    62\nFri     19\nName: day, dtype: int64\n\n\nSat    0.36\nSun    0.31\nThur   0.25\nFri    0.08\nName: day, dtype: float64\n\n\n\n\nsex     smoker\nMale    No        97\n        Yes       60\nFemale  No        54\n        Yes       33\ndtype: int64\n\n\n\n\n\n\n\nLoading a Dataset: Penguins\n\npenguins = sns.load_dataset(\"penguins\")\npenguins\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.10\n      18.70\n      181.00\n      3750.00\n      Male\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.50\n      17.40\n      186.00\n      3800.00\n      Female\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.30\n      18.00\n      195.00\n      3250.00\n      Female\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      341\n      Gentoo\n      Biscoe\n      50.40\n      15.70\n      222.00\n      5750.00\n      Male\n    \n    \n      342\n      Gentoo\n      Biscoe\n      45.20\n      14.80\n      212.00\n      5200.00\n      Female\n    \n    \n      343\n      Gentoo\n      Biscoe\n      49.90\n      16.10\n      213.00\n      5400.00\n      Male\n    \n  \n\n344 rows × 7 columns\n\n\n\n\npenguins.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 344 entries, 0 to 343\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \ndtypes: float64(4), object(3)\nmemory usage: 18.9+ KB\n\n\n\npenguins.describe(include=\"object\")\n\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      sex\n    \n  \n  \n    \n      count\n      344\n      344\n      333\n    \n    \n      unique\n      3\n      3\n      2\n    \n    \n      top\n      Adelie\n      Biscoe\n      Male\n    \n    \n      freq\n      152\n      168\n      168\n    \n  \n\n\n\n\n\n\n\npenguins[[\"island\", \"species\"]].value_counts()\n\nisland     species  \nBiscoe     Gentoo       124\nDream      Chinstrap     68\n           Adelie        56\nTorgersen  Adelie        52\nBiscoe     Adelie        44\ndtype: int64\n\n\n\npenguins[[\"sex\", \"species\"]].value_counts(dropna=False) # NaN은 기본적으로 생략\n\nsex     species  \nFemale  Adelie       73\nMale    Adelie       73\n        Gentoo       61\n                     ..\n        Chinstrap    34\nNaN     Adelie        6\n        Gentoo        5\nLength: 8, dtype: int64\n\n\n\ns1 = tips[\"total_bill\"]\ns2 = tips[\"tip\"]\n\npd.DataFrame([s1, s2]).T.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n    \n    \n      1\n      10.34\n      1.66\n    \n    \n      2\n      21.01\n      3.50\n    \n    \n      3\n      23.68\n      3.31\n    \n    \n      4\n      24.59\n      3.61"
  },
  {
    "objectID": "contents/pandas.html#pandas",
    "href": "contents/pandas.html#pandas",
    "title": "NumPy and pandas",
    "section": "pandas",
    "text": "pandas\nSeries & DataFrame\n\nSeries\n1개의 칼럼으로 이루어진 데이터 포멧 - DataFrame의 각 칼럼들을 Series로 이해할 수 있음\n\nSource: Practical Data Science\n\n\nDataFrame\n각 칼럼들이 한 가지 데이터 타입으로 이루어진 tabular형태 (2차원)의 데이터 포맷\n\n각 칼럼은 기본적으로 한 가지 데이터 타입인 것이 이상적이나, 다른 타입이 섞여 있을 수 있음\nNumPy의 2차원 array의 각 칼럼에 labels을 부여한 것으로 볼 수도 있으나, 여러 다른 기능들이 추가됨\nNumPy의 경우 고차원의 array를 다룰 수 있음: ndarray\n\n고차원의 DataFrame과 비슷한 것은 xarray가 존재\n\nLabels와 index를 제외한 데이터 값은 거의 NumPy ndarray로 볼 수 있음\n(pandas.array 존재)\n\n\nSource: Practical Data Science\n\n\nndarray <> DataFrame\n\ndf = pd.DataFrame(A, columns=[\"A1\", \"A2\"])\ndf\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n      A2\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n    \n    \n      2\n      5\n      6\n    \n  \n\n\n\n\n\n\n\n# 데이터 값들은 NumPy array\ndf.values # 또는 df.to_numpy()\n\narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n\n\ntype(df)\n\npandas.core.frame.DataFrame\n\n\n\n\nColumns\nSeries로 추출\n\ns = df[\"A1\"] # A1 칼럼 선택\ns\n# DataFrame의 column 이름이 Series의 name으로 전환\n\n0    1\n1    3\n2    5\nName: A1, dtype: int64\n\n\n\ntype(s)\n\npandas.core.series.Series\n\n\n\n\n\n\n\n\nA DataFrame with a single column\n\n\n\n\n\ndf[[\"A1\"]] # double brackets\n\n\n\n\n\n\n\n\n\nIndex objects\n\nframe = pd.DataFrame(np.arange(6).reshape((2, 3)),\n                     index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n                     columns=pd.Index([\"one\", \"two\", \"three\"], name=\"number\"))\nframe\n\n\n\n\n\n\n\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Ohio\n      0\n      1\n      2\n    \n    \n      Colorado\n      3\n      4\n      5\n    \n  \n\n\n\n\n\n\n\nframe.index\n\nIndex(['Ohio', 'Colorado'], dtype='object', name='state')\n\n\n\nframe.columns # columns도 index object\n\nIndex(['one', 'two', 'three'], dtype='object', name='number')\n\n\n\n\n\n\n\n\nNote\n\n\n\n“number”: columns의 이름 “state”: index의 이름\nframe.columns.name #> ‘number’\nframe.index.name #> ‘state’\n\n\n\nMulti-Index ojbect\nIndex는 여러 levels을 지닐 수 있음\n\nframe.stack() # stack()은 long form으로 변환\n# 2 levels의 index를 가진 Series\n\nstate     number\nOhio      one       0\n          two       1\n          three     2\nColorado  one       3\n          two       4\n          three     5\ndtype: int64\n\n\n\n# MultiIndex를 직접 구성\npd.DataFrame(np.arange(12).reshape((4, 3)),\n        index=pd.MultiIndex.from_arrays([[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]], names=[\"idx1\", \"idx2\"]),\n        columns=pd.MultiIndex.from_arrays([[\"Ohio\", \"Ohio\", \"Colorado\"], [\"Green\", \"Red\", \"Green\"]], names=[\"state\", \"color\"]))\n\n\n\n\n\n\n\n  \n    \n      \n      state\n      Ohio\n      Colorado\n    \n    \n      \n      color\n      Green\n      Red\n      Green\n    \n    \n      idx1\n      idx2\n      \n      \n      \n    \n  \n  \n    \n      a\n      1\n      0\n      1\n      2\n    \n    \n      2\n      3\n      4\n      5\n    \n    \n      b\n      1\n      6\n      7\n      8\n    \n    \n      2\n      9\n      10\n      11\n    \n  \n\n\n\n\n\n\n\n\nTime Series\nIndex는 times series에 특화\n\nfb = pd.read_csv('data/fb_stock_prices_2018.csv', index_col='date', parse_dates=True)\nfb.head()\n\n\n\n\n\n  \n    \n      \n      open\n      high\n      low\n      close\n      volume\n    \n    \n      date\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2018-01-02\n      177.68\n      181.58\n      177.55\n      181.42\n      18151903\n    \n    \n      2018-01-03\n      181.88\n      184.78\n      181.33\n      184.67\n      16886563\n    \n    \n      2018-01-04\n      184.90\n      186.21\n      184.10\n      184.33\n      13880896\n    \n    \n      2018-01-05\n      185.59\n      186.90\n      184.93\n      186.85\n      13574535\n    \n    \n      2018-01-08\n      187.20\n      188.90\n      186.33\n      188.28\n      17994726\n    \n  \n\n\n\n\n\nfb.plot(kind='line', y=['high', 'low'], figsize=(7, 4), title='Facebook Stock 2018')\nplt.show()\n\n\n\n\nindex없이 분석 가능?\nindex의 활용은 강의 후반부에…\nIndex를 column으로 전환시켜 분석할 수 있음\n\nfb.reset_index()\n\n\n\n\n\n  \n    \n      \n      date\n      open\n      high\n      low\n      close\n      volume\n    \n  \n  \n    \n      0\n      2018-01-02\n      177.68\n      181.58\n      177.55\n      181.42\n      18151903\n    \n    \n      1\n      2018-01-03\n      181.88\n      184.78\n      181.33\n      184.67\n      16886563\n    \n    \n      2\n      2018-01-04\n      184.90\n      186.21\n      184.10\n      184.33\n      13880896\n    \n    \n      3\n      2018-01-05\n      185.59\n      186.90\n      184.93\n      186.85\n      13574535\n    \n    \n      4\n      2018-01-08\n      187.20\n      188.90\n      186.33\n      188.28\n      17994726\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      246\n      2018-12-24\n      123.10\n      129.74\n      123.02\n      124.06\n      22066002\n    \n    \n      247\n      2018-12-26\n      126.00\n      134.24\n      125.89\n      134.18\n      39723370\n    \n    \n      248\n      2018-12-27\n      132.44\n      134.99\n      129.67\n      134.52\n      31202509\n    \n    \n      249\n      2018-12-28\n      135.34\n      135.92\n      132.20\n      133.20\n      22627569\n    \n    \n      250\n      2018-12-31\n      134.45\n      134.64\n      129.95\n      131.09\n      24625308\n    \n  \n\n251 rows × 6 columns\n\n\n\n\n\n\n\n\nDataFrame의 연산\nNumPy의 ndarray들이 연산되는 방식과 동일하게 series나 DataFrame들의 연산 가능함\n\ndf + 2 * df\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n      A2\n    \n  \n  \n    \n      0\n      3\n      6\n    \n    \n      1\n      9\n      12\n    \n    \n      2\n      15\n      18\n    \n  \n\n\n\n\n\n\n\nnp.log(df)\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n      A2\n    \n  \n  \n    \n      0\n      0.00\n      0.69\n    \n    \n      1\n      1.10\n      1.39\n    \n    \n      2\n      1.61\n      1.79\n    \n  \n\n\n\n\n\n\n사실 연산은 index를 align해서 시행됨\n\n\n\n\n\n\nframe1\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Ohio\n      0\n      1\n      2\n    \n    \n      Colorado\n      3\n      4\n      5\n    \n  \n\n\n\n\n\n\n\nframe2\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Ohio\n      0\n      2\n      4\n    \n    \n      Floria\n      6\n      8\n      10\n    \n  \n\n\n\n\n\n\nframe1 + frame2\n\n\n\n\n\n\n\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Colorado\n      NaN\n      NaN\n      NaN\n    \n    \n      Floria\n      NaN\n      NaN\n      NaN\n    \n    \n      Ohio\n      0.00\n      3.00\n      6.00\n    \n  \n\n\n\n\n\n\n\n(참고) Mixed Data Type\n\ns = pd.Series([1, 2, \"3\"])\n\n\ns.dtype\n\ndtype('O')\n\n\n\ns + s\n\n0     2\n1     4\n2    33\ndtype: object\n\n\n\ns_int = s.astype(\"int\")\ns_int + s_int\n\n0    2\n1    4\n2    6\ndtype: int64\n\n\n\ns2 = pd.Series([1, 2, 3.1])\ns2.dtype\n\ndtype('float64')\n\n\n\ns2.astype(\"int\")\n\n0    1\n1    2\n2    3\ndtype: int64"
  },
  {
    "objectID": "contents/plots.html",
    "href": "contents/plots.html",
    "title": "Plots",
    "section": "",
    "text": "source: R for Data Science\n\nTransform (데이터 변형)\n\n데이터의 변수들 중 일부를 선택하기\n필요한 부분를 필터링하기\n기존의 변수들로 새로운 변수 만들기\n요약자료를 계산하기\n\nVisualise (시각화)\n\n시각화를 통해 데이터가 품고 있는 정보를 파악하여 데이터에 대한 이해를 높임\n\nModel (모형)\n\n시각화와 데이터 변형의 두 가지를 병행하면서 호기심과 의구심을 갖고 연구자가 자신의 관심사에 답을 구하는 탐색적 분석을 하는 과정\n이 과정에서 모형을 세우고 데이터를 얼마나 잘 설명하는지를 살펴보고, 모형을 수정해 나가는 과정을 거침"
  },
  {
    "objectID": "contents/plots.html#first-steps",
    "href": "contents/plots.html#first-steps",
    "title": "Plots",
    "section": "First steps",
    "text": "First steps\n\n\nLoad packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\n\n\nData: Fuel economy data from 1999 to 2008 for 38 popular models of cars\n\n# import the dataset\nmpg_data = sm.datasets.get_rdataset(\"mpg\", \"ggplot2\")\nmpg = mpg_data.data\n\n\n# Description\nprint(mpg_data.__doc__)\n\n\nmpg\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns\n\n\n\nQ: 엔진의 크기(displ)와 연비(hwy)는 어떤 관계에 있는가?\n\n# Scatter plot: 산포도\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\") # empty plot을 생성하고, x, y축에 mapping할 mpg 데이터의 변수를 지정\n    .add(so.Dot()) # layer를 추가하여, points들을 Dot이라는 mark object를 써서 표현\n)\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nLayer-specific mappings\n다음과 같이 첫번째 layer 안에서 x, y를 mapping하는 경우, 이후 새로 추가되는 layer에는 그 mapping이 적용되지 않음\n(\n    so.Plot(mpg)\n    .add(so.Dot(), x=\"displ\", y=\"hwy\") # 이 layer에서만 mapping이 유효\n)\n\n\n\n\n\n\n\n\nTip\n\n\n\n다음과 같이 x, y를 생략하거나 간략히 할 수 있으나…\nso.Plot(mpg, \"displ\", \"hwy\").add(so.Dot())\n\n\n\n카테고리 변수인 경우\n\ncyl (실린더 개수), hwy (고속도로 연비)의 관계를 scatterplot으로 살펴볼 수 있는가? (left)\nclass (차량 타입), drv (전륜 구동, 후륜 구동, 4륜 구동 타입)의 관계는 어떠한가? (right)"
  },
  {
    "objectID": "contents/plots.html#aesthetic-mappings",
    "href": "contents/plots.html#aesthetic-mappings",
    "title": "Plots",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\nQ: 엔진의 크기와 연비와의 관계에서 보이는 트렌드 라인에서 심하게 벗어난 것이 있는가?\n\n\n\n\n\n 변수들을 x, y라는 position에 mapping하는 것에 추가하여 다음과 같은 속성(aesthetic)에 mapping할 수 있음\n색(color), 크기(pointsize), 모양(marker), 선 종류(linestyle), 투명도(alpha)\n\n\nColor\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nPointsize\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", pointsize=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nMarker\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", marker=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nAlpha\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", alpha=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nLinestyle\n\nhealthexp = sns.load_dataset(\"healthexp\")\n\np = so.Plot(healthexp, x=\"Spending_USD\", y=\"Life_Expectancy\", linestyle=\"Country\")\np.add(so.Line())\n\n\n\n\n\n\n두 가지 이상의 속성\nex. color & marker\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\", marker=\"drv\")\n    .add(so.Dot())\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\", pointsize=\"drv\")\n    .add(so.Dot())\n    .scale(pointsize=(5, 15)) # pointsize의 range설정\n)\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n어떤 속성을 어떤 변수에 할당하는 것이 적절한지를 선택하는 것이 기술\n예를 들어, 아래 두 플랏은 동일한 정보를 품고 있으나, 시각적 인식에 큰 차이를 만듦\n\n\n\n\n\n\n\n\n\n\n\n\n연속 vs. 카테고리 변수 여부에 따라 다르게 작동\n\nleft = so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\").add(so.Dot()).layout(engine=\"constrained\")\n\nright = so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"cty\").add(so.Dot()).layout(engine=\"constrained\")\n\n\n\n\n\n\n\n\n(a) type of car\n\n\n\n\n\n\n\n(b) city miles per gallon\n\n\n\n\nFigure 1: Categorical vs. Continuous\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"cty\")\n    .add(so.Dot())\n    .scale(color=so.Continuous(\"crest\", norm=(0, 50), trans=\"sqrt\"))\n)"
  },
  {
    "objectID": "contents/plots.html#setting-properties",
    "href": "contents/plots.html#setting-properties",
    "title": "Plots",
    "section": "Setting properties",
    "text": "Setting properties\nSetting properties vs. mapping properties (aesthetic)\n\n변수에 속성을 할당하는 것이 아니라, graphical objects (Marks)의 속성을 지정\nMarks (.Dot, .Line, .Bar, …) 마다 설정할 수 있는 속성이 다름\n주로 쓰이는 속성들: color, pointsize, alpha\n\n.Dot()의 경우\nclass seaborn.objects.Dot(artist_kws=, marker=<‘o’>, pointsize=<6>, stroke=<0.75>, color=<‘C0’>, alpha=<1>, fill=, edgecolor=, edgealpha=, edgewidth=<0.5>, edgestyle=<‘-’>)\n.Dots()의 경우\nclass seaborn.objects.Dots(artist_kws=, marker=<rc:scatter.marker>, pointsize=<4>, stroke=<0.75>, color=<‘C0’>, alpha=<1>, fill=, fillcolor=, fillalpha=<0.2>)\nAPI reference 참고\n\n\n\n\n\n\n\nTip\n\n\n\n다양한 Mark properties에 대해서는 홈페이지 참고\nProperties of Mark objects\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\"deepskyblue\")) # Mark object 안에 지정!\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\"deepskyblue\", pointsize=12, edgecolor=\"white\", edgewidth=1)) # Mark object 안에 지정!\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\"orange\", pointsize=12, marker=\">\", alpha=.4)) # Mark object 안에 지정!\n)"
  },
  {
    "objectID": "contents/plots.html#faceting",
    "href": "contents/plots.html#faceting",
    "title": "Plots",
    "section": "Faceting",
    "text": "Faceting\n카테고리 변수들이 지니는 카테고리들(레벨)로 나누어 그리기\nData: palmerpenguins\n\n\n\n Artwork by @allison_horst\n\n\n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\") # load a dataset: penguins\npenguins.head()\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      Male\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      Female\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      Female\n    \n    \n      3\n      Adelie\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      Adelie\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      Female\n    \n  \n\n\n\n\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .facet(\"sex\") # 기본적으로 columns으로 나누어져 그림\n    .add(so.Dot(alpha=.5))\n)\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .facet(col=\"species\", row=\"sex\")\n    .add(so.Dot(alpha=.5))\n)\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFacet과 Color 중 어떤 방식으로 표현하는 것이 유리한가? 밸런스를 잘 선택!\n\n\n\nleft = (\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .facet(col=\"species\")\n    .add(so.Dot(alpha=.5))\n)\nright = (\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\", color=\"species\")\n    .add(so.Dot(alpha=.5))\n)\n\n\n\n\n\n\n\n\n(a) faceting\n\n\n\n\n\n\n\n(b) color mapping\n\n\n\n\nFigure 2: faceting vs. color mapping\n\n\n\nPairing\nFaceting이 변수 내에 다른 레벨에 따라 그려지는데 반해,\nparing은 x, y축에 다른 변수를 지정하여 그림\n\n(\n    so.Plot(penguins, y=\"body_mass_g\", color=\"species\") # y축은 공유\n    .pair(x=[\"bill_length_mm\", \"bill_depth_mm\"]) # x축에 다른 변수를 mapping\n    .add(so.Dots()) # .Dots()! overploting에 유리. .Dot(alpha=.)로도 비슷\n)\n\n\n\n\nFacet & pair 동시\n\n(\n    so.Plot(penguins, y=\"body_mass_g\", color=\"sex\")\n    .pair(x=[\"bill_length_mm\", \"bill_depth_mm\"])\n    .facet(row=\"species\")\n    .add(so.Dots())\n)\n\n\n\n\n\n\nMultiple plots\n개발 중…? Matplotlib을 이용\n\nimport matplotlib as mpl\n\nf = mpl.figure.Figure(figsize=(8, 4))\nsf1, sf2 = f.subfigures(1, 2)\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .add(so.Dots())\n    .on(sf1)\n    .plot()\n)\n(\n    so.Plot(penguins, x=\"bill_length_mm\", y=\"flipper_length_mm\")\n    .facet(row=\"sex\")\n    .add(so.Dots())\n    .on(sf2)\n    .plot()\n)\n\n\n\n\nSave plots\np.save(\"data/filename.png\") # p: a plot oject"
  },
  {
    "objectID": "contents/plots.html#geometric-objects",
    "href": "contents/plots.html#geometric-objects",
    "title": "Plots",
    "section": "Geometric objects",
    "text": "Geometric objects\n\nDot marks: Dot, Dots\nLine marks: Line, Lines, Path, Paths, Dash, Range\nBar marks: Bar, Bars\nFill marks: Area, Band\nText marks: Text"
  },
  {
    "objectID": "contents/plots.html#statistical-transformations",
    "href": "contents/plots.html#statistical-transformations",
    "title": "Plots",
    "section": "Statistical transformations",
    "text": "Statistical transformations\nAgg, Est, Count, Hist, KDE, Perc, PolyFit\n\n\n\n\n\n\nImportant\n\n\n\n위의 stats transform들을 이용하여 변형된 데이터 값을 geometric objects에 mapping하여 다양한 플랏을 그릴 수 있음\n원칙적으로는 직접 stats을 계산한 후에 그 데이터로 플랏을 그릴 수 있으나, 신속한 탐색적 분석을 위해 사용\n\n\n\n\n\n\n\n\nNote\n\n\n\n현재 seaborn.objects에서 다음 두 가지 중요한 statistical transformations이 제공되지 않고 있음\n\n(non-parametirc) fitted line을 보여주는 loess or GAM line\n분포의 간략한 summary인 boxplot\n\n이 부분에 대해서는 아래 몇 가지 대안이 있음: 그외에는 alternative plots 섹션 참고\n\n\n\n\n\n\n\n\nNote\n\n\n\nData에 fitted curve를 구하는 방식에는 여러 방법이 있음\n\nLinear fit: 1차 함수형태로 fit\nSmoothing fit\n\nPolynominal fit: n차 다항함수형태로 fit\nLoess/lowess: locally estimated/weighted scatterplot smoothing\nGAM: generalized additive model\nSpine: piece-wise polynominal regression\n\n\n나중에 좀 더 자세히 알아봄\n현재 seaborn.objects에서는 polynomial fit만 제공\n\n\n\nFitted lines\nseaborn.objects\n\nleft = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot())\n    .add(so.Line(), so.PolyFit(5)) # PolyFit(n): n차 다항식으로 fit\n)\n\nright = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Line(), so.PolyFit(5)) # PolyFit(n): n차 다항식으로 fit\n)\n\n\n\n\n\n\n\n\n(a) Scatterplot + trendline\n\n\n\n\n\n\n\n(b) Trendline only\n\n\n\n\nFigure 3: 데이터로부터 계산을 한 후 플랏이 그려짐\n\n\n\nleft = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"drv\") # color mapping이 이후 모든 layer에 적용\n    .add(so.Dot())\n    .add(so.Line(), so.PolyFit(5))\n)\n\nright = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(), color=\"drv\") # color mapping이 이 layer에만 적용\n    .add(so.Line(), so.PolyFit(5))\n)\n\n\n\n\n\n\n\n\n(a) color가 모든 layers에 적용: global mapping\n\n\n\n\n\n\n\n(b) color가 두번째 layer에만 적용: local mapping\n\n\n\n\nFigure 4: Inherited mapping\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(), color=\"drv\")\n    .add(so.Line(), so.PolyFit(5), group=\"drv\") # color가 아닌 group으로 grouping\n)\n\n\n\n\nLinear fit vs. smoothing fit:\n선형적인 트렌드에서 얼마나 벗어나는가?\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\".6\"))\n    .add(so.Line(), so.PolyFit(5))\n    .add(so.Line(), so.PolyFit(1))\n)\n\n\n\n\n다른 대안으로는 plotly, seaborn: alternative plots 섹션 참고\n\n\nAggregation"
  },
  {
    "objectID": "contents/plots.html#visualizing-distributions",
    "href": "contents/plots.html#visualizing-distributions",
    "title": "Plots",
    "section": "Visualizing distributions",
    "text": "Visualizing distributions\n분포를 살펴보는데 변수가 연속인지 카테고리인지에 따라 다른 방식\n\nA categorical variable\n\ntips = sns.load_dataset(\"tips\")\ntips.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   total_bill  244 non-null    float64 \n 1   tip         244 non-null    float64 \n 2   sex         244 non-null    category\n 3   smoker      244 non-null    category\n 4   day         244 non-null    category\n 5   time        244 non-null    category\n 6   size        244 non-null    int64   \ndtypes: category(4), float64(2), int64(1)\nmemory usage: 7.4 KB\n\n\n\n(\n    so.Plot(tips, x=\"day\")\n    .add(so.Bar(), so.Count()) # category type의 변수는 순서가 존재. 그렇지 않은 경우 알바벳 순서로 \n)\n\n\n\n\n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\") # load a dataset: penguins\n\n# Species에 inherent order가 없음\n(\n    so.Plot(penguins, x=\"species\")\n    .add(so.Bar(), so.Count())\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n표시 순서를 변경하는 일은 의미있는 플랏을 만드는데 중요\n나중에 좀 더 자세히 다룸\n\n\n\ncl = penguins[\"species\"].value_counts().index.values\n#> array(['Adelie', 'Gentoo', 'Chinstrap'], dtype=object)\n\n(\n    so.Plot(penguins, x=\"species\")\n    .add(so.Bar(), so.Count())\n    .scale(x=so.Nominal(order=cl)) # x축의 카테고리 순서를 변경\n)\n\n\n\n\n\n\n\n\n\n\nA numerical variable\n\n(\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Bars(), so.Hist()) # Histogram\n    # .Bars()는 .Bar()에 비해 연속변수에 더 적합: 얇은 경계선으로 나란히 붙혀서 그려짐\n)\n\n\n\n\n\n\n\n\n\nleft = (\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Bars(), so.Hist(binwidth=100)) # binwidth vs. bins\n)\nright = (\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Bars(), so.Hist(bins=10)) # binwidth vs. bins\n)\n\n\n\n\n\n\n\n\n(a) binwidth=2\n\n\n\n\n\n\n\n(b) bins=5\n\n\n\n\nFigure 5: binwidth vs. bins\n\n\n\n(\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Area(), so.KDE()) # Density plot\n)\n\n\n\n\n\n\n\n\n\n# Density plot: 넓이가 1이 되도록\n(\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Line(), so.KDE(bw_adjust=.2)) # Density bandwidth: binwidth에 대응\n    .add(so.Bars(alpha=.3), so.Hist(\"density\")) # y축이 count가 아니 density\n)"
  },
  {
    "objectID": "contents/plots.html#visualizing-relationships",
    "href": "contents/plots.html#visualizing-relationships",
    "title": "Plots",
    "section": "Visualizing relationships",
    "text": "Visualizing relationships\n\nA numerical and a categorical variable\nboxplot, frequency polygon, density plot\nBoxplot\n\nsource: R for Data Science\n\nsns.boxplot(penguins, x=\"species\", y=\"body_mass_g\")\nplt.show() # 생략해도 무방\n\n\n\n\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"species\", y=\"body_mass_g\")\n    .add(so.Dots(color=\".5\"), so.Jitter()) # .Jitter(): 흐트려뜨려 그리기\n    .add(so.Dot(pointsize=8), so.Agg(\"median\")) # .Agg(): aggregation, default는 mean\n    .add(so.Range(), so.Est(\"median\", errorbar=(\"pi\", 50))) # .Range(): 기본 min/max range, .Est(): estimator\n)\n\n\n\n\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"species\", y=\"body_mass_g\", color=\"sex\")\n    .add(so.Dots(), so.Jitter(), so.Dodge())\n    .add(so.Dot(pointsize=5), so.Agg(\"median\"), so.Dodge())\n    .add(so.Range(), so.Est(\"median\", errorbar=(\"pi\", 50)), so.Dodge())\n)\n\n\n\n\n\nsns.boxplot(penguins, x=\"species\", y=\"body_mass_g\", hue=\"sex\")\nplt.show() # 생략해도 무방\n\n\n\n\n\n\n\n\nFrequency polygon\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", color=\"species\")\n    .add(so.Line(marker=\".\"), so.Hist(binwidth=200)) # Line에 maker \".\"을 표시\n)\n\n\n\n\n\n\n\n\nGrouped density plot\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", color=\"species\")\n    .add(so.Area(), so.KDE(common_norm=[\"color\"])) # Density plot, species별로 넓이가 1이 되도록\n)\n\n\n\n\n\n\n\n\n\n\nTwo categorical variables\n\np = so.Plot(penguins, x=\"island\", color=\"species\")\np.add(so.Bar(), so.Count()) # Bar() mark + Count() transformation\n\n\n\n\n\n\n\n\n\nleft = p.add(so.Bar(), so.Count(), so.Dodge()) # 나란히 표시\nright = p.add(so.Bar(), so.Count(), so.Stack()) # stacking\n\n\n\n\n\n\n\n\n(a) dodge\n\n\n\n\n\n\n\n(b) stack\n\n\n\n\nFigure 6: dodge vs. stack\n\n\nCount 대신 proportion을 표시하는 경우\n\np.add(\n    so.Bar(width=.5), so.Hist(stat=\"proportion\", common_norm=[\"x\"]), # proportion\n    so.Stack() # stacking\n)\n\n/Users/georgeair/miniconda3/envs/envconda/lib/python3.11/site-packages/seaborn/_stats/counting.py:228: UserWarning: Undefined variable(s) passed for Hist.common_norm: 'x'.\n  self._check_grouping_vars(\"common_norm\", grouping_vars)\n\n\n\n\n\n\n\n\n\n\np.add(\n    so.Bar(width=.8), so.Hist(stat=\"proportion\", common_norm=[\"x\", \"col\"]), # proportion\n    so.Stack(), # stacking\n).facet(col=\"sex\") # faceting\n\n/Users/georgeair/miniconda3/envs/envconda/lib/python3.11/site-packages/seaborn/_stats/counting.py:228: UserWarning: Undefined variable(s) passed for Hist.common_norm: 'x'.\n  self._check_grouping_vars(\"common_norm\", grouping_vars)\n\n\n\n\n\n\n\nTwo numerical variables\nScatterplot\n\n(\n    so.Plot(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\n\n\n\n\nThree or more variables\n\n(\n    so.Plot(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\",\n            color=\"species\", marker=\"island\")\n    .add(so.Dot())\n    .layout(size=(6, 4))\n)\n\n\n\n\nFacet의 활용\n\n(\n    so.Plot(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\",\n            color=\"species\")\n    .add(so.Dot(alpha=.5))\n    .facet(\"island\")\n    .layout(size=(8, 4))\n)\n\n\n\n\n\n\nTime series\n\nhealthexp = sns.load_dataset(\"healthexp\")\n\n(\n    so.Plot(healthexp, x=\"Year\", y=\"Spending_USD\", color=\"Country\")\n    .add(so.Lines())\n)\n\n\n\n\n\n(\n    so.Plot(healthexp, x=\"Year\", y=\"Life_Expectancy\")\n    .add(so.Line(alpha=.3), group=\"Country\", col=None)\n    .add(so.Line(linewidth=3))\n    .facet(\"Country\", wrap=3)\n)\n\n\n\n\n\nfmri = sns.load_dataset(\"fmri\")\np = so.Plot(fmri, \"timepoint\", \"signal\", color=\"region\", linestyle=\"event\")\np.add(so.Line(), so.Agg())\n\n\n\n\n\np.add(so.Line(marker=\"o\", edgecolor=\"w\"), so.Agg(), linestyle=None)"
  },
  {
    "objectID": "contents/plots.html#overploting",
    "href": "contents/plots.html#overploting",
    "title": "Plots",
    "section": "Overploting",
    "text": "Overploting\n대표적으로 다음과 같은 방식으로 해결할 수 있음.\nalpha property: 투명도를 조절\n.jitter() mark: 흐트려뜨려 그리기\n.facet() facet: 다른 면에 그리기\n특별히 overplotting에 특화된 plots도 있음. 예를 들어,\n\nsns.catplot(\n    data=penguins, kind=\"swarm\",\n    x=\"species\", y=\"body_mass_g\", hue=\"sex\", col=\"island\",\n    aspect=.6\n)\nplt.show()\n\n\n\n\n\nsns.histplot(penguins, x=\"bill_depth_mm\", y=\"body_mass_g\")\nplt.show()"
  },
  {
    "objectID": "contents/pandas.html#attributes",
    "href": "contents/pandas.html#attributes",
    "title": "NumPy and pandas",
    "section": "Attributes",
    "text": "Attributes\nHere are some commonly used attributes with Series objects:\n\n\n\n\n\n\n\nAttribute\nReturns\n\n\n\n\nname\nThe name of the Series object\n\n\ndtype\nThe data type of the Series object\n\n\nshape\nDimensions of the Series object in a tuple of the form (number of rows,)\n\n\nindex\nThe Index object that is part of the Series object\n\n\nvalues\nThe data in the Series object\n\n\n\nHere are some commonly used attributes with Index objects:\n\n\n\nAttribute\nReturns\n\n\n\n\nname\nThe name of the Index object\n\n\ndtype\nThe data type of the Index object\n\n\nshape\nDimensions of the Index object\n\n\nvalues\nThe data in the Index object\n\n\nis_unique\nCheck if the Index object has all unique values\n\n\n\nHere are some commonly used attributes:\n\n\n\n\n\n\n\nAttribute\nReturns\n\n\n\n\ndtypes\nThe data types of each column\n\n\nshape\nDimensions of the DataFrame object in a tuple of the form (number of rows, number of columns)\n\n\nindex\nThe Index object along the rows of the DataFrame object\n\n\ncolumns\nThe name of the columns (as an Index object)\n\n\nvalues\nThe data in the DataFrame object\n\n\nempty\nCheck if the DataFrame object is empty"
  },
  {
    "objectID": "contents/pandas.html#creating-dataframes",
    "href": "contents/pandas.html#creating-dataframes",
    "title": "NumPy and pandas",
    "section": "Creating DataFrames",
    "text": "Creating DataFrames"
  },
  {
    "objectID": "contents/transform.html",
    "href": "contents/transform.html",
    "title": "Transforming",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\n이번 장에서는 시각화를 하기 전, 중요한 데이터 패턴을 보기 위해서 새로운 변수를 만들거나 요약한 통계치를 만들 필요가 있는데 이를 다루는 핵심적인 함수들에 대해 익힙니다.\n좀 더 자세한 데이터 가공에 대해서는 추후에 다룰 예정입니다.\n대략 다음과 같은 transform들을 조합하여 분석에 필요한 상태로 바꿉니다.\nOn-time data for all flights that departed NYC (i.e. JFK, LGA or EWR) in 2013"
  },
  {
    "objectID": "contents/transform.html#rows",
    "href": "contents/transform.html#rows",
    "title": "Transforming",
    "section": "Rows",
    "text": "Rows\n\nquery()\n\nConditional operators\n>, >=, <, <=, == (equal to), != (not equal to)\n& (and) | (or)\n~ (not)\nin (includes)\n\n\n# Flights that arrived more than 120 minutes (two hours) late\nflights.query('arr_delay > 120')\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      119\n      2013\n      1\n      1\n      811.00\n      630\n      101.00\n      1047.00\n      830\n      137.00\n      MQ\n      4576\n      N531MQ\n      LGA\n      CLT\n      118.00\n      544\n      6\n      30\n    \n    \n      151\n      2013\n      1\n      1\n      848.00\n      1835\n      853.00\n      1001.00\n      1950\n      851.00\n      MQ\n      3944\n      N942MQ\n      JFK\n      BWI\n      41.00\n      184\n      18\n      35\n    \n    \n      218\n      2013\n      1\n      1\n      957.00\n      733\n      144.00\n      1056.00\n      853\n      123.00\n      UA\n      856\n      N534UA\n      EWR\n      BOS\n      37.00\n      200\n      7\n      33\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336724\n      2013\n      9\n      30\n      2053.00\n      1815\n      158.00\n      2310.00\n      2054\n      136.00\n      EV\n      5292\n      N600QX\n      EWR\n      ATL\n      91.00\n      746\n      18\n      15\n    \n    \n      336757\n      2013\n      9\n      30\n      2159.00\n      1845\n      194.00\n      2344.00\n      2030\n      194.00\n      9E\n      3320\n      N906XJ\n      JFK\n      BUF\n      50.00\n      301\n      18\n      45\n    \n    \n      336763\n      2013\n      9\n      30\n      2235.00\n      2001\n      154.00\n      59.00\n      2249\n      130.00\n      B6\n      1083\n      N804JB\n      JFK\n      MCO\n      123.00\n      944\n      20\n      1\n    \n  \n\n10034 rows × 18 columns\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n위의 query 방식의 filtering은 다음과 같은 boolean indexing의 결과와 같음\nflights[flights[\"arr_delay\"] > 120]\n\n\n\n# Flights that departed on January 1\nflights.query('month == 1 & day == 1')  # == 과 = 을 혼동하지 말것!\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n      517.00\n      515\n      2.00\n      830.00\n      819\n      11.00\n      UA\n      1545\n      N14228\n      EWR\n      IAH\n      227.00\n      1400\n      5\n      15\n    \n    \n      1\n      2013\n      1\n      1\n      533.00\n      529\n      4.00\n      850.00\n      830\n      20.00\n      UA\n      1714\n      N24211\n      LGA\n      IAH\n      227.00\n      1416\n      5\n      29\n    \n    \n      2\n      2013\n      1\n      1\n      542.00\n      540\n      2.00\n      923.00\n      850\n      33.00\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.00\n      1089\n      5\n      40\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      839\n      2013\n      1\n      1\n      NaN\n      1935\n      NaN\n      NaN\n      2240\n      NaN\n      AA\n      791\n      N3EHAA\n      LGA\n      DFW\n      NaN\n      1389\n      19\n      35\n    \n    \n      840\n      2013\n      1\n      1\n      NaN\n      1500\n      NaN\n      NaN\n      1825\n      NaN\n      AA\n      1925\n      N3EVAA\n      LGA\n      MIA\n      NaN\n      1096\n      15\n      0\n    \n    \n      841\n      2013\n      1\n      1\n      NaN\n      600\n      NaN\n      NaN\n      901\n      NaN\n      B6\n      125\n      N618JB\n      JFK\n      FLL\n      NaN\n      1069\n      6\n      0\n    \n  \n\n842 rows × 18 columns\n\n\n\n\n# Flights that departed in January or February\nflights.query('month == 1 | month == 2')\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n      517.00\n      515\n      2.00\n      830.00\n      819\n      11.00\n      UA\n      1545\n      N14228\n      EWR\n      IAH\n      227.00\n      1400\n      5\n      15\n    \n    \n      1\n      2013\n      1\n      1\n      533.00\n      529\n      4.00\n      850.00\n      830\n      20.00\n      UA\n      1714\n      N24211\n      LGA\n      IAH\n      227.00\n      1416\n      5\n      29\n    \n    \n      2\n      2013\n      1\n      1\n      542.00\n      540\n      2.00\n      923.00\n      850\n      33.00\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.00\n      1089\n      5\n      40\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      136244\n      2013\n      2\n      28\n      NaN\n      1115\n      NaN\n      NaN\n      1310\n      NaN\n      MQ\n      4485\n      N725MQ\n      LGA\n      CMH\n      NaN\n      479\n      11\n      15\n    \n    \n      136245\n      2013\n      2\n      28\n      NaN\n      830\n      NaN\n      NaN\n      1205\n      NaN\n      UA\n      1480\n      NaN\n      EWR\n      SFO\n      NaN\n      2565\n      8\n      30\n    \n    \n      136246\n      2013\n      2\n      28\n      NaN\n      840\n      NaN\n      NaN\n      1147\n      NaN\n      UA\n      443\n      NaN\n      JFK\n      LAX\n      NaN\n      2475\n      8\n      40\n    \n  \n\n51955 rows × 18 columns\n\n\n\n\n# A shorter way to select flights that departed in January or February\nflights.query('month in [1, 2]')\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n      517.00\n      515\n      2.00\n      830.00\n      819\n      11.00\n      UA\n      1545\n      N14228\n      EWR\n      IAH\n      227.00\n      1400\n      5\n      15\n    \n    \n      1\n      2013\n      1\n      1\n      533.00\n      529\n      4.00\n      850.00\n      830\n      20.00\n      UA\n      1714\n      N24211\n      LGA\n      IAH\n      227.00\n      1416\n      5\n      29\n    \n    \n      2\n      2013\n      1\n      1\n      542.00\n      540\n      2.00\n      923.00\n      850\n      33.00\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.00\n      1089\n      5\n      40\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      136244\n      2013\n      2\n      28\n      NaN\n      1115\n      NaN\n      NaN\n      1310\n      NaN\n      MQ\n      4485\n      N725MQ\n      LGA\n      CMH\n      NaN\n      479\n      11\n      15\n    \n    \n      136245\n      2013\n      2\n      28\n      NaN\n      830\n      NaN\n      NaN\n      1205\n      NaN\n      UA\n      1480\n      NaN\n      EWR\n      SFO\n      NaN\n      2565\n      8\n      30\n    \n    \n      136246\n      2013\n      2\n      28\n      NaN\n      840\n      NaN\n      NaN\n      1147\n      NaN\n      UA\n      443\n      NaN\n      JFK\n      LAX\n      NaN\n      2475\n      8\n      40\n    \n  \n\n51955 rows × 18 columns\n\n\n\n\nflights.query('arr_delay > 120 & ~(origin == \"JFK\")')\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      119\n      2013\n      1\n      1\n      811.00\n      630\n      101.00\n      1047.00\n      830\n      137.00\n      MQ\n      4576\n      N531MQ\n      LGA\n      CLT\n      118.00\n      544\n      6\n      30\n    \n    \n      218\n      2013\n      1\n      1\n      957.00\n      733\n      144.00\n      1056.00\n      853\n      123.00\n      UA\n      856\n      N534UA\n      EWR\n      BOS\n      37.00\n      200\n      7\n      33\n    \n    \n      268\n      2013\n      1\n      1\n      1114.00\n      900\n      134.00\n      1447.00\n      1222\n      145.00\n      UA\n      1086\n      N76502\n      LGA\n      IAH\n      248.00\n      1416\n      9\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336529\n      2013\n      9\n      30\n      1738.00\n      1529\n      129.00\n      1906.00\n      1649\n      137.00\n      EV\n      4580\n      N12563\n      EWR\n      MKE\n      110.00\n      725\n      15\n      29\n    \n    \n      336668\n      2013\n      9\n      30\n      1951.00\n      1649\n      182.00\n      2157.00\n      1903\n      174.00\n      EV\n      4294\n      N13988\n      EWR\n      SAV\n      95.00\n      708\n      16\n      49\n    \n    \n      336724\n      2013\n      9\n      30\n      2053.00\n      1815\n      158.00\n      2310.00\n      2054\n      136.00\n      EV\n      5292\n      N600QX\n      EWR\n      ATL\n      91.00\n      746\n      18\n      15\n    \n  \n\n6868 rows × 18 columns\n\n\n\n\n\n\n\n\n\nquery() 조건의 참거짓에 상관없이 NA값은 모두 제외함\n\n\n\n\n\n# df가 다음과 같을 때,\n#      A     B\n# 0 1.00  2.00\n# 1  NaN  5.00\n# 2 3.00  3.00\n# 3 4.00   NaN\n\ndf.query('A > 1')\n#      A     B\n# 2 3.00  3.00\n# 3 4.00   NaN\n\n# NA를 포함하고자 할 때,\ndf.query('A > 1 | A.isna()') # .isna() : NA인지 여부\n#      A     B\n# 1  NaN  5.00\n# 2 3.00  3.00\n# 3 4.00   NaN\nNA(missing)에 대해서는 뒤에서 자세히\n\n\n\n\n\nsort_values()\n\n# \"year\", \"month\", \"day\", \"dep_time\" 순서대로 내림차순으로 정렬\nflights.sort_values(by=[\"year\", \"month\", \"day\", \"dep_time\"], ascending=False) # default: ascending=True\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      111279\n      2013\n      12\n      31\n      2356.00\n      2359\n      -3.00\n      436.00\n      445\n      -9.00\n      B6\n      745\n      N665JB\n      JFK\n      PSE\n      200.00\n      1617\n      23\n      59\n    \n    \n      111278\n      2013\n      12\n      31\n      2355.00\n      2359\n      -4.00\n      430.00\n      440\n      -10.00\n      B6\n      1503\n      N509JB\n      JFK\n      SJU\n      195.00\n      1598\n      23\n      59\n    \n    \n      111277\n      2013\n      12\n      31\n      2332.00\n      2245\n      47.00\n      58.00\n      3\n      55.00\n      B6\n      486\n      N334JB\n      JFK\n      ROC\n      60.00\n      264\n      22\n      45\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      839\n      2013\n      1\n      1\n      NaN\n      1935\n      NaN\n      NaN\n      2240\n      NaN\n      AA\n      791\n      N3EHAA\n      LGA\n      DFW\n      NaN\n      1389\n      19\n      35\n    \n    \n      840\n      2013\n      1\n      1\n      NaN\n      1500\n      NaN\n      NaN\n      1825\n      NaN\n      AA\n      1925\n      N3EVAA\n      LGA\n      MIA\n      NaN\n      1096\n      15\n      0\n    \n    \n      841\n      2013\n      1\n      1\n      NaN\n      600\n      NaN\n      NaN\n      901\n      NaN\n      B6\n      125\n      N618JB\n      JFK\n      FLL\n      NaN\n      1069\n      6\n      0\n    \n  \n\n336776 rows × 18 columns\n\n\n\n\n# \"dep_time\"은 내림차순으로, \"arr_delay\"는 오름차순으로\nflights.sort_values(by=[\"dep_time\", \"arr_delay\"], ascending=[False, True])\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      150301\n      2013\n      3\n      15\n      2400.00\n      2359\n      1.00\n      324.00\n      338\n      -14.00\n      B6\n      727\n      N636JB\n      JFK\n      BQN\n      186.00\n      1576\n      23\n      59\n    \n    \n      87893\n      2013\n      12\n      5\n      2400.00\n      2359\n      1.00\n      427.00\n      440\n      -13.00\n      B6\n      1503\n      N587JB\n      JFK\n      SJU\n      182.00\n      1598\n      23\n      59\n    \n    \n      212941\n      2013\n      5\n      21\n      2400.00\n      2359\n      1.00\n      339.00\n      350\n      -11.00\n      B6\n      739\n      N527JB\n      JFK\n      PSE\n      199.00\n      1617\n      23\n      59\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      2013\n      9\n      30\n      NaN\n      1210\n      NaN\n      NaN\n      1330\n      NaN\n      MQ\n      3461\n      N535MQ\n      LGA\n      BNA\n      NaN\n      764\n      12\n      10\n    \n    \n      336774\n      2013\n      9\n      30\n      NaN\n      1159\n      NaN\n      NaN\n      1344\n      NaN\n      MQ\n      3572\n      N511MQ\n      LGA\n      CLE\n      NaN\n      419\n      11\n      59\n    \n    \n      336775\n      2013\n      9\n      30\n      NaN\n      840\n      NaN\n      NaN\n      1020\n      NaN\n      MQ\n      3531\n      N839MQ\n      LGA\n      RDU\n      NaN\n      431\n      8\n      40\n    \n  \n\n336776 rows × 18 columns\n\n\n\n query()와 sort_values()을 함께 이용하여 좀 더 복잡한 문제를 해결할 수 있음\n예를 들어, 다음과 같이 거의 제시간에 출발한(+- 10분) 항공편들 중 가장 도착 지연이 큰 항공편을 찾을 수 있음\n\n(\n    flights\n    .query('dep_delay <= 10 & dep_delay >= -10')\n    .sort_values(\"arr_delay\", ascending=False)\n)\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      55985\n      2013\n      11\n      1\n      658.00\n      700\n      -2.00\n      1329.00\n      1015\n      194.00\n      VX\n      399\n      N629VA\n      JFK\n      LAX\n      336.00\n      2475\n      7\n      0\n    \n    \n      181270\n      2013\n      4\n      18\n      558.00\n      600\n      -2.00\n      1149.00\n      850\n      179.00\n      AA\n      707\n      N3EXAA\n      LGA\n      DFW\n      234.00\n      1389\n      6\n      0\n    \n    \n      256340\n      2013\n      7\n      7\n      1659.00\n      1700\n      -1.00\n      2050.00\n      1823\n      147.00\n      US\n      2183\n      N948UW\n      LGA\n      DCA\n      64.00\n      214\n      17\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      334354\n      2013\n      9\n      28\n      847.00\n      839\n      8.00\n      1130.00\n      959\n      NaN\n      EV\n      4510\n      N14542\n      EWR\n      MKE\n      NaN\n      725\n      8\n      39\n    \n    \n      334412\n      2013\n      9\n      28\n      1010.00\n      1020\n      -10.00\n      1344.00\n      1222\n      NaN\n      EV\n      4412\n      N12175\n      EWR\n      DSM\n      NaN\n      1017\n      10\n      20\n    \n    \n      335805\n      2013\n      9\n      30\n      559.00\n      600\n      -1.00\n      NaN\n      715\n      NaN\n      WN\n      464\n      N411WN\n      EWR\n      MDW\n      NaN\n      711\n      6\n      0\n    \n  \n\n239109 rows × 18 columns\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRow가 재정렬되는 operation을 한 후에는 index 순서가 바뀌는데, 이를 reset하려면,\n.sort_values(ignore_index=True)\nDataFrame updated: inplace=True\nNA는 sort 후 맨 뒤로\n맨 앞으로 오게하려면 na_position='first'\n\n\n\n\n\nunique()\nSeries method\n\nflights[\"origin\"].unique() # return as a NumPy array, but depends on the dtypes\n\narray(['EWR', 'LGA', 'JFK'], dtype=object)\n\n\n\n# finds all unique origin and destination pairs.\nflights[[\"origin\", \"dest\"]].value_counts() # default: dropna=True\n\norigin  dest\nJFK     LAX     11262\nLGA     ATL     10263\n        ORD      8857\n                ...  \n        LEX         1\nJFK     MEM         1\n        BHM         1\nLength: 224, dtype: int64\n\n\n\nflights[[\"origin\", \"dest\"]].value_counts().reset_index(name=\"n\")\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      n\n    \n  \n  \n    \n      0\n      JFK\n      LAX\n      11262\n    \n    \n      1\n      LGA\n      ATL\n      10263\n    \n    \n      2\n      LGA\n      ORD\n      8857\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      221\n      LGA\n      LEX\n      1\n    \n    \n      222\n      JFK\n      MEM\n      1\n    \n    \n      223\n      JFK\n      BHM\n      1\n    \n  \n\n224 rows × 3 columns\n\n\n\n\n\n\nflights[[\"origin\", \"dest\"]].value_counts()\n\norigin  dest\nJFK     LAX     11262\nLGA     ATL     10263\n        ORD      8857\n                ...  \n        LEX         1\nJFK     MEM         1\n        BHM         1\nLength: 224, dtype: int64"
  },
  {
    "objectID": "contents/transform.html#sort_values",
    "href": "contents/transform.html#sort_values",
    "title": "Transformation",
    "section": "sort_values()",
    "text": "sort_values()\n\nflights.sort_values(by=[\"year\", \"month\", \"day\", \"dep_time\"], ascending=False).head(5) # default: ascending=True\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      111279\n      2013\n      12\n      31\n      2356.00\n      2359\n      -3.00\n      436.00\n      445\n      -9.00\n      B6\n      745\n      N665JB\n      JFK\n      PSE\n      200.00\n      1617\n      23\n      59\n    \n    \n      111278\n      2013\n      12\n      31\n      2355.00\n      2359\n      -4.00\n      430.00\n      440\n      -10.00\n      B6\n      1503\n      N509JB\n      JFK\n      SJU\n      195.00\n      1598\n      23\n      59\n    \n    \n      111277\n      2013\n      12\n      31\n      2332.00\n      2245\n      47.00\n      58.00\n      3\n      55.00\n      B6\n      486\n      N334JB\n      JFK\n      ROC\n      60.00\n      264\n      22\n      45\n    \n    \n      111276\n      2013\n      12\n      31\n      2328.00\n      2330\n      -2.00\n      412.00\n      409\n      3.00\n      B6\n      1389\n      N651JB\n      EWR\n      SJU\n      198.00\n      1608\n      23\n      30\n    \n    \n      111275\n      2013\n      12\n      31\n      2321.00\n      2250\n      31.00\n      46.00\n      8\n      38.00\n      B6\n      2002\n      N179JB\n      JFK\n      BUF\n      66.00\n      301\n      22\n      50\n    \n  \n\n\n\n\n\nflights.sort_values(by=[\"dep_time\", \"arr_delay\"], ascending=[False, True]).head(5)\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      150301\n      2013\n      3\n      15\n      2400.00\n      2359\n      1.00\n      324.00\n      338\n      -14.00\n      B6\n      727\n      N636JB\n      JFK\n      BQN\n      186.00\n      1576\n      23\n      59\n    \n    \n      87893\n      2013\n      12\n      5\n      2400.00\n      2359\n      1.00\n      427.00\n      440\n      -13.00\n      B6\n      1503\n      N587JB\n      JFK\n      SJU\n      182.00\n      1598\n      23\n      59\n    \n    \n      212941\n      2013\n      5\n      21\n      2400.00\n      2359\n      1.00\n      339.00\n      350\n      -11.00\n      B6\n      739\n      N527JB\n      JFK\n      PSE\n      199.00\n      1617\n      23\n      59\n    \n    \n      54966\n      2013\n      10\n      30\n      2400.00\n      2359\n      1.00\n      327.00\n      337\n      -10.00\n      B6\n      839\n      N661JB\n      JFK\n      BQN\n      182.00\n      1576\n      23\n      59\n    \n    \n      91492\n      2013\n      12\n      9\n      2400.00\n      2359\n      1.00\n      432.00\n      440\n      -8.00\n      B6\n      1503\n      N705JB\n      JFK\n      SJU\n      195.00\n      1598\n      23\n      59\n    \n  \n\n\n\n\n\n(\n    flights\n    .query('dep_delay <= 10 & dep_delay >= -10')\n    .sort_values(\"arr_delay\", ascending=False)\n)\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      55985\n      2013\n      11\n      1\n      658.00\n      700\n      -2.00\n      1329.00\n      1015\n      194.00\n      VX\n      399\n      N629VA\n      JFK\n      LAX\n      336.00\n      2475\n      7\n      0\n    \n    \n      181270\n      2013\n      4\n      18\n      558.00\n      600\n      -2.00\n      1149.00\n      850\n      179.00\n      AA\n      707\n      N3EXAA\n      LGA\n      DFW\n      234.00\n      1389\n      6\n      0\n    \n    \n      256340\n      2013\n      7\n      7\n      1659.00\n      1700\n      -1.00\n      2050.00\n      1823\n      147.00\n      US\n      2183\n      N948UW\n      LGA\n      DCA\n      64.00\n      214\n      17\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      334354\n      2013\n      9\n      28\n      847.00\n      839\n      8.00\n      1130.00\n      959\n      NaN\n      EV\n      4510\n      N14542\n      EWR\n      MKE\n      NaN\n      725\n      8\n      39\n    \n    \n      334412\n      2013\n      9\n      28\n      1010.00\n      1020\n      -10.00\n      1344.00\n      1222\n      NaN\n      EV\n      4412\n      N12175\n      EWR\n      DSM\n      NaN\n      1017\n      10\n      20\n    \n    \n      335805\n      2013\n      9\n      30\n      559.00\n      600\n      -1.00\n      NaN\n      715\n      NaN\n      WN\n      464\n      N411WN\n      EWR\n      MDW\n      NaN\n      711\n      6\n      0\n    \n  \n\n239109 rows × 18 columns\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nRow가 재정렬되는 operation을 한 후에는 index 순서가 바뀌는데, 이를 reset하려면,\nsort_values(ignore_index=True)"
  },
  {
    "objectID": "contents/transform.html#subsetting",
    "href": "contents/transform.html#subsetting",
    "title": "Transformation",
    "section": "Subsetting",
    "text": "Subsetting\n.loc & .iloc\n\nflights.loc[:, flights.columns.str.contains(\"time\")]\n\n\n\n\n\n  \n    \n      \n      dep_time\n      sched_dep_time\n      arr_time\n      sched_arr_time\n      air_time\n    \n  \n  \n    \n      0\n      517.00\n      515\n      830.00\n      819\n      227.00\n    \n    \n      1\n      533.00\n      529\n      850.00\n      830\n      227.00\n    \n    \n      2\n      542.00\n      540\n      923.00\n      850\n      160.00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      NaN\n      1210\n      NaN\n      1330\n      NaN\n    \n    \n      336774\n      NaN\n      1159\n      NaN\n      1344\n      NaN\n    \n    \n      336775\n      NaN\n      840\n      NaN\n      1020\n      NaN\n    \n  \n\n336776 rows × 5 columns\n\n\n\n• unique(): Returns the distinct values of the column.\n• value_counts(): Returns a frequency table of the number of times each unique value in a given column appears, or, alternatively, the percentage of times each unique value appears when passed normalize=True.\n• mode(): Returns the most common value of the column.\nisin()"
  },
  {
    "objectID": "contents/transform.html#columns",
    "href": "contents/transform.html#columns",
    "title": "Transforming",
    "section": "Columns",
    "text": "Columns\n\nSelect\n기본적인 column selection 이전 섹션 참고: subsetting\n\n# Select columns by name\nflights[[\"year\", \"month\", \"day\"]]\n\n\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n    \n    \n      1\n      2013\n      1\n      1\n    \n    \n      2\n      2013\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      2013\n      9\n      30\n    \n    \n      336774\n      2013\n      9\n      30\n    \n    \n      336775\n      2013\n      9\n      30\n    \n  \n\n336776 rows × 3 columns\n\n\n\n\n\n\n# Select all columns between year and day (inclusive)\nflights.loc[:, \"year\":\"day\"]\n\n\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n    \n    \n      1\n      2013\n      1\n      1\n    \n    \n      2\n      2013\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      2013\n      9\n      30\n    \n    \n      336774\n      2013\n      9\n      30\n    \n    \n      336775\n      2013\n      9\n      30\n    \n  \n\n336776 rows × 3 columns\n\n\n\n\n\n\n# Select all columns except those from year to day (inclusive)\n# .isin(): includes\nflights.loc[:, ~flights.columns.isin([\"year\", \"month\", \"day\"])]\n\n\n\n\n\n  \n    \n      \n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      0\n      517.00\n      515\n      2.00\n      830.00\n      819\n      11.00\n      UA\n      1545\n      N14228\n      EWR\n      IAH\n      227.00\n      1400\n      5\n      15\n    \n    \n      1\n      533.00\n      529\n      4.00\n      850.00\n      830\n      20.00\n      UA\n      1714\n      N24211\n      LGA\n      IAH\n      227.00\n      1416\n      5\n      29\n    \n    \n      2\n      542.00\n      540\n      2.00\n      923.00\n      850\n      33.00\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.00\n      1089\n      5\n      40\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      NaN\n      1210\n      NaN\n      NaN\n      1330\n      NaN\n      MQ\n      3461\n      N535MQ\n      LGA\n      BNA\n      NaN\n      764\n      12\n      10\n    \n    \n      336774\n      NaN\n      1159\n      NaN\n      NaN\n      1344\n      NaN\n      MQ\n      3572\n      N511MQ\n      LGA\n      CLE\n      NaN\n      419\n      11\n      59\n    \n    \n      336775\n      NaN\n      840\n      NaN\n      NaN\n      1020\n      NaN\n      MQ\n      3531\n      N839MQ\n      LGA\n      RDU\n      NaN\n      431\n      8\n      40\n    \n  \n\n336776 rows × 15 columns\n\n\n\n Series/Index object의 str method와 함께\nstr.contains(), str.startswith(), str.endswith()\n\n# Select all columns that begin with “dep”.\nflights.loc[:, flights.columns.str.startswith(\"dep\")]\n\n\n\n\n\n\n\n  \n    \n      \n      dep_time\n      dep_delay\n    \n  \n  \n    \n      0\n      517.00\n      2.00\n    \n    \n      1\n      533.00\n      4.00\n    \n    \n      2\n      542.00\n      2.00\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      336773\n      NaN\n      NaN\n    \n    \n      336774\n      NaN\n      NaN\n    \n    \n      336775\n      NaN\n      NaN\n    \n  \n\n336776 rows × 2 columns\n\n\n\n\n\n\n# Select all columns that are characters\nflights.select_dtypes(\"object\") # dtype: object, number, ...\n\n\n\n\n\n  \n    \n      \n      carrier\n      tailnum\n      origin\n      dest\n    \n  \n  \n    \n      0\n      UA\n      N14228\n      EWR\n      IAH\n    \n    \n      1\n      UA\n      N24211\n      LGA\n      IAH\n    \n    \n      2\n      AA\n      N619AA\n      JFK\n      MIA\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      MQ\n      N535MQ\n      LGA\n      BNA\n    \n    \n      336774\n      MQ\n      N511MQ\n      LGA\n      CLE\n    \n    \n      336775\n      MQ\n      N839MQ\n      LGA\n      RDU\n    \n  \n\n336776 rows × 4 columns\n\n\n\nindex selection: reindex\n\n\nrename()\n\nflights.rename(\n    columns={\"dep_time\": \"dep_t\", \"arr_time\": \"arr_t\"},\n  # inplace=True (dataframe is updated)\n)\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_t\n      sched_dep_time\n      dep_delay\n      arr_t\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n      517.00\n      515\n      2.00\n      830.00\n      819\n      11.00\n      UA\n      1545\n      N14228\n      EWR\n      IAH\n      227.00\n      1400\n      5\n      15\n    \n    \n      1\n      2013\n      1\n      1\n      533.00\n      529\n      4.00\n      850.00\n      830\n      20.00\n      UA\n      1714\n      N24211\n      LGA\n      IAH\n      227.00\n      1416\n      5\n      29\n    \n    \n      2\n      2013\n      1\n      1\n      542.00\n      540\n      2.00\n      923.00\n      850\n      33.00\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.00\n      1089\n      5\n      40\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      2013\n      9\n      30\n      NaN\n      1210\n      NaN\n      NaN\n      1330\n      NaN\n      MQ\n      3461\n      N535MQ\n      LGA\n      BNA\n      NaN\n      764\n      12\n      10\n    \n    \n      336774\n      2013\n      9\n      30\n      NaN\n      1159\n      NaN\n      NaN\n      1344\n      NaN\n      MQ\n      3572\n      N511MQ\n      LGA\n      CLE\n      NaN\n      419\n      11\n      59\n    \n    \n      336775\n      2013\n      9\n      30\n      NaN\n      840\n      NaN\n      NaN\n      1020\n      NaN\n      MQ\n      3531\n      N839MQ\n      LGA\n      RDU\n      NaN\n      431\n      8\n      40\n    \n  \n\n336776 rows × 18 columns\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nSeries의 경우\ns = flights.dep_delay.head(3)\n# 0   2.00\n# 1   4.00\n# 2   2.00\n# Name: dep_delay, dtype: float64\n\ns.rename(\"what\")\n# 0   2.00\n# 1   4.00\n# 2   2.00\n# Name: what, dtype: float64\n\n\n함수 str.capitalize, str.lower, str.upper과 함께\n\nflights.rename(str.capitalize, axis=\"columns\").head(3) # axis=1\n\n\n\n\n\n  \n    \n      \n      Year\n      Month\n      Day\n      Dep_time\n      Sched_dep_time\n      Dep_delay\n      Arr_time\n      Sched_arr_time\n      Arr_delay\n      Carrier\n      Flight\n      Tailnum\n      Origin\n      Dest\n      Air_time\n      Distance\n      Hour\n      Minute\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n      517.00\n      515\n      2.00\n      830.00\n      819\n      11.00\n      UA\n      1545\n      N14228\n      EWR\n      IAH\n      227.00\n      1400\n      5\n      15\n    \n    \n      1\n      2013\n      1\n      1\n      533.00\n      529\n      4.00\n      850.00\n      830\n      20.00\n      UA\n      1714\n      N24211\n      LGA\n      IAH\n      227.00\n      1416\n      5\n      29\n    \n    \n      2\n      2013\n      1\n      1\n      542.00\n      540\n      2.00\n      923.00\n      850\n      33.00\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.00\n      1089\n      5\n      40\n    \n  \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nindex를 rename할 수도 있음\nflights.rename(\n    index={0: \"a\", 1: \"b\"},\n).head(3)\n# year  month   day dep_time ...\n# a 2013    1   1   517.00   ...\n# b 2013    1   1   533.00   ...\n# 2 2013    1   1   542.00   ...\n\n\n\n\nassign()\n\n['title', 'time'] + [col for col in df.columns if col.startswith('mag')]\n\n['title', 'time']\n\n\n\ncols = [\"year\", \"month\", \"day\", \"distance\", \"air_time\"] + \\\n        [col for col in flights.columns if col.endswith(\"delay\")]  # string method .endswith\nflights_sml = flights[cols].copy()\nflights_sml\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      distance\n      air_time\n      dep_delay\n      arr_delay\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n      1400\n      227.00\n      2.00\n      11.00\n    \n    \n      1\n      2013\n      1\n      1\n      1416\n      227.00\n      4.00\n      20.00\n    \n    \n      2\n      2013\n      1\n      1\n      1089\n      160.00\n      2.00\n      33.00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      2013\n      9\n      30\n      764\n      NaN\n      NaN\n      NaN\n    \n    \n      336774\n      2013\n      9\n      30\n      419\n      NaN\n      NaN\n      NaN\n    \n    \n      336775\n      2013\n      9\n      30\n      431\n      NaN\n      NaN\n      NaN\n    \n  \n\n336776 rows × 7 columns\n\n\n\n\n# 새로 만들어진 변수는 맨 뒤로\nflights_sml.assign(\n    gain=lambda x:x.dep_delay - x.arr_delay,\n    speed=lambda x:x.distance / x.air_time * 60\n)\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      distance\n      air_time\n      dep_delay\n      arr_delay\n      gain\n      speed\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n      1400\n      227.00\n      2.00\n      11.00\n      -9.00\n      370.04\n    \n    \n      1\n      2013\n      1\n      1\n      1416\n      227.00\n      4.00\n      20.00\n      -16.00\n      374.27\n    \n    \n      2\n      2013\n      1\n      1\n      1089\n      160.00\n      2.00\n      33.00\n      -31.00\n      408.38\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      2013\n      9\n      30\n      764\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      336774\n      2013\n      9\n      30\n      419\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      336775\n      2013\n      9\n      30\n      431\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n336776 rows × 9 columns\n\n\n\n\n# 앞에서 만든 변수나 함수를 이용할 수 있음\nflights_sml.assign(\n    gain=lambda x:x.dep_delay - x.arr_delay,\n    hours=lambda x:x.air_time / 60,\n    gain_per_hour=lambda x:x.gain / x.hours,\n    rounded=lambda x: np.round(x.gain_per_hour, 1)  # use a numpy function\n)\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      distance\n      air_time\n      dep_delay\n      arr_delay\n      gain\n      hours\n      gain_per_hour\n      rounded\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n      1400\n      227.00\n      2.00\n      11.00\n      -9.00\n      3.78\n      -2.38\n      -2.40\n    \n    \n      1\n      2013\n      1\n      1\n      1416\n      227.00\n      4.00\n      20.00\n      -16.00\n      3.78\n      -4.23\n      -4.20\n    \n    \n      2\n      2013\n      1\n      1\n      1089\n      160.00\n      2.00\n      33.00\n      -31.00\n      2.67\n      -11.62\n      -11.60\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      2013\n      9\n      30\n      764\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      336774\n      2013\n      9\n      30\n      419\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      336775\n      2013\n      9\n      30\n      431\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n336776 rows × 11 columns\n\n\n\n\n# Find the fastest flights\n(\n    flights_sml\n    .assign(speed=lambda x:x.distance / x.air_time)\n    .sort_values(by=\"speed\", ascending=False)\n    .head(5)\n)\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      distance\n      air_time\n      dep_delay\n      arr_delay\n      speed\n    \n  \n  \n    \n      216447\n      2013\n      5\n      25\n      762\n      65.00\n      9.00\n      -14.00\n      11.72\n    \n    \n      251999\n      2013\n      7\n      2\n      1008\n      93.00\n      45.00\n      26.00\n      10.84\n    \n    \n      205388\n      2013\n      5\n      13\n      594\n      55.00\n      15.00\n      -1.00\n      10.80\n    \n    \n      157516\n      2013\n      3\n      23\n      748\n      70.00\n      4.00\n      2.00\n      10.69\n    \n    \n      10223\n      2013\n      1\n      12\n      1035\n      105.00\n      -1.00\n      -28.00\n      9.86"
  },
  {
    "objectID": "contents/transform.html#groups",
    "href": "contents/transform.html#groups",
    "title": "Transforming",
    "section": "Groups",
    "text": "Groups\n\ngroupby()\n\ngroupby()는 데이터를 의미있는 그룹으로 나누어 분석할 수 있도록 해줌\n.count(), .sum(), .mean(), .min(), .max()과 같은 통계치를 구하는 methods와 함께 효과적으로, 자주 활용됨\n\n\nSource: Ch.10 in Python for Data Analysis (3e) by Wes McKinney\n아래 표는\n\nSource: Ch.10 in Python for Data Analysis (3e) by Wes McKinney\n\nflights.groupby(\"month\") # “GroupBy” object\n\n<pandas.core.groupby.generic.DataFrameGroupBy object at 0x144733c50>\n\n\n\nflights_sml.groupby(\"month\").mean()\n\n\n\n\n\n\n\n  \n    \n      \n      year\n      day\n      distance\n      air_time\n      dep_delay\n      arr_delay\n    \n    \n      month\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      2013.00\n      15.99\n      1006.84\n      154.19\n      10.04\n      6.13\n    \n    \n      2\n      2013.00\n      14.74\n      1000.98\n      151.35\n      10.82\n      5.61\n    \n    \n      3\n      2013.00\n      16.00\n      1011.99\n      149.08\n      13.23\n      5.81\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      10\n      2013.00\n      15.98\n      1038.88\n      148.89\n      6.24\n      -0.17\n    \n    \n      11\n      2013.00\n      15.29\n      1050.31\n      155.47\n      5.44\n      0.46\n    \n    \n      12\n      2013.00\n      15.72\n      1064.66\n      162.59\n      16.58\n      14.87\n    \n  \n\n12 rows × 6 columns\n\n\n\n\n\n\n# 보통은 다음과 같이 특정 columns을 선택\nflights.groupby(\"month\")[\"dep_delay\"]  # [[\"dep_delay\"]] 처럼 list로 입력하면 DataFrameGroupBy object\n\n<pandas.core.groupby.generic.SeriesGroupBy object at 0x14472be50>\n\n\n\nflights.groupby(\"month\")[\"dep_delay\"].mean() # Series GroupBy object에 적용된 결과는 Series\n\nmonth\n1    10.04\n2    10.82\n3    13.23\n      ... \n10    6.24\n11    5.44\n12   16.58\nName: dep_delay, Length: 12, dtype: float64\n\n\n\nflights.groupby(\"month\")[[\"dep_delay\", \"arr_delay\"]].mean().head(3)\n\n\n\n\n\n\n\n  \n    \n      \n      dep_delay\n      arr_delay\n    \n    \n      month\n      \n      \n    \n  \n  \n    \n      1\n      10.04\n      6.13\n    \n    \n      2\n      10.82\n      5.61\n    \n    \n      3\n      13.23\n      5.81\n    \n  \n\n\n\n\n\n\n\n# 2 levels의 grouping\n# nsmallest: a Series method, not a DataFrame method\nflights.groupby([\"month\", \"day\"])[\"arr_delay\"].nsmallest(1)\n\nmonth  day        \n1      1    696      -48.00\n       2    919      -59.00\n       3    2035     -65.00\n                      ...  \n12     29   108914   -60.00\n       30   110330   -45.00\n       31   111113   -44.00\nName: arr_delay, Length: 365, dtype: float64\n\n\n\nflights.groupby([\"origin\", \"dest\"])[\"arr_delay\"].count()\n\norigin  dest\nEWR     ALB      418\n        ANC        8\n        ATL     4876\n                ... \nLGA     TVC       73\n        TYS      265\n        XNA      709\nName: arr_delay, Length: 224, dtype: int64\n\n\n\n\n\n\n\n\nTip\n\n\n\nas_index=False: grouping 변수들을 index가 아닌 columns으로\nflights.groupby([\"month\", \"day\"], as_index=False)[\"arr_delay\"].mean().head(3)\n#    month  day  arr_delay\n# 0      1    1      12.65\n# 1      1    2      12.69\n# 2      1    3       5.73\n물론, 결과물에 .reset_index() method를 사용해도 됨\n\n\n\n\n\n\n\n\nNote\n\n\n\n원칙적으로 grouping은 같은 DataFrame의 변수일 필요없이 match만 되면 됨\nSource: Wes McKinney’s\n# df\n#    key1  key2  data1  data2\n# 0     a     1   0.36  -0.42\n# 1     a     2  -1.51   0.04\n# 2  None     1   0.75  -0.28\n# 3     b     2   0.57   0.25\n# 4     b     1   1.30  -0.77\n# 5     a  <NA>  -0.53  -0.73\n# 6  None     1   2.04  -0.37\n\nstates = np.array([\"OH\", \"CA\", \"CA\", \"OH\", \"OH\", \"CA\", \"OH\"])\nyears = [2005, 2005, 2006, 2005, 2006, 2005, 2006]\n\ndf[\"data1\"].groupby([states, years]).mean()\n# CA  2005   -1.02\n#     2006    0.75\n# OH  2005    0.46\n#     2006    1.67\n# Name: data1, dtype: float64\n\n\n\nflights.groupby(\"dest\").size() # .size(): a method for DataFrame, not Series\n\ndest\nABQ     254\nACK     265\nALB     439\n       ... \nTVC     101\nTYS     631\nXNA    1036\nLength: 105, dtype: int64\n\n\n\nflights.groupby(\"tailnum\", dropna=False).size() # groupby는 기본적으로 NA 무시\n\ntailnum\nD942DN       4\nN0EGMQ     371\nN10156     153\n          ... \nN999DN      61\nN9EAMQ     248\nNaN       2512\nLength: 4044, dtype: int64\n\n\n\n\n\n\n\n\nNote\n\n\n\n.size()는 .value_counts()와 유사하게 사용될 수 있음\nflights[\"tailnum\"].value_counts(dropna=False)\n# NaN       2512\n# N725MQ     575\n# N722MQ     513\n#           ... \n# N318AS       1\n# N651UA       1\n# N557AS       1\n# Name: tailnum, Length: 4044, dtype: int64\n\n\n\n\n\n\n\n\nNote\n\n\n\nIndex에 grouping하는 방식에 대해서는 Wes McKineey’s Chapter 10 참고\n\nGrouping with Dictionaries and Series\nGrouping with Functions\nGrouping by Index Levels\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTimes series 데이터의 경우 다양한 grouping 방식이 존재\nStephanie Molin의 ch.4 Working with time series data 참고\n예를 들어, facebook stock에 대한 자료에서 2018년 4분기에 해당하는 날을 week단위로 그룹핑하여 volume을 다음과 같이 계산할 수 있음\nfb.loc['2018-Q4'].groupby(pd.Grouper(freq='W')).volume.sum()\n\n\n\n\n\n\n\n\nTip\n\n\n\ngroupby filtering\nflights.groupby([\"year\", \"month\", \"day\"]).filter(lambda x: x[\"arr_delay\"].mean() < 0)\n\n\n\n\n\nagg()\nAggregations: data transformation that produces scalar values from arrays\n앞서 GroupBy object에 직접 stats function을 적용하였는데, agg()를 이용하여 더 확장, 일반화할 수 있음\n\n# 모두 동일\nflights_sml.groupby(\"month\").mean()\nflights_sml.groupby(\"month\").agg(\"mean\")  # function names\nflights_sml.groupby(\"month\").agg(np.mean)  # general functions\n\n\n\n         year   day  distance  air_time  dep_delay  arr_delay\nmonth                                                        \n1     2013.00 15.99   1006.84    154.19      10.04       6.13\n2     2013.00 14.74   1000.98    151.35      10.82       5.61\n3     2013.00 16.00   1011.99    149.08      13.23       5.81\n...       ...   ...       ...       ...        ...        ...\n10    2013.00 15.98   1038.88    148.89       6.24      -0.17\n11    2013.00 15.29   1050.31    155.47       5.44       0.46\n12    2013.00 15.72   1064.66    162.59      16.58      14.87\n\n[12 rows x 6 columns]\n\n\n\nflights.groupby(\"month\")[\"dep_delay\"].agg([\"mean\", \"count\"])\n\n\n\n\n\n\n\n  \n    \n      \n      mean\n      count\n    \n    \n      month\n      \n      \n    \n  \n  \n    \n      1\n      10.04\n      26483\n    \n    \n      2\n      10.82\n      23690\n    \n    \n      3\n      13.23\n      27973\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      10\n      6.24\n      28653\n    \n    \n      11\n      5.44\n      27035\n    \n    \n      12\n      16.58\n      27110\n    \n  \n\n12 rows × 2 columns\n\n\n\n\n\n\nflights_agg = flights.groupby(\"month\").agg({\n    \"air_time\": [\"min\", \"max\"],\n    \"dep_delay\": \"mean\",\n    \"arr_delay\": \"median\"\n})\nflights_agg.head(3)\n\n\n\n\n\n\n\n  \n    \n      \n      air_time\n      dep_delay\n      arr_delay\n    \n    \n      \n      min\n      max\n      mean\n      median\n    \n    \n      month\n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      20.00\n      667.00\n      10.04\n      -3.00\n    \n    \n      2\n      21.00\n      691.00\n      10.82\n      -3.00\n    \n    \n      3\n      21.00\n      695.00\n      13.23\n      -6.00\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nflights_agg.columns\n# MultiIndex([( 'air_time',    'min'),\n#             ( 'air_time',    'max'),\n#             ('dep_delay',   'mean'),\n#             ('arr_delay', 'median')],\n#            )\n\nflights_agg.columns = ['_'.join(col_agg) for col_agg in flights_agg.columns]\nflights_agg.head(3)\n#        air_time_min  air_time_max  dep_delay_mean  arr_delay_median\n# month                                                              \n# 1             20.00        667.00           10.04             -3.00\n# 2             21.00        691.00           10.82             -3.00\n# 3             21.00        695.00           13.23             -6.00\n\n\nagg()에는 custom function을 pass할 수 있음\n단, the optimized functions (Table 10-1)에 비해 일반적으로 훨씬 느림\n\ndef peak_to_peak(arr):\n    return arr.max() - arr.min()\n\n\ngrouped = flights_sml.groupby([\"month\", \"day\"])\ngrouped_dist = flights_sml.groupby([\"month\", \"day\"])[\"distance\"]\n\ngrouped_dist.agg([\"std\", peak_to_peak]) # a list of functions\n\n\n\n\n\n\n\n  \n    \n      \n      \n      std\n      peak_to_peak\n    \n    \n      month\n      day\n      \n      \n    \n  \n  \n    \n      1\n      1\n      727.73\n      4889\n    \n    \n      2\n      721.72\n      4889\n    \n    \n      3\n      714.95\n      4903\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      12\n      29\n      728.78\n      4887\n    \n    \n      30\n      723.88\n      4887\n    \n    \n      31\n      731.36\n      4887\n    \n  \n\n365 rows × 2 columns\n\n\n\n\n\n\n# Naming a function as a tuple\ngrouped_dist.agg([(\"sd\", \"std\"), (\"range\", peak_to_peak)])\n\n\n\n\n\n\n\n  \n    \n      \n      \n      sd\n      range\n    \n    \n      month\n      day\n      \n      \n    \n  \n  \n    \n      1\n      1\n      727.73\n      4889\n    \n    \n      2\n      721.72\n      4889\n    \n    \n      3\n      714.95\n      4903\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      12\n      29\n      728.78\n      4887\n    \n    \n      30\n      723.88\n      4887\n    \n    \n      31\n      731.36\n      4887\n    \n  \n\n365 rows × 2 columns\n\n\n\n\n\n\n# Apply different funtions to different columns\ngrouped.agg({\"distance\" : np.std, \"air_time\" : \"sum\"})\n\n\n\n\n\n\n\n  \n    \n      \n      \n      distance\n      air_time\n    \n    \n      month\n      day\n      \n      \n    \n  \n  \n    \n      1\n      1\n      727.73\n      140981.00\n    \n    \n      2\n      721.72\n      150520.00\n    \n    \n      3\n      714.95\n      140934.00\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      12\n      29\n      728.78\n      144085.00\n    \n    \n      30\n      723.88\n      162526.00\n    \n    \n      31\n      731.36\n      131910.00\n    \n  \n\n365 rows × 2 columns\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n.describe()는 aggregation은 아니나 grouped objects에 적용가능\ngrouped[[\"dep_delay\", \"arr_delay\"]].describe()\n#       dep_delay                                              arr_delay        \\\n#           count  mean   std    min   25%   50%   75%     max     count  mean   \n# month                                                                          \n# 1      26483.00 10.04 36.39 -30.00 -5.00 -2.00  8.00 1301.00  26398.00  6.13   \n# 2      23690.00 10.82 36.27 -33.00 -5.00 -2.00  9.00  853.00  23611.00  5.61   \n# 3      27973.00 13.23 40.13 -25.00 -5.00 -1.00 12.00  911.00  27902.00  5.81   \n# ...         ...   ...   ...    ...   ...   ...   ...     ...       ...   ...    \n                                               \n#         std    min    25%   50%   75%     max  \n# month                                          \n# 1     40.42 -70.00 -15.00 -3.00 13.00 1272.00  \n# 2     39.53 -70.00 -15.00 -3.00 13.00  834.00  \n# 3     44.12 -68.00 -18.00 -6.00 13.00  915.00  \n# ...     ...    ...    ...   ...   ...     ...  \n\n# [12 rows x 16 columns]\n\n\n\n\ntransform()\n앞서 group별로 통계치가 summary되어 원래 reduced 데이터를 변형됐다면,\ntransform()은 group별로 얻은 통계치가 원래 데이터의 형태를 그대로 보존하면서 출력\n\nflights_sml.groupby([\"month\"])[\"arr_delay\"].mean()\n\nmonth\n1     6.13\n2     5.61\n3     5.81\n      ... \n10   -0.17\n11    0.46\n12   14.87\nName: arr_delay, Length: 12, dtype: float64\n\n\n\ngrouped_delay = flights_sml.groupby([\"month\"])[\"arr_delay\"].transform(\"mean\")\ngrouped_delay\n\n0         6.13\n1         6.13\n2         6.13\n          ... \n336773   -4.02\n336774   -4.02\n336775   -4.02\nName: arr_delay, Length: 336776, dtype: float64\n\n\n\nflights_sml[\"monthly_delay\"] = grouped_delay\nflights_sml\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      distance\n      air_time\n      dep_delay\n      arr_delay\n      monthly_delay\n    \n  \n  \n    \n      0\n      2013\n      1\n      1\n      1400\n      227.00\n      2.00\n      11.00\n      6.13\n    \n    \n      1\n      2013\n      1\n      1\n      1416\n      227.00\n      4.00\n      20.00\n      6.13\n    \n    \n      2\n      2013\n      1\n      1\n      1089\n      160.00\n      2.00\n      33.00\n      6.13\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      2013\n      9\n      30\n      764\n      NaN\n      NaN\n      NaN\n      -4.02\n    \n    \n      336774\n      2013\n      9\n      30\n      419\n      NaN\n      NaN\n      NaN\n      -4.02\n    \n    \n      336775\n      2013\n      9\n      30\n      431\n      NaN\n      NaN\n      NaN\n      -4.02\n    \n  \n\n336776 rows × 8 columns\n\n\n\nQ: 1년에 10000편 이상 운항편이 있는 도착지에 대한 항공편들만 추리면,\n\ndest_size =  flights.groupby(\"dest\").transform(\"size\")\ndest_size\n\n0          7198\n1          7198\n2         11728\n          ...  \n336773     6333\n336774     4573\n336775     8163\nLength: 336776, dtype: int64\n\n\n\n# 1년에 10000편 이상 운항편이 있는 도착지에 대한 항공편\nflights[dest_size > 10000]\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      2\n      2013\n      1\n      1\n      542.00\n      540\n      2.00\n      923.00\n      850\n      33.00\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.00\n      1089\n      5\n      40\n    \n    \n      4\n      2013\n      1\n      1\n      554.00\n      600\n      -6.00\n      812.00\n      837\n      -25.00\n      DL\n      461\n      N668DN\n      LGA\n      ATL\n      116.00\n      762\n      6\n      0\n    \n    \n      5\n      2013\n      1\n      1\n      554.00\n      558\n      -4.00\n      740.00\n      728\n      12.00\n      UA\n      1696\n      N39463\n      EWR\n      ORD\n      150.00\n      719\n      5\n      58\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336762\n      2013\n      9\n      30\n      2233.00\n      2113\n      80.00\n      112.00\n      30\n      42.00\n      UA\n      471\n      N578UA\n      EWR\n      SFO\n      318.00\n      2565\n      21\n      13\n    \n    \n      336763\n      2013\n      9\n      30\n      2235.00\n      2001\n      154.00\n      59.00\n      2249\n      130.00\n      B6\n      1083\n      N804JB\n      JFK\n      MCO\n      123.00\n      944\n      20\n      1\n    \n    \n      336768\n      2013\n      9\n      30\n      2307.00\n      2255\n      12.00\n      2359.00\n      2358\n      1.00\n      B6\n      718\n      N565JB\n      JFK\n      BOS\n      33.00\n      187\n      22\n      55\n    \n  \n\n131440 rows × 18 columns\n\n\n\nQ: 하루 중 출발 지연이 가장 늦은 두 항공편들을 365일 각각 구하면,\n\ndef get_ranks(group):\n    return group.rank(ascending=False)\n\n\ndelay_rank = flights.groupby([\"month\", \"day\"])[\"dep_delay\"].transform(get_ranks)\ndelay_rank\n\n0        313.00\n1        276.00\n2        313.00\n          ...  \n336773      NaN\n336774      NaN\n336775      NaN\nName: dep_delay, Length: 336776, dtype: float64\n\n\n\nflights[delay_rank < 3].head(6)\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      151\n      2013\n      1\n      1\n      848.00\n      1835\n      853.00\n      1001.00\n      1950\n      851.00\n      MQ\n      3944\n      N942MQ\n      JFK\n      BWI\n      41.00\n      184\n      18\n      35\n    \n    \n      834\n      2013\n      1\n      1\n      2343.00\n      1724\n      379.00\n      314.00\n      1938\n      456.00\n      EV\n      4321\n      N21197\n      EWR\n      MCI\n      222.00\n      1092\n      17\n      24\n    \n    \n      1440\n      2013\n      1\n      2\n      1607.00\n      1030\n      337.00\n      2003.00\n      1355\n      368.00\n      AA\n      179\n      N324AA\n      JFK\n      SFO\n      346.00\n      2586\n      10\n      30\n    \n    \n      1749\n      2013\n      1\n      2\n      2131.00\n      1512\n      379.00\n      2340.00\n      1741\n      359.00\n      UA\n      488\n      N593UA\n      LGA\n      DEN\n      228.00\n      1620\n      15\n      12\n    \n    \n      2598\n      2013\n      1\n      3\n      2008.00\n      1540\n      268.00\n      2339.00\n      1909\n      270.00\n      DL\n      2027\n      N338NW\n      JFK\n      FLL\n      158.00\n      1069\n      15\n      40\n    \n    \n      2637\n      2013\n      1\n      3\n      2056.00\n      1605\n      291.00\n      2239.00\n      1754\n      285.00\n      9E\n      3459\n      N928XJ\n      JFK\n      BNA\n      125.00\n      765\n      16\n      5\n    \n  \n\n\n\n\nQ: Normalize air time by destination\n\ndest_air = flights.groupby(\"dest\")[\"air_time\"]\n\n\n# Z = (x - mean) / std\n(flights['air_time'] - dest_air.transform('mean')) / dest_air.transform('std')\n\n0        1.73\n1        1.73\n2        0.61\n         ... \n336773    NaN\n336774    NaN\n336775    NaN\nName: air_time, Length: 336776, dtype: float64\n\n\n\ndef normalize(x):\n    return (x - x.mean()) / x.std()\n\n\ndest_air.transform(normalize)\n\n0        1.73\n1        1.73\n2        0.61\n         ... \n336773    NaN\n336774    NaN\n336775    NaN\nName: air_time, Length: 336776, dtype: float64\n\n\n\n\napply()\nApply: General split-apply-combine McKineey’s Chapter 10.3 참고\nThe most general-purpose GroupBy method is apply, which is the subject of this section.\napply splits the object being manipulated into pieces, invokes the passed function on each piece, and then attempts to concatenate the pieces.\n\ntips = sns.load_dataset(\"tips\")\ntips = tips.assign(tip_pct = lambda x: x.tip / x.total_bill)\ntips.head(3)\n\n\n\n\n\n\n   total_bill  tip     sex smoker  day    time  size  tip_pct\n0       16.99 1.01  Female     No  Sun  Dinner     2     0.06\n1       10.34 1.66    Male     No  Sun  Dinner     3     0.16\n2       21.01 3.50    Male     No  Sun  Dinner     3     0.17\n\n\n\ndef top(df, n=5, column=\"tip_pct\"):\n    return df.sort_values(column, ascending=False)[:n]\n\n\ntop(tips, n=4)\n\n\n\n\n\n\n     total_bill  tip     sex smoker  day    time  size  tip_pct\n172        7.25 5.15    Male    Yes  Sun  Dinner     2     0.71\n178        9.60 4.00  Female    Yes  Sun  Dinner     2     0.42\n67         3.07 1.00  Female    Yes  Sat  Dinner     1     0.33\n232       11.61 3.39    Male     No  Sat  Dinner     2     0.29\n\n\n\ntips.groupby(\"time\").apply(top)\n\n\n\n            total_bill  tip     sex smoker   day    time  size  tip_pct\ntime                                                                   \nLunch  149        7.51 2.00    Male     No  Thur   Lunch     2     0.27\n       221       13.42 3.48  Female    Yes   Fri   Lunch     2     0.26\n       194       16.58 4.00    Male    Yes  Thur   Lunch     2     0.24\n...                ...  ...     ...    ...   ...     ...   ...      ...\nDinner 67         3.07 1.00  Female    Yes   Sat  Dinner     1     0.33\n       232       11.61 3.39    Male     No   Sat  Dinner     2     0.29\n       183       23.17 6.50    Male    Yes   Sun  Dinner     4     0.28\n\n[10 rows x 8 columns]\n\n\n\ntips.groupby([\"time\", \"day\"]).apply(top, n=1, column=\"total_bill\")\n\n\n\n                 total_bill   tip     sex smoker   day    time  size  tip_pct\ntime   day                                                                   \nLunch  Thur 197       43.11  5.00  Female    Yes  Thur   Lunch     4     0.12\n       Fri  225       16.27  2.50  Female    Yes   Fri   Lunch     2     0.15\nDinner Thur 243       18.78  3.00  Female     No  Thur  Dinner     2     0.16\n       Fri  95        40.17  4.73    Male    Yes   Fri  Dinner     4     0.12\n       Sat  170       50.81 10.00    Male    Yes   Sat  Dinner     3     0.20\n       Sun  156       48.17  5.00    Male     No   Sun  Dinner     6     0.10\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhat occurs inside the function passed is up to you;\nit must either return a pandas object or a scalar value.\n\n\n\ntips.groupby(\"sex\")[\"tip_pct\"].describe()\n\n\n\n\n\n  \n    \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n    \n      sex\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Male\n      157.00\n      0.16\n      0.06\n      0.04\n      0.12\n      0.15\n      0.19\n      0.71\n    \n    \n      Female\n      87.00\n      0.17\n      0.05\n      0.06\n      0.14\n      0.16\n      0.19\n      0.42\n    \n  \n\n\n\n\nInside GroupBy, when you invoke a method like describe, it is actually just a shortcut for:\ndef f(group):\n    return group.describe()\n\n\n\n\n\n\nTip\n\n\n\nSuppressing the Group Keys\ntips.groupby(\"time\", group_keys=False).apply(top)\n#      total_bill  tip     sex smoker   day    time  size  tip_pct\n# 149        7.51 2.00    Male     No  Thur   Lunch     2     0.27\n# 221       13.42 3.48  Female    Yes   Fri   Lunch     2     0.26\n# 194       16.58 4.00    Male    Yes  Thur   Lunch     2     0.24\n# 172        7.25 5.15    Male    Yes   Sun  Dinner     2     0.71\n# 178        9.60 4.00  Female    Yes   Sun  Dinner     2     0.42\n# 67         3.07 1.00  Female    Yes   Sat  Dinner     1     0.33\n\n\n\ncut(), qcut()\nQuantile and Bucket Analysis pd.cut(), pd.qcut()\ncf. map, mapapply, apply\n• unique(): Returns the distinct values of the column.\n• value_counts(): Returns a frequency table of the number of times each unique value in a given column appears, or, alternatively, the percentage of times each unique value appears when passed normalize=True.\n• mode(): Returns the most common value of the column.\n\nflights[flights[\"arr_delay\"] > 0].groupby([\"year\", \"month\", \"day\"])[\"arr_delay\"].mean()"
  },
  {
    "objectID": "contents/subsetting.html",
    "href": "contents/subsetting.html",
    "title": "Subsetting",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\nData: On-time data for all flights that departed NYC (i.e. JFK, LGA or EWR) in 2013\nSubsetting options"
  },
  {
    "objectID": "contents/subsetting.html#subsetting",
    "href": "contents/subsetting.html#subsetting",
    "title": "Subsetting",
    "section": "Subsetting",
    "text": "Subsetting\n\nColumns\n\nflights.dest # 몇 가지 제약 존재: ex. 빈칸이 있는 변수명, method와 같은 이름의 변수명\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object\n\n\n\n\n\n\n\n\nWarning\n\n\n\n값을 assign할 때는 df[\"var\"]만을 쓸 것\n\n\n\nflights[\"dest\"]\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object\n\n\n\n\nBoolean index\n\nflights.loc[:, flights.columns.str.contains(\"time\")]"
  },
  {
    "objectID": "contents/rtest.html",
    "href": "contents/rtest.html",
    "title": "R Test",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\noptions(repr.plot.width = 5, repr.plot.height = 5)\nmpg |> \n    ggplot(aes(x=displ, y =cty)) +\n    geom_point() +\n    geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균, sk.cho@snu.ac.kr\n면담 시간: 수업 후\n조교: 정은정, gtsyej11@naver.com\n수업시간: 월, 수 1:00 ~ 2:50PM\nWebsite: dg.modellings.art\n과제: Notice\n질문: Communicate/Ask"
  },
  {
    "objectID": "contents/subsetting.html#subsetting-options",
    "href": "contents/subsetting.html#subsetting-options",
    "title": "Subsetting",
    "section": "Subsetting options",
    "text": "Subsetting options\n\nBracket []\nDot-notation .\niloc\nloc"
  },
  {
    "objectID": "contents/subsetting.html#selecting-columns",
    "href": "contents/subsetting.html#selecting-columns",
    "title": "Subsetting",
    "section": "Selecting columns",
    "text": "Selecting columns\n\nflights['dest'] # return as a Series\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object\n\n\n\nflights[['origin', 'dest']]\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n    \n  \n  \n    \n      0\n      EWR\n      IAH\n    \n    \n      1\n      LGA\n      IAH\n    \n    \n      2\n      JFK\n      MIA\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      336773\n      LGA\n      BNA\n    \n    \n      336774\n      LGA\n      CLE\n    \n    \n      336775\n      LGA\n      RDU\n    \n  \n\n336776 rows × 2 columns\n\n\n\n\n주의\n\ndf = flights[:100][[\"origin\", \"dest\", \"arr_delay\"]].nlargest(5, \"arr_delay\")\ndf\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      96\n      EWR\n      ORD\n      49.00\n    \n    \n      42\n      LGA\n      DFW\n      48.00\n    \n    \n      69\n      JFK\n      LAX\n      44.00\n    \n    \n      2\n      JFK\n      MIA\n      33.00\n    \n    \n      25\n      EWR\n      ORD\n      32.00\n    \n  \n\n\n\n\n\ndf.loc[42:2, :]\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      42\n      LGA\n      DFW\n      48.00\n    \n    \n      69\n      JFK\n      LAX\n      44.00\n    \n    \n      2\n      JFK\n      MIA\n      33.00\n    \n  \n\n\n\n\n\ns = df[\"dest\"]\ns\n\n96    ORD\n42    DFW\n69    LAX\n2     MIA\n25    ORD\nName: dest, dtype: object\n\n\n\ns[:3]\n\n96    ORD\n42    DFW\n69    LAX\nName: dest, dtype: object\n\n\n\ndf.iloc[:3, 1:3]\n\n\n\n\n\n  \n    \n      \n      dest\n      arr_delay\n    \n  \n  \n    \n      96\n      ORD\n      49.00\n    \n    \n      42\n      DFW\n      48.00\n    \n    \n      69\n      LAX\n      44.00\n    \n  \n\n\n\n\n\ndf = flights[['origin', 'dest', \"arr_delay\"]][:100].nlargest(5, \"arr_dealy\")\ndf = df.sample(5)\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      10\n      JFK\n      PBI\n      -2.00\n    \n    \n      97\n      LGA\n      MCO\n      -18.00\n    \n    \n      29\n      EWR\n      ATL\n      -9.00\n    \n    \n      23\n      JFK\n      ATL\n      -8.00\n    \n    \n      39\n      LGA\n      BWI\n      -19.00\n    \n  \n\n\n\n\n\ndf2 = df[\"origin\"]\ndf2\n\n10    JFK\n97    LGA\n29    EWR\n23    JFK\n39    LGA\nName: origin, dtype: object\n\n\n\ndf2[:3]\n\n10    JFK\n97    LGA\n29    EWR\nName: origin, dtype: object\n\n\n\ndf2[[10, 29]]\n\n10    JFK\n29    EWR\nName: origin, dtype: object\n\n\n\ndf.loc[10:29, :]\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      10\n      JFK\n      PBI\n      -2.00\n    \n    \n      97\n      LGA\n      MCO\n      -18.00\n    \n    \n      29\n      EWR\n      ATL\n      -9.00"
  },
  {
    "objectID": "contents/subsetting.html#slicing",
    "href": "contents/subsetting.html#slicing",
    "title": "Subsetting",
    "section": "Slicing",
    "text": "Slicing\n\nSelecting rows\nUsing row numbers (inclusive of first index, exclusive of last)\nrow numbers가 index labels\n\ndf[100:103]\n\n\n\nSelecting rows and columns with chaining\n\ndf[['title', 'time']][100:103]\n\ndf[110:113][‘title’] = df[110:113][‘title’].str.lower() # warning copy\n\nflights.dest # 몇 가지 제약 존재: ex. 빈칸이 있는 변수명, method와 같은 이름의 변수명\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object\n\n\n\n\n\n\n\n\nWarning\n\n\n\n값을 assign할 때는 df[\"var\"]만을 쓸 것\n\n\n\nflights[\"dest\"]\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object"
  },
  {
    "objectID": "contents/subsetting.html#boolean-index",
    "href": "contents/subsetting.html#boolean-index",
    "title": "Subsetting",
    "section": "Boolean index",
    "text": "Boolean index"
  },
  {
    "objectID": "contents/subsetting.html#tips",
    "href": "contents/subsetting.html#tips",
    "title": "Subsetting",
    "section": "tips",
    "text": "tips\n-1 index\n\n[col for col in df.columns if col.startswith('mag')]\n\n\ndf[\n    ['title', 'time']\n    + [col for col in df.columns if col.startswith('mag')]\n]\n\n\nflights.loc[:, flights.columns.str.contains(\"time\")]"
  },
  {
    "objectID": "contents/subsetting.html#bracket",
    "href": "contents/subsetting.html#bracket",
    "title": "Subsetting",
    "section": "Bracket [ ]",
    "text": "Bracket [ ]\nBracket안에 labels이 있는 경우 columns을 select\n\nA single string: Series로 반환\n\nA list of a single string: DataFrame으로 반환\n\nA list of strings\n\n\nflights['dest'] # return as a Series\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object\n\n\n\nflights[['dest']] # return as a DataFrame\n\n\n\n\n\n\n\n  \n    \n      \n      dest\n    \n  \n  \n    \n      0\n      IAH\n    \n    \n      1\n      IAH\n    \n    \n      2\n      MIA\n    \n    \n      ...\n      ...\n    \n    \n      336773\n      BNA\n    \n    \n      336774\n      CLE\n    \n    \n      336775\n      RDU\n    \n  \n\n336776 rows × 1 columns\n\n\n\n\n\n\nflights[['origin', 'dest']]\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n    \n  \n  \n    \n      0\n      EWR\n      IAH\n    \n    \n      1\n      LGA\n      IAH\n    \n    \n      2\n      JFK\n      MIA\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      336773\n      LGA\n      BNA\n    \n    \n      336774\n      LGA\n      CLE\n    \n    \n      336775\n      LGA\n      RDU\n    \n  \n\n336776 rows × 2 columns\n\n\n\n\n\nBracket안에 numbers가 있는 경우 rows를 select - position-based\n\nSlicing만 허용\nFirst index는 포함, last index는 제외\n[1, 5, 8]과 같이 특정 rows를 선택하는 것은 허용안됨\n\n\nflights[2:5]\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      2\n      2013\n      1\n      1\n      542.00\n      540\n      2.00\n      923.00\n      850\n      33.00\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.00\n      1089\n      5\n      40\n    \n    \n      3\n      2013\n      1\n      1\n      544.00\n      545\n      -1.00\n      1004.00\n      1022\n      -18.00\n      B6\n      725\n      N804JB\n      JFK\n      BQN\n      183.00\n      1576\n      5\n      45\n    \n    \n      4\n      2013\n      1\n      1\n      554.00\n      600\n      -6.00\n      812.00\n      837\n      -25.00\n      DL\n      461\n      N668DN\n      LGA\n      ATL\n      116.00\n      762\n      6\n      0\n    \n  \n\n\n\n\n 만약, 아래와 같이 index가 number일 때 out of order가 된 경우에도 row position으로 적용됨\n\n\n\n\n\n\nTable 1:  df_outoforder \n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      42\n      LGA\n      DFW\n      48.00\n    \n    \n      2\n      JFK\n      MIA\n      33.00\n    \n    \n      25\n      EWR\n      ORD\n      32.00\n    \n    \n      14\n      LGA\n      DFW\n      31.00\n    \n    \n      33\n      EWR\n      MSP\n      29.00\n    \n  \n\n\n\n\n\n\ndf_outoforder[2:4]\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      25\n      EWR\n      ORD\n      32.00\n    \n    \n      14\n      LGA\n      DFW\n      31.00\n    \n  \n\n\n\n\n\n\n Chaining with brackets\n\nflights[['origin', 'dest']][2:5]\n# 순서 바꿔어도 동일: flights[2:5][['origin', 'dest']]\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n    \n  \n  \n    \n      2\n      JFK\n      MIA\n    \n    \n      3\n      JFK\n      BQN\n    \n    \n      4\n      LGA\n      ATL"
  },
  {
    "objectID": "contents/subsetting.html#주의",
    "href": "contents/subsetting.html#주의",
    "title": "Subsetting",
    "section": "주의",
    "text": "주의\n\ndf = flights[:100][[\"origin\", \"dest\", \"arr_delay\"]].nlargest(5, \"arr_delay\")\ndf\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      96\n      EWR\n      ORD\n      49.00\n    \n    \n      42\n      LGA\n      DFW\n      48.00\n    \n    \n      69\n      JFK\n      LAX\n      44.00\n    \n    \n      2\n      JFK\n      MIA\n      33.00\n    \n    \n      25\n      EWR\n      ORD\n      32.00\n    \n  \n\n\n\n\n\ndf.loc[42:2, :]\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      42\n      LGA\n      DFW\n      48.00\n    \n    \n      69\n      JFK\n      LAX\n      44.00\n    \n    \n      2\n      JFK\n      MIA\n      33.00\n    \n  \n\n\n\n\n\ns = df[\"dest\"]\ns\n\n96    ORD\n42    DFW\n69    LAX\n2     MIA\n25    ORD\nName: dest, dtype: object\n\n\n\ns[:3]\n\n96    ORD\n42    DFW\n69    LAX\nName: dest, dtype: object\n\n\n\ndf.iloc[:3, 1:3]\n\n\n\n\n\n  \n    \n      \n      dest\n      arr_delay\n    \n  \n  \n    \n      96\n      ORD\n      49.00\n    \n    \n      42\n      DFW\n      48.00\n    \n    \n      69\n      LAX\n      44.00\n    \n  \n\n\n\n\n\ndf = flights[['origin', 'dest', \"arr_delay\"]][:100].nlargest(5, \"arr_dealy\")\ndf = df.sample(5)\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      10\n      JFK\n      PBI\n      -2.00\n    \n    \n      97\n      LGA\n      MCO\n      -18.00\n    \n    \n      29\n      EWR\n      ATL\n      -9.00\n    \n    \n      23\n      JFK\n      ATL\n      -8.00\n    \n    \n      39\n      LGA\n      BWI\n      -19.00\n    \n  \n\n\n\n\n\ndf2 = df[\"origin\"]\ndf2\n\n10    JFK\n97    LGA\n29    EWR\n23    JFK\n39    LGA\nName: origin, dtype: object\n\n\n\ndf2[:3]\n\n10    JFK\n97    LGA\n29    EWR\nName: origin, dtype: object\n\n\n\ndf2[[10, 29]]\n\n10    JFK\n29    EWR\nName: origin, dtype: object\n\n\n\ndf.loc[10:29, :]\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      10\n      JFK\n      PBI\n      -2.00\n    \n    \n      97\n      LGA\n      MCO\n      -18.00\n    \n    \n      29\n      EWR\n      ATL\n      -9.00\n    \n  \n\n\n\n\n\ncopy vs. view\ndf[110:113][‘title’] = df[110:113][‘title’].str.lower() # warning copy\n\n# 경고대로 loc으로 대체\ndf.loc[110:112, 'title'] = df.loc[110:112, 'title'].str.lower()\n# 하지만, 100:112는 label-based, not position-based indexing\n# df[110:113]['title']: [100:113]는 position-based, ['title']는 label-based"
  },
  {
    "objectID": "contents/subsetting.html#dot-notation",
    "href": "contents/subsetting.html#dot-notation",
    "title": "Subsetting",
    "section": "Dot notation",
    "text": "Dot notation\n편리하나 주의해서 사용할 필요가 있음\n\n\n\n\n\n\nNote\n\n\n\n\nspace나 .이 있는 변수명 사용 불가\nmethods와 동일한 이름의 변수명 사용 불가: 예) 변수명이 count인 경우 df.count는 df의 method로 인식\n새로운 변수를 만들어 값을 assgin할 수 없음: 예) df.new_var = 1 불가, 대신 df[\"new_var\"] = 1\n만약, 변수 vars_names=[\"origin\", \"dest\"]을 지정했을 때,\n\ndf[vars_names]은 df[[\"orign\", \"dest\"]]과 동일\ndf.vars_names을 vars_names이라는 변수명을 지시\n\n\n\n\n\nflights.dest # flihgts[\"dest\"]와 동일\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object"
  },
  {
    "objectID": "contents/subsetting.html#loc과-.iloc",
    "href": "contents/subsetting.html#loc과-.iloc",
    "title": "Subsetting",
    "section": ".loc과 .iloc",
    "text": ".loc과 .iloc\n각각 location, integer location의 약자\n\nflights.iloc[[1, 3], :]\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      1\n      2013\n      1\n      1\n      533.00\n      529\n      4.00\n      850.00\n      830\n      20.00\n      UA\n      1714\n      N24211\n      LGA\n      IAH\n      227.00\n      1416\n      5\n      29\n    \n    \n      3\n      2013\n      1\n      1\n      544.00\n      545\n      -1.00\n      1004.00\n      1022\n      -18.00\n      B6\n      725\n      N804JB\n      JFK\n      BQN\n      183.00\n      1576\n      5\n      45\n    \n  \n\n\n\n\n\nSelecting rows and columns with chaining\n\ndf[['title', 'time']][100:103]\n\n\nflights.dest # 몇 가지 제약 존재: ex. 빈칸이 있는 변수명, method와 같은 이름의 변수명\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object\n\n\n\n\n\n\n\n\nWarning\n\n\n\n값을 assign할 때는 df[\"var\"]만을 쓸 것\n\n\n\nflights[\"dest\"]\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object"
  },
  {
    "objectID": "contents/subsetting.html#loc-.iloc",
    "href": "contents/subsetting.html#loc-.iloc",
    "title": "Subsetting",
    "section": ".loc & .iloc",
    "text": ".loc & .iloc\n각각 location, integer location의 약자\n\nflights.iloc[[1, 3], :]\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      1\n      2013\n      1\n      1\n      533.00\n      529\n      4.00\n      850.00\n      830\n      20.00\n      UA\n      1714\n      N24211\n      LGA\n      IAH\n      227.00\n      1416\n      5\n      29\n    \n    \n      3\n      2013\n      1\n      1\n      544.00\n      545\n      -1.00\n      1004.00\n      1022\n      -18.00\n      B6\n      725\n      N804JB\n      JFK\n      BQN\n      183.00\n      1576\n      5\n      45\n    \n  \n\n\n\n\n\nSelecting rows and columns with chaining\n\ndf[['title', 'time']][100:103]\n\n\nflights.dest # 몇 가지 제약 존재: ex. 빈칸이 있는 변수명, method와 같은 이름의 변수명\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object\n\n\n\n\n\n\n\n\nWarning\n\n\n\n값을 assign할 때는 df[\"var\"]만을 쓸 것\n\n\n\nflights[\"dest\"]\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object"
  },
  {
    "objectID": "contents/subsetting.html#loc-iloc",
    "href": "contents/subsetting.html#loc-iloc",
    "title": "Subsetting",
    "section": "loc & iloc",
    "text": "loc & iloc\n각각 location, integer location의 약자\ndf.(i)loc[row_indexer, column_indexer]\n\nloc: label-based indexing\n\nIndex가 number인 경우도 label로 처리\nSlicing의 경우 first, last index 모두 inclusive\n\n\nflights.loc[2:5, ['origin', 'dest']] # 2:5는 index의 label, not position\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n    \n  \n  \n    \n      2\n      JFK\n      MIA\n    \n    \n      3\n      JFK\n      BQN\n    \n    \n      4\n      LGA\n      ATL\n    \n    \n      5\n      EWR\n      ORD\n    \n  \n\n\n\n\n\n\n다음과 같이 index가 labels인 경우는 혼동의 염려 없음\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n    \n  \n  \n    \n      red\n      JFK\n      MIA\n    \n    \n      blue\n      JFK\n      BQN\n    \n    \n      green\n      LGA\n      ATL\n    \n    \n      yellow\n      EWR\n      ORD\n    \n  \n\n\n\n\n\n\ndf_labels.loc[\"blue\":\"green\", :]\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n    \n  \n  \n    \n      blue\n      JFK\n      BQN\n    \n    \n      green\n      LGA\n      ATL\n    \n  \n\n\n\n\n\n\n하지만, index가 number인 경우는 혼동이 있음\n앞서 본 예에서처럼 index가 out of order인 경우 loc은 다르게 작동\n\n\n\n\n\n\nTable 2:  df_outoforder \n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      42\n      LGA\n      DFW\n      48.00\n    \n    \n      2\n      JFK\n      MIA\n      33.00\n    \n    \n      25\n      EWR\n      ORD\n      32.00\n    \n    \n      14\n      LGA\n      DFW\n      31.00\n    \n    \n      33\n      EWR\n      MSP\n      29.00\n    \n  \n\n\n\n\n\n\ndf_outoforder.loc[2:14, :] # position 아님\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      2\n      JFK\n      MIA\n      33.00\n    \n    \n      25\n      EWR\n      ORD\n      32.00\n    \n    \n      14\n      LGA\n      DFW\n      31.00\n    \n  \n\n\n\n\n\n\n\ndf_outoforder.loc[[25, 33], :] # slicing이 아닌 특정 index 선택\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n      arr_delay\n    \n  \n  \n    \n      25\n      EWR\n      ORD\n      32.00\n    \n    \n      33\n      EWR\n      MSP\n      29.00\n    \n  \n\n\n\n\n\n\n\nflights.loc[2:5, 'dest'] # returns as a Series\n\n2    MIA\n3    BQN\n4    ATL\n5    ORD\nName: dest, dtype: object\n\n\n\nflights.loc[2:5, ['dest']] # return as a DataFrame\n\n\n\n\n\n\n\n  \n    \n      \n      dest\n    \n  \n  \n    \n      2\n      MIA\n    \n    \n      3\n      BQN\n    \n    \n      4\n      ATL\n    \n    \n      5\n      ORD\n    \n  \n\n\n\n\n\n\n\nflights.loc[2:5, :] # ':' means all\n# 다음 모두 가능\n# flights.loc[2:5]\n# flights.loc[2:5, ]\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      2\n      2013\n      1\n      1\n      542.00\n      540\n      2.00\n      923.00\n      850\n      33.00\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.00\n      1089\n      5\n      40\n    \n    \n      3\n      2013\n      1\n      1\n      544.00\n      545\n      -1.00\n      1004.00\n      1022\n      -18.00\n      B6\n      725\n      N804JB\n      JFK\n      BQN\n      183.00\n      1576\n      5\n      45\n    \n    \n      4\n      2013\n      1\n      1\n      554.00\n      600\n      -6.00\n      812.00\n      837\n      -25.00\n      DL\n      461\n      N668DN\n      LGA\n      ATL\n      116.00\n      762\n      6\n      0\n    \n    \n      5\n      2013\n      1\n      1\n      554.00\n      558\n      -4.00\n      740.00\n      728\n      12.00\n      UA\n      1696\n      N39463\n      EWR\n      ORD\n      150.00\n      719\n      5\n      58\n    \n  \n\n\n\n\n\n# select a single row\nflights.loc[2, :] # returns as a Series, column names as its index\n\nyear        2013\nmonth          1\nday            1\n            ... \ndistance    1089\nhour           5\nminute        40\nName: 2, Length: 18, dtype: object\n\n\n\n\n\niloc: position-based indexing\n\nSlicing의 경우 as usual: first index는 inclusive, last index는 exclusive\n\n\nflights.iloc[2:5, 12:14] # 2:5는 index의 position, last index는 미포함\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n    \n  \n  \n    \n      2\n      JFK\n      MIA\n    \n    \n      3\n      JFK\n      BQN\n    \n    \n      4\n      LGA\n      ATL\n    \n  \n\n\n\n\n\n\n\nflights.iloc[2:5, 12] # return as a Series\n\n2    JFK\n3    JFK\n4    LGA\nName: origin, dtype: object\n\n\n\nflights.iloc[2:5, :]\n# 다음 모두 가능\n# flights.iloc[2:5]\n# flights.iloc[2:5, ]\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      day\n      dep_time\n      sched_dep_time\n      dep_delay\n      arr_time\n      sched_arr_time\n      arr_delay\n      carrier\n      flight\n      tailnum\n      origin\n      dest\n      air_time\n      distance\n      hour\n      minute\n    \n  \n  \n    \n      2\n      2013\n      1\n      1\n      542.00\n      540\n      2.00\n      923.00\n      850\n      33.00\n      AA\n      1141\n      N619AA\n      JFK\n      MIA\n      160.00\n      1089\n      5\n      40\n    \n    \n      3\n      2013\n      1\n      1\n      544.00\n      545\n      -1.00\n      1004.00\n      1022\n      -18.00\n      B6\n      725\n      N804JB\n      JFK\n      BQN\n      183.00\n      1576\n      5\n      45\n    \n    \n      4\n      2013\n      1\n      1\n      554.00\n      600\n      -6.00\n      812.00\n      837\n      -25.00\n      DL\n      461\n      N668DN\n      LGA\n      ATL\n      116.00\n      762\n      6\n      0\n    \n  \n\n\n\n\n\nflights.iloc[2:5, [12]] # return as a DataFrame\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n    \n  \n  \n    \n      2\n      JFK\n    \n    \n      3\n      JFK\n    \n    \n      4\n      LGA\n    \n  \n\n\n\n\n\n\n\nflights.iloc[[2, 5, 7], 12:14] # 특정 위치의 rows 선택\n\n\n\n\n\n\n\n  \n    \n      \n      origin\n      dest\n    \n  \n  \n    \n      2\n      JFK\n      MIA\n    \n    \n      5\n      EWR\n      ORD\n    \n    \n      7\n      LGA\n      IAD"
  },
  {
    "objectID": "contents/subsetting.html#dot-notation-.",
    "href": "contents/subsetting.html#dot-notation-.",
    "title": "Subsetting",
    "section": "Dot notation .",
    "text": "Dot notation .\n편리하나 주의해서 사용할 필요가 있음\n\n\n\n\n\n\nNote\n\n\n\n\nspace 또는 . 이 있는 변수명 사용 불가\nmethods와 동일한 이름의 변수명 사용 불가: 예) 변수명이 count인 경우 df.count는 df의 method로 인식\n새로운 변수를 만들어 값을 assgin할 수 없음: 예) df.new_var = 1 불가, 대신 df[\"new_var\"] = 1\n만약, 다음과 같이 변수을 지정했을 때 vars_names=[\"origin\", \"dest\"],\n\ndf[vars_names]는 \"orign\"과 \"dest\" columns을 선택\ndf.vars_names는 vars_names이라는 이름의 column을 의미\n\n\n\n\n\nflights.dest # flihgts[\"dest\"]와 동일\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object"
  },
  {
    "objectID": "contents/subsetting.html#series의-indexing",
    "href": "contents/subsetting.html#series의-indexing",
    "title": "Subsetting",
    "section": "Series의 indexing",
    "text": "Series의 indexing\nDataFrame과 같은 방식으로 이해\nIndex가 numbers인 경우\n\n\n42    DFW\n2     MIA\n25    ORD\n14    DFW\n33    MSP\nName: dest, dtype: object\n\n\n\ns.loc[25:14]\n\n25    ORD\n14    DFW\nName: dest, dtype: object\n\n\n\ns.iloc[2:4]\n\n25    ORD\n14    DFW\nName: dest, dtype: object\n\n\n\ns[:3]\n\n42    DFW\n2     MIA\n25    ORD\nName: dest, dtype: object\n\n\n\n\n\n\n\n\nNote\n\n\n\n다음과 같은 경우 혼동스러움\ns[3] # 3번째? label 3?\n#> errors occur\n\n\n Index가 lables인 경우\n\n\nred       MIA\nblue      BQN\ngreen     ATL\nyellow    ORD\nName: dest, dtype: object\n\n\n\ns[[\"red\", \"green\"]]\n\nred      MIA\ngreen    ATL\nName: dest, dtype: object"
  },
  {
    "objectID": "contents/subsetting.html#boolean-indexing",
    "href": "contents/subsetting.html#boolean-indexing",
    "title": "Subsetting",
    "section": "Boolean indexing",
    "text": "Boolean indexing\n\nBracket [ ] 이나 loc을 이용\niloc은 적용 안됨\n\n\nBracket [ ]\n\nnp.random.seed(123)\nflights_6 = flights[:100][[\"dep_delay\", \"arr_delay\", \"origin\", \"dest\"]].sample(6)\nflights_6\n\n\n\n\n\n\n\n  \n    \n      \n      dep_delay\n      arr_delay\n      origin\n      dest\n    \n  \n  \n    \n      8\n      -3.00\n      -8.00\n      JFK\n      MCO\n    \n    \n      70\n      9.00\n      20.00\n      LGA\n      ORD\n    \n    \n      82\n      -1.00\n      -26.00\n      JFK\n      SFO\n    \n    \n      28\n      0.00\n      -21.00\n      JFK\n      SJU\n    \n    \n      63\n      -2.00\n      2.00\n      JFK\n      LAX\n    \n    \n      0\n      2.00\n      11.00\n      EWR\n      IAH\n    \n  \n\n\n\n\n\n\n\nflights_6[flights_6[\"dep_delay\"] < 0]\n\n\n\n\n\n\n\n  \n    \n      \n      dep_delay\n      arr_delay\n      origin\n      dest\n      delayed\n    \n  \n  \n    \n      8\n      -3.00\n      -8.00\n      JFK\n      MCO\n      delayed\n    \n    \n      82\n      -1.00\n      -26.00\n      JFK\n      SFO\n      delayed\n    \n    \n      63\n      -2.00\n      2.00\n      JFK\n      LAX\n      delayed\n    \n  \n\n\n\n\n\n\n\nidx = flights_6[\"dep_delay\"] < 0\nidx # bool type의 Series\n\n8      True\n70    False\n82     True\n28    False\n63     True\n0     False\nName: dep_delay, dtype: bool\n\n\n\n# Select a column with the boolean indexing\nflights_6[idx][\"dest\"]\n\n8     MCO\n82    SFO\n63    LAX\nName: dest, dtype: object\n\n\n\n\n\n\n\n\nNote\n\n\n\n사실, boolean indexing을 할때, DataFrame/Series의 index와 match함\n대부분 염려하지 않아도 되나 다음과 같은 결과 참고\n# Reset index\nidx_reset = idx.reset_index(drop=True)\n# 0     True\n# 1    False\n# 2     True\n# 3    False\n# 4     True\n# 5    False\n# Name: dep_delay, dtype: bool\n\nflights_6[idx_reset][\"dest\"]\n#> IndexingError: Unalignable boolean Series provided as indexer \n#> (index of the boolean Series and of the indexed object do not match)\n\n# Index가 없는 numpy array로 boolean indexing을 하는 경우 문제없음\nflights_6[idx_reset.to_numpy()][\"dest\"]\n# 8     MCO\n# 82    SFO\n# 63    LAX\n# Name: dest, dtype: object\n\n\n\nbool_idx = flights_6[[\"dep_delay\", \"arr_delay\"]] > 0\nbool_idx\n\n\n\n\n\n\n\n  \n    \n      \n      dep_delay\n      arr_delay\n    \n  \n  \n    \n      8\n      False\n      False\n    \n    \n      70\n      True\n      True\n    \n    \n      82\n      False\n      False\n    \n    \n      28\n      False\n      False\n    \n    \n      63\n      False\n      True\n    \n    \n      0\n      True\n      True\n    \n  \n\n\n\n\n\n\n\nidx_any = bool_idx.any(axis=1)\nidx_any\n\n8     False\n70     True\n82    False\n28    False\n63     True\n0      True\ndtype: bool\n\n\n\n\nnp.where() 활용\nnp.where(boolean condition, value if True, value if False)\n\nflights_6[\"delayed\"] = np.where(idx, \"delayed\", \"on-time\")\nflights_6\n\n\n\n\n\n  \n    \n      \n      dep_delay\n      arr_delay\n      origin\n      dest\n      delayed\n    \n  \n  \n    \n      8\n      -3.00\n      -8.00\n      JFK\n      MCO\n      delayed\n    \n    \n      70\n      9.00\n      20.00\n      LGA\n      ORD\n      on-time\n    \n    \n      82\n      -1.00\n      -26.00\n      JFK\n      SFO\n      delayed\n    \n    \n      28\n      0.00\n      -21.00\n      JFK\n      SJU\n      on-time\n    \n    \n      63\n      -2.00\n      2.00\n      JFK\n      LAX\n      delayed\n    \n    \n      0\n      2.00\n      11.00\n      EWR\n      IAH\n      on-time\n    \n  \n\n\n\n\n\nnp.where(flights_6[\"dest\"].str.startswith(\"S\"), \"S\", \"T\") # str method: \"S\"로 시작하는지 여부\n\narray(['T', 'T', 'S', 'S', 'T', 'T'], dtype='<U1')\n\n\n\nbool_idx.all(axis=1)\n\n8      True\n70    False\n82     True\n28    False\n63    False\n0     False\ndtype: bool\n\n\n\n\nloc\n\nflights_6.loc[idx, \"dest\"] # flights_6[idx][\"dest\"]과 동일\n\n8     MCO\n82    SFO\n63    LAX\nName: dest, dtype: object\n\n\n만약 column 이름에 “time”을 포함하는 columns만 선택하고자 하면\n\nSeries/Index object는 str method 존재\nstr.contains(), str.startswith(), str.endswith()\n자세한 사항은 7.4 String Manipulation/String Functions in pandas by Wes McKinney\n\n\ncols = flights.columns.str.contains(\"time\") # str method: \"time\"을 포함하는지 여부\ncols\n\narray([False, False, False,  True,  True, False,  True,  True, False,\n       False, False, False, False, False,  True, False, False, False])\n\n\n\n# Columns 쪽으로 boolean indexing\nflights.loc[:, cols]\n\n\n\n\n\n  \n    \n      \n      dep_time\n      sched_dep_time\n      arr_time\n      sched_arr_time\n      air_time\n    \n  \n  \n    \n      0\n      517.00\n      515\n      830.00\n      819\n      227.00\n    \n    \n      1\n      533.00\n      529\n      850.00\n      830\n      227.00\n    \n    \n      2\n      542.00\n      540\n      923.00\n      850\n      160.00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      336773\n      NaN\n      1210\n      NaN\n      1330\n      NaN\n    \n    \n      336774\n      NaN\n      1159\n      NaN\n      1344\n      NaN\n    \n    \n      336775\n      NaN\n      840\n      NaN\n      1020\n      NaN\n    \n  \n\n336776 rows × 5 columns\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nChained indexing으로 값을 assign하는 경우 copy vs. view 경고 메세지\nflights[flights[\"arr_delay\"] < 0][\"arr_delay\"] = 0\n/var/folders/mp/vcywncl97ml2q4c_5k2r573m0000gn/T/ipykernel_96692/3780864177.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n 경고가 제시하는데로 .loc을 이용하여 assign\nflights.loc[flights[\"arr_delay\"] < 0, \"arr_delay\"] = 0"
  },
  {
    "objectID": "contents/pandas.html#missing",
    "href": "contents/pandas.html#missing",
    "title": "NumPy and pandas",
    "section": "Missing",
    "text": "Missing\nNULL, NaN, NA inf, -inf\nWorking with missing data\nMcKinney, p.233"
  },
  {
    "objectID": "contents/subsetting.html#summary",
    "href": "contents/subsetting.html#summary",
    "title": "Subsetting",
    "section": "Summary",
    "text": "Summary\n\nBracket [ ]의 경우\n\n간단히 columns을 선택하고자 할때 column labels: df[[\"var1\", \"var2\"]]\n간단히 rows를 선택하고자 할때 numerical indexing: df[:10]\n\nDot-notation은\n\npandas의 methods와 중복된 이름을 피하고,\nassignment의 왼편에는 사용을 피할 것\n\n가능하면 분명한 loc 또는 iloc을 사용\n\nloc[:, [\"var1\", \"var2\"]]는 df[[\"var1\", \"var2\"]]과 동일\niloc[:10, :]은 df[:10]와 동일\nloc의 경우, index가 숫자라 할지라도 label로 처리됨\nloc은 iloc과는 다른게 first, last index 모두 inclusive\n\nBoolean indexing의 경우\n\nBracket [ ]: df[bool_idx]\nloc: df.loc[bool_idx, :]\niloc 불가\n\nAssignment를 할때는,\n\nchained indexing을 피하고: df[:5][\"dest\"]\nloc or iloc 사용:\n\ndf.loc[:4, \"dest\"]: index가 0부터 정렬되어 있다고 가정했을 때, slicing에서 위치 하나 차이남\ndf.iloc[:5, 13]: “dest”의 column 위치 13\n\n\n한 개의 column 혹은 row을 선택하면 Series로 반환: df[\"var1\"] 또는 df.loc[2, :]"
  },
  {
    "objectID": "contents/transform.html#groups-1",
    "href": "contents/transform.html#groups-1",
    "title": "Transforming",
    "section": "Groups",
    "text": "Groups\nmap, mapapply, apply"
  },
  {
    "objectID": "contents/pandas2.html",
    "href": "contents/pandas2.html",
    "title": "NumPy and pandas",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\nNumpy & pandas\nPython 언어는 수치 계산을 위해 디자인되지 않았기 때문에, 데이터 분석에 대한 효율적이고 빠른 계산이 요구되면서 C/C++이라는 언어로 구현된 NumPy (Numerical Python)가 탄생하였고, Python 생태계 안에 통합되었음. 기본적으로 Python 언어 안에 새로운 언어라고 볼 수 있음. 데이터 사이언스에서의 대부분의 계산은 NumPy의 ndarray (n-dimensioal array)와 수학적 operator들을 통해 계산됨.\n데이터 사이언스가 발전함에 따라 단일한 floating-point number들을 성분으로하는 array들의 계산에서 벗어나 columns별로 다른 데이터 타입(string, integer, object..)을 포함하는 tabular형태의 데이터를 효율적으로 처리해야 할 필요성이 나타났고, 이를 다룰 수 있는 새로운 언어를 NumPy 위에 개발한 것이 pandas임. 이는 기본적으로 Wes Mckinney에 의해 독자적으로 개발이 시작되었으며, 디자인적으로 불만족스러운 점이 지적되고는 있으나 데이터 사이언스의 기본적인 언어가 되었음.\nNumPy와 pandas에 대한 자세한 내용은 Python for Data Analysis by Wes MacKinney 참고\n특히, NumPy는 Ch.4 & appendices"
  },
  {
    "objectID": "contents/pandas2.html#numpy",
    "href": "contents/pandas2.html#numpy",
    "title": "NumPy and pandas",
    "section": "NumPy",
    "text": "NumPy\n\n수학적 symbolic 연산에 대한 구현이라고 볼 수 있으며,\n행렬(matrix) 또는 벡터(vector)를 ndarray (n-dimensional array)이라는 이름으로 구현함.\n\n사실상 정수(int)나 실수(float)의 한가지 타입으로 이루어짐.\n\n고차원의 arrays 가능\n\nSource: Medium.com\n\n\n가령, 다음과 같은 matrix 연산이 있다면,\n\\(\\begin{bmatrix}1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix} \\begin{bmatrix}2 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix}0 \\\\ 2 \\\\ 4 \\end{bmatrix}\\)\n\n\nimport numpy as np  # import numpy package\n\nA = np.array([[1, 2],\n              [3, 4],\n              [5, 6]]) # 3x2 matrix\nX = np.array([[2],\n              [-1]]) # 2x1 matrix\n\n\nA @ X  # A * X : matrix multiplication\n\narray([[0],\n       [2],\n       [4]])\n\n\n\nA.dot(X) # same as A @ X\n\narray([[0],\n       [2],\n       [4]])\n\n\nVector vs. Matrix\n\narr1 = np.array([0, 2, 4]) # 1-dim matrix: vector\narr2 = np.array([[0, 2, 4]]) # 2-dim 1x3 matrix\narr3 = np.array([[0],\n                 [2],\n                 [4]]) # 2-dim 3x1 matrix\n\nprint(arr1); print(arr2); print(arr3)\n\n[0 2 4]\n[[0 2 4]]\n[[0]\n [2]\n [4]]\n\n\n\nprint(arr1.shape); print(arr2.shape); print(arr3.shape)\n\n(3,)\n(1, 3)\n(3, 1)\n\n\n\nA + A # element-wise addition\n\narray([[ 2,  4],\n       [ 6,  8],\n       [10, 12]])\n\n\n\n2 * A - 1 # recycling rule\n\narray([[ 1,  3],\n       [ 5,  7],\n       [ 9, 11]])\n\n\n\nnp.exp(A) # element-wise\n\narray([[  2.72,   7.39],\n       [ 20.09,  54.6 ],\n       [148.41, 403.43]])\n\n\n\nnp.add(A, A)\n\narray([[ 2,  4],\n       [ 6,  8],\n       [10, 12]])\n\n\n\nnp.power(A, 2)\n\narray([[ 1,  4],\n       [ 9, 16],\n       [25, 36]])\n\n\n\n\nSource: Python for Data Analysis (3e) by Wes MacKinney\n\nPython vs. NumPy\n\n2**31\n\n2147483648\n\n\n\nnp.array([2**31]) # dtype='int64'\n\narray([2147483648])\n\n\nNumPy의 data type\n\na = np.array([2**31-1], dtype='int32')\na + 1\n\narray([-2147483648], dtype=int32)\n\n\n\nSource: Python for Data Analysis (3e) by Wes MacKinney"
  },
  {
    "objectID": "contents/pandas2.html#pandas",
    "href": "contents/pandas2.html#pandas",
    "title": "NumPy and pandas",
    "section": "pandas",
    "text": "pandas\nSeries & DataFrame\n\nSeries\n\n1개의 column으로 이루어진 data format\n\nNumPy array에 labels을 붙인 것으로 볼 수 있음: index\n\nDataFrame의 각 칼럼들을 Series로 이해할 수 있음\n\n\nSource: Practical data science\n\n\nDataFrame\n\n\n   total_bill  tip     sex smoker  day    time  size\n0       16.99 1.01  Female     No  Sun  Dinner     2\n1       10.34 1.66    Male     No  Sun  Dinner     3\n2       21.01 3.50    Male     No  Sun  Dinner     3\n3       23.68 3.31    Male     No  Sun  Dinner     2\n4       24.59 3.61  Female     No  Sun  Dinner     4\n...\n244 rows × 7 columns\n\n\n각 column들이 한 가지 data type으로 이루어진 tabular형태 (2d)의 data format\n\n각 column은 기본적으로 한 가지 data type인 것이 이상적이나, 다른 타입이 섞여 있을 수 있음\nNumPy의 2-dim array의 각 column에 labels을 부여한 것으로 볼 수도 있으나, 여러 다른 기능들이 추가됨\nNumPy의 경우 고차원의 array를 다룰 수 있음: ndarray\n\n고차원의 DataFrame과 비슷한 것은 xarray가 존재\n\nLabels와 index를 제외한 데이터 값은 거의 NumPy ndarray로 볼 수 있음\n(pandas.array 존재)\n\n\nSource: Practical data science\n\n\nNumPy array <> pandas DataFrame\n\nimport pandas as pd  # import pandas package\n\n\n\n\n\nA = np.array([[1, 2],\n              [3, 4],\n              [5, 6]]) # 3x2 matrix\nA\n\narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n\n\ndf = pd.DataFrame(A, columns=[\"A1\", \"A2\"]) # A1, A2: column labels\ndf\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n      A2\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n    \n    \n      2\n      5\n      6\n    \n  \n\n\n\n\n\n\n\ndf2 = pd.DataFrame(A, \n                   columns=[\"A1\", \"A2\"], # A1, A2: column labels\n                   index=[\"red\", \"blue\", \"green\"]) # index labels\ndf2\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n      A2\n    \n  \n  \n    \n      red\n      1\n      2\n    \n    \n      blue\n      3\n      4\n    \n    \n      green\n      5\n      6\n    \n  \n\n\n\n\n\n\n\n# 데이터 값들은 NumPy array\ndf2.values\n\narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n\n\ntype(df2)\n\npandas.core.frame.DataFrame\n\n\n\n\nColumns\nSeries로 추출\n\ns = df2[\"A1\"] # select a column A1\ns\n# DataFrame의 column label이 Series의 name으로 전환\n\nred      1\nblue     3\ngreen    5\nName: A1, dtype: int64\n\n\n\ntype(s)\n\npandas.core.series.Series\n\n\n\n\n\n\n\nIndex objects\n\nframe = pd.DataFrame(np.arange(6).reshape((2, 3)),\n                     index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n                     columns=pd.Index([\"one\", \"two\", \"three\"], name=\"number\"))\nframe\n\n\n\n\n\n\n\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Ohio\n      0\n      1\n      2\n    \n    \n      Colorado\n      3\n      4\n      5\n    \n  \n\n\n\n\n\n\n\nframe.index\n\nIndex(['Ohio', 'Colorado'], dtype='object', name='state')\n\n\n\nframe.columns # columns도 index object\n\nIndex(['one', 'two', 'three'], dtype='object', name='number')\n\n\n\n\n\n\n\n\nNote\n\n\n\n“number”: columns의 이름 “state”: index의 이름\nframe.columns.name #> ‘number’\nframe.index.name #> ‘state’\n\n\n\nMulti-Index ojbect\nIndex는 여러 levels을 지닐 수 있음\n\nprint(frame)\n\n\n\nnumber    one  two  three\nstate                    \nOhio        0    1      2\nColorado    3    4      5\n\n\n\n\n\nframe.stack() # stack()은 long form으로 변환\n# 2 levels의 index를 가진 Series\n\nstate     number\nOhio      one       0\n          two       1\n          three     2\nColorado  one       3\n          two       4\n          three     5\ndtype: int64\n\n\n\n# MultiIndex를 직접 구성\ndf = pd.DataFrame(np.arange(12).reshape((4, 3)),\n        index=pd.MultiIndex.from_arrays([[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]], names=[\"idx1\", \"idx2\"]),\n        columns=pd.MultiIndex.from_arrays([[\"Ohio\", \"Ohio\", \"Colorado\"], [\"Green\", \"Red\", \"Green\"]], names=[\"state\", \"color\"]))\n\n\n\n\n\n\nstate      Ohio     Colorado\ncolor     Green Red    Green\nidx1 idx2                   \na    1        0   1        2\n     2        3   4        5\nb    1        6   7        8\n     2        9  10       11\n\n\n\n\nTime Series\nIndex는 times series에 특화\n\nfb = pd.read_csv('data/fb_stock_prices_2018.csv', index_col='date', parse_dates=True)\nfb.head()\n\n\n\n\n\n  \n    \n      \n      open\n      high\n      low\n      close\n      volume\n    \n    \n      date\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2018-01-02\n      177.68\n      181.58\n      177.55\n      181.42\n      18151903\n    \n    \n      2018-01-03\n      181.88\n      184.78\n      181.33\n      184.67\n      16886563\n    \n    \n      2018-01-04\n      184.90\n      186.21\n      184.10\n      184.33\n      13880896\n    \n    \n      2018-01-05\n      185.59\n      186.90\n      184.93\n      186.85\n      13574535\n    \n    \n      2018-01-08\n      187.20\n      188.90\n      186.33\n      188.28\n      17994726\n    \n  \n\n\n\n\nPlot method을 이용해 간단히 trendline을 구할 수 있음\n\nfb.plot(kind='line', y=['high', 'low'], figsize=(7, 4), title='Facebook Stock 2018')\nplt.show()\n\n\n\n\nindex없이 분석 가능?\nIndex를 column으로 전환시켜 index에 신경쓰지 않고 분석할 수도 있음\nindex의 활용은 강의 후반부에…\n\nfb.reset_index() # index into a column\n\n\n\n\n\n  \n    \n      \n      date\n      open\n      high\n      low\n      close\n      volume\n    \n  \n  \n    \n      0\n      2018-01-02\n      177.68\n      181.58\n      177.55\n      181.42\n      18151903\n    \n    \n      1\n      2018-01-03\n      181.88\n      184.78\n      181.33\n      184.67\n      16886563\n    \n    \n      2\n      2018-01-04\n      184.90\n      186.21\n      184.10\n      184.33\n      13880896\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      248\n      2018-12-27\n      132.44\n      134.99\n      129.67\n      134.52\n      31202509\n    \n    \n      249\n      2018-12-28\n      135.34\n      135.92\n      132.20\n      133.20\n      22627569\n    \n    \n      250\n      2018-12-31\n      134.45\n      134.64\n      129.95\n      131.09\n      24625308\n    \n  \n\n251 rows × 6 columns\n\n\n\n\n\n\n\n\nDataFrame의 연산\nNumPy의 ndarray들이 연산되는 방식과 동일하게 series나 DataFrame들의 연산 가능함\n\ndf + 2 * df\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n      A2\n    \n  \n  \n    \n      0\n      3\n      6\n    \n    \n      1\n      9\n      12\n    \n    \n      2\n      15\n      18\n    \n  \n\n\n\n\n\n\n\nnp.log(df)\n\n\n\n\n\n\n\n  \n    \n      \n      A1\n      A2\n    \n  \n  \n    \n      0\n      0.00\n      0.69\n    \n    \n      1\n      1.10\n      1.39\n    \n    \n      2\n      1.61\n      1.79\n    \n  \n\n\n\n\n\n\n사실, 연산은 index를 align해서 시행됨\n\n\n\n\n\n\nframe1\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Ohio\n      0\n      1\n      2\n    \n    \n      Colorado\n      3\n      4\n      5\n    \n  \n\n\n\n\n\n\n\nframe2\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Ohio\n      0\n      2\n      4\n    \n    \n      Floria\n      6\n      8\n      10\n    \n  \n\n\n\n\n\n\nframe1 + frame2\n\n\n\n\n\n\n\n  \n    \n      number\n      one\n      two\n      three\n    \n    \n      state\n      \n      \n      \n    \n  \n  \n    \n      Colorado\n      NaN\n      NaN\n      NaN\n    \n    \n      Floria\n      NaN\n      NaN\n      NaN\n    \n    \n      Ohio\n      0.00\n      3.00\n      6.00\n    \n  \n\n\n\n\n\n\n\n(참고) Mixed Data Type\n\ns = pd.Series([1, 2, \"3\"])\n\n\ns.dtype # object dtype\n\ndtype('O')\n\n\n\ns + s  # \"3\" + \"3\" (string): concaternated\n\n0     2\n1     4\n2    33\ndtype: object\n\n\n\ns_int = s.astype(\"int\") # astype: type conversion\ns_int + s_int\n\n0    2\n1    4\n2    6\ndtype: int64\n\n\n\ns2 = pd.Series([1, 2, 3.6]) # automatic type conversion to floating numbers\ns2.dtype\n\ndtype('float64')\n\n\n\ns2.astype(\"int\") # force type conversion >> floor\n\n0    1\n1    2\n2    3\ndtype: int64"
  },
  {
    "objectID": "contents/pandas2.html#missing",
    "href": "contents/pandas2.html#missing",
    "title": "NumPy and pandas",
    "section": "Missing",
    "text": "Missing\nNULL, NaN, NA inf, -inf\nWorking with missing data\nMcKinney, p.233"
  },
  {
    "objectID": "contents/pandas2.html#copy-vs.-view",
    "href": "contents/pandas2.html#copy-vs.-view",
    "title": "NumPy and pandas",
    "section": "Copy vs. View",
    "text": "Copy vs. View"
  },
  {
    "objectID": "contents/pandas2.html#attributes",
    "href": "contents/pandas2.html#attributes",
    "title": "NumPy and pandas",
    "section": "Attributes",
    "text": "Attributes\nHere are some commonly used attributes with Series objects:\n\n\n\n\n\n\n\nAttribute\nReturns\n\n\n\n\nname\nThe name of the Series object\n\n\ndtype\nThe data type of the Series object\n\n\nshape\nDimensions of the Series object in a tuple of the form (number of rows,)\n\n\nindex\nThe Index object that is part of the Series object\n\n\nvalues\nThe data in the Series object\n\n\n\nHere are some commonly used attributes with Index objects:\n\n\n\nAttribute\nReturns\n\n\n\n\nname\nThe name of the Index object\n\n\ndtype\nThe data type of the Index object\n\n\nshape\nDimensions of the Index object\n\n\nvalues\nThe data in the Index object\n\n\nis_unique\nCheck if the Index object has all unique values\n\n\n\nHere are some commonly used attributes:\n\n\n\n\n\n\n\nAttribute\nReturns\n\n\n\n\ndtypes\nThe data types of each column\n\n\nshape\nDimensions of the DataFrame object in a tuple of the form (number of rows, number of columns)\n\n\nindex\nThe Index object along the rows of the DataFrame object\n\n\ncolumns\nThe name of the columns (as an Index object)\n\n\nvalues\nThe data in the DataFrame object\n\n\nempty\nCheck if the DataFrame object is empty"
  },
  {
    "objectID": "contents/pandas2.html#creating-dataframes",
    "href": "contents/pandas2.html#creating-dataframes",
    "title": "NumPy and pandas",
    "section": "Creating DataFrames",
    "text": "Creating DataFrames"
  },
  {
    "objectID": "contents/inspection.html#useful-method",
    "href": "contents/inspection.html#useful-method",
    "title": "Inspecting data",
    "section": "Useful method",
    "text": "Useful method\n.head(), .tail(), .sample()\n.info(), .describe(),\n.value_counts(),\n.sort_values(), .nlargest()\n\nLoading a Dataset: Tips\n일정기간 한 웨이터가 얻은 팁에 대한 데이터\n\ntips = sns.load_dataset(\"tips\")\ntips\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n    \n  \n\n244 rows × 7 columns\n\n\n\n\n# \ntips.values\n\narray([[16.99, 1.01, 'Female', ..., 'Sun', 'Dinner', 2],\n       [10.34, 1.66, 'Male', ..., 'Sun', 'Dinner', 3],\n       [21.01, 3.5, 'Male', ..., 'Sun', 'Dinner', 3],\n       ...,\n       [22.67, 2.0, 'Male', ..., 'Sat', 'Dinner', 2],\n       [17.82, 1.75, 'Male', ..., 'Sat', 'Dinner', 2],\n       [18.78, 3.0, 'Female', ..., 'Thur', 'Dinner', 2]], dtype=object)\n\n\n\ntips.head() # 처음 N개 나열\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n    \n  \n\n\n\n\n\ntips.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   total_bill  244 non-null    float64 \n 1   tip         244 non-null    float64 \n 2   sex         244 non-null    category\n 3   smoker      244 non-null    category\n 4   day         244 non-null    category\n 5   time        244 non-null    category\n 6   size        244 non-null    int64   \ndtypes: category(4), float64(2), int64(1)\nmemory usage: 7.4 KB\n\n\n\ntips.describe() # numerical type만 나열\n\n\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      size\n    \n  \n  \n    \n      count\n      244.00\n      244.00\n      244.00\n    \n    \n      mean\n      19.79\n      3.00\n      2.57\n    \n    \n      std\n      8.90\n      1.38\n      0.95\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      50%\n      17.80\n      2.90\n      2.00\n    \n    \n      75%\n      24.13\n      3.56\n      3.00\n    \n    \n      max\n      50.81\n      10.00\n      6.00\n    \n  \n\n8 rows × 3 columns\n\n\n\n\n\n\ntips.describe(include=\"all\") # all types 나열\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      count\n      244.00\n      244.00\n      244\n      244\n      244\n      244\n      244.00\n    \n    \n      unique\n      NaN\n      NaN\n      2\n      2\n      4\n      2\n      NaN\n    \n    \n      top\n      NaN\n      NaN\n      Male\n      No\n      Sat\n      Dinner\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      50%\n      17.80\n      2.90\n      NaN\n      NaN\n      NaN\n      NaN\n      2.00\n    \n    \n      75%\n      24.13\n      3.56\n      NaN\n      NaN\n      NaN\n      NaN\n      3.00\n    \n    \n      max\n      50.81\n      10.00\n      NaN\n      NaN\n      NaN\n      NaN\n      6.00\n    \n  \n\n11 rows × 7 columns\n\n\n\n\ntips.describe(include=\"category\")\n\n\n\n\n\n\n\n  \n    \n      \n      sex\n      smoker\n      day\n      time\n    \n  \n  \n    \n      count\n      244\n      244\n      244\n      244\n    \n    \n      unique\n      2\n      2\n      4\n      2\n    \n    \n      top\n      Male\n      No\n      Sat\n      Dinner\n    \n    \n      freq\n      157\n      151\n      87\n      176\n    \n  \n\n\n\n\n\n\n\ns1 = tips[\"day\"].value_counts() # \"day\" 칼럼을 선택 후 각 카테고리별 counts\ns2 = tips[\"day\"].value_counts(sort=False) # default: sort is true\ns3 = tips[\"day\"].value_counts(normalize=True) # 카테고리별 비율\ns4 = tips[[\"sex\", \"smoker\"]].value_counts() # \"sex\", \"smoker\" 칼럼을 선택 후 유니크한 카테고리별 counts\n\n\n\n\n\n\nSat     87\nSun     76\nThur    62\nFri     19\nName: day, dtype: int64\n(a) s1\n\n\n\n\nThur    62\nFri     19\nSat     87\nSun     76\nName: day, dtype: int64\n(b) s2\n\n\n\n\n\n\nSat    0.36\nSun    0.31\nThur   0.25\nFri    0.08\nName: day, dtype: float64\n(c) s3\n\n\n\n\nsex     smoker\nMale    No        97\n        Yes       60\nFemale  No        54\n        Yes       33\ndtype: int64\n(d) s4\n\n\n\nFigure 1: value_count() arguments\n\n\n\n\n\nLoading a Dataset: Penguins\n\npenguins = sns.load_dataset(\"penguins\")\npenguins\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.10\n      18.70\n      181.00\n      3750.00\n      Male\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.50\n      17.40\n      186.00\n      3800.00\n      Female\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.30\n      18.00\n      195.00\n      3250.00\n      Female\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      341\n      Gentoo\n      Biscoe\n      50.40\n      15.70\n      222.00\n      5750.00\n      Male\n    \n    \n      342\n      Gentoo\n      Biscoe\n      45.20\n      14.80\n      212.00\n      5200.00\n      Female\n    \n    \n      343\n      Gentoo\n      Biscoe\n      49.90\n      16.10\n      213.00\n      5400.00\n      Male\n    \n  \n\n344 rows × 7 columns\n\n\n\n\npenguins.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 344 entries, 0 to 343\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \ndtypes: float64(4), object(3)\nmemory usage: 18.9+ KB\n\n\n\npenguins.describe(include=\"object\")\n\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      sex\n    \n  \n  \n    \n      count\n      344\n      344\n      333\n    \n    \n      unique\n      3\n      3\n      2\n    \n    \n      top\n      Adelie\n      Biscoe\n      Male\n    \n    \n      freq\n      152\n      168\n      168\n    \n  \n\n\n\n\n\n\n\npenguins[[\"island\", \"species\"]].value_counts()\n\nisland     species  \nBiscoe     Gentoo       124\nDream      Chinstrap     68\n           Adelie        56\nTorgersen  Adelie        52\nBiscoe     Adelie        44\ndtype: int64\n\n\n\npenguins[[\"sex\", \"species\"]].value_counts(dropna=False) # NA은 기본적으로 생략\n\nsex     species  \nFemale  Adelie       73\nMale    Adelie       73\n        Gentoo       61\n                     ..\n        Chinstrap    34\nNaN     Adelie        6\n        Gentoo        5\nLength: 8, dtype: int64\n\n\n\npenguins.isna().sum() # NA의 개수\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\ndtype: int64\n\n\n\ns1 = tips[\"total_bill\"]\ns2 = tips[\"tip\"]\n\npd.DataFrame([s1, s2]).T.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n    \n    \n      1\n      10.34\n      1.66\n    \n    \n      2\n      21.01\n      3.50\n    \n    \n      3\n      23.68\n      3.31\n    \n    \n      4\n      24.59\n      3.61"
  },
  {
    "objectID": "contents/transform.html#missing",
    "href": "contents/transform.html#missing",
    "title": "Transforming",
    "section": "Missing",
    "text": "Missing"
  },
  {
    "objectID": "contents/transform.html#groupby-with-a-time-series",
    "href": "contents/transform.html#groupby-with-a-time-series",
    "title": "Transforming",
    "section": "groupby() with a time series",
    "text": "groupby() with a time series\n\nDescriptive and summary statistics\n\nsummary statistics by level, 251\n• unique(): Returns the distinct values of the column.\n• value_counts(): Returns a frequency table of the number of times each unique value in a given column appears, or, alternatively, the percentage of times each unique value appears when passed normalize=True.\n• mode(): Returns the most common value of the column.\nmap, mapapply, apply"
  },
  {
    "objectID": "contents/transform.html#transform",
    "href": "contents/transform.html#transform",
    "title": "Transforming",
    "section": "transform()",
    "text": "transform()"
  },
  {
    "objectID": "contents/transform.html#apply-general-split-apply-combine",
    "href": "contents/transform.html#apply-general-split-apply-combine",
    "title": "Transforming",
    "section": "10.3 Apply: General split-apply-combine",
    "text": "10.3 Apply: General split-apply-combine\nmap, mapapply, apply\n\nDescriptive and summary statistics\n\n• unique(): Returns the distinct values of the column.\n• value_counts(): Returns a frequency table of the number of times each unique value in a given column appears, or, alternatively, the percentage of times each unique value appears when passed normalize=True.\n• mode(): Returns the most common value of the column."
  },
  {
    "objectID": "contents/case1.html",
    "href": "contents/case1.html",
    "title": "Case study 1",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\n\nfrom IPython.display import display, HTML\nHTML('<style>.output {flex-direction: row;}</style>')"
  },
  {
    "objectID": "contents/case1.html#q1",
    "href": "contents/case1.html#q1",
    "title": "Case study 1",
    "section": "Q1",
    "text": "Q1\n각 도착지에 따른 비행거리와 도착지연시간과의 관계를 알아보고자 함.\n\nGroup flights by destination.\nSummarise to compute distance, average delay, and number of flights.\nFilter to remove noisy points and Honolulu airport, which is almost twice as far away as the next closest airport.\n\n\nflights = sm.datasets.get_rdataset(\"flights\", \"nycflights13\").data.drop(columns=\"time_hour\")\n\n\nby_dest = flights.groupby(\"dest\")\n\n\ndelay = by_dest[[\"distance\", \"arr_delay\"]].agg([\"count\", \"mean\"])\ndelay.head()\n\n     distance         arr_delay      \n        count    mean     count  mean\ndest                                 \nABQ       254 1826.00       254  4.38\nACK       265  199.00       264  4.85\nALB       439  143.00       418 14.40\nANC         8 3370.00         8 -2.50\nATL     17215  757.11     16837 11.30\n\n\n\ndelay.columns = ['_'.join(col_agg) for col_agg in delay.columns]\ndelay.drop(columns=\"arr_delay_count\", inplace=True)\ndelay.columns = [\"count\", \"dist\", \"delay\"]\ndelay = delay.reset_index()\n\n\ndelay.head()\n\n  dest  count    dist  delay\n0  ABQ    254 1826.00   4.38\n1  ACK    265  199.00   4.85\n2  ALB    439  143.00  14.40\n3  ANC      8 3370.00  -2.50\n4  ATL  17215  757.11  11.30\n\n\n\n(\n    so.Plot(delay, x=\"dist\", y=\"delay\")\n    .add(so.Dots(), pointsize=\"count\")\n    .add(so.Line(), so.PolyFit(5))\n    .scale(pointsize=(2, 20))\n)\n\n\n\n\n불필요한 자료를 제거하고 시각화하는 것이 유리\n\n# Filter to remove noisy points and Honolulu airport\ndelay_sub = delay.query('count > 20 & dest != \"HNL\"')\n(\n    so.Plot(delay_sub, x=\"dist\", y=\"delay\")\n    .add(so.Dots(), pointsize=\"count\")\n    .add(so.Line(), so.PolyFit(5))\n    .scale(pointsize=(2, 20))\n)\n\n\n\n\n\nidx = (delay[\"count\"] > 20) & (delay[\"dest\"] != \"HNL\")\ndelay[\"incl\"] = np.where(idx, \"out\", \"in\")\n\n\ndelay.head()\n\n  dest  count    dist  delay incl\n0  ABQ    254 1826.00   4.38  out\n1  ACK    265  199.00   4.85  out\n2  ALB    439  143.00  14.40  out\n3  ANC      8 3370.00  -2.50   in\n4  ATL  17215  757.11  11.30  out\n\n\n\n(\n    so.Plot(delay, x=\"dist\", y=\"delay\", color=\"incl\")\n    .add(so.Dots(), pointsize=\"count\")\n    .add(so.Line(), so.PolyFit(5))\n    .scale(pointsize=(2, 20))\n)"
  },
  {
    "objectID": "contents/case1.html#q2",
    "href": "contents/case1.html#q2",
    "title": "Case study 1",
    "section": "Q2",
    "text": "Q2\n항공기의 비행횟수와 연착시간의 관계를 살펴보고자 함.\n먼저, 평균적으로 가장 연착시간이 큰 항공기(tail number로 구분)를 살펴보고자 함.\n\nCount를 사용하여 샘플 수가 작은 케이스들 혹은 극단치들을 제거해서 살펴보기\n\nagg()와 같이 여러 값들을 aggregate할 시, “갯수”를 같이 살펴보는 것이 좋음 (count(), size())"
  },
  {
    "objectID": "contents/intro.html#getting-up",
    "href": "contents/intro.html#getting-up",
    "title": "데이터 분석 및 시각화",
    "section": "Getting up",
    "text": "Getting up\n\n알람 끄기222d2222\nGet out of bed"
  },
  {
    "objectID": "contents/intro.html#breakfast",
    "href": "contents/intro.html#breakfast",
    "title": "데이터 분석 및 시각화",
    "section": "Breakfast",
    "text": "Breakfast\n\nEat eggs\nDrink coffee"
  },
  {
    "objectID": "contents/intro.html#dinner",
    "href": "contents/intro.html#dinner",
    "title": "데이터 분석 및 시각화",
    "section": "Dinner",
    "text": "Dinner\n\n{.nonincremental}\n\nEat spaghetti\nDrink wine"
  },
  {
    "objectID": "contents/intro.html#going-to-sleep",
    "href": "contents/intro.html#going-to-sleep",
    "title": "데이터 분석 및 시각화",
    "section": "Going to sleep",
    "text": "Going to sleep\n\nGet in bed\nCount sheep"
  },
  {
    "objectID": "contents/intro.html#multiple-columns",
    "href": "contents/intro.html#multiple-columns",
    "title": "데이터 분석 및 시각화",
    "section": "Multiple Columns",
    "text": "Multiple Columns\n\n\ncontents…\n\ncontents…"
  },
  {
    "objectID": "contents/notice.html#중간고사-4.20",
    "href": "contents/notice.html#중간고사-4.20",
    "title": "Notice",
    "section": "중간고사 4.20",
    "text": "중간고사 4.20"
  },
  {
    "objectID": "contents/notice.html#기말고사-6.14",
    "href": "contents/notice.html#기말고사-6.14",
    "title": "Notice",
    "section": "기말고사 6.14",
    "text": "기말고사 6.14"
  },
  {
    "objectID": "contents/notice.html#개별-프로젝트",
    "href": "contents/notice.html#개별-프로젝트",
    "title": "Notice",
    "section": "개별 프로젝트",
    "text": "개별 프로젝트"
  },
  {
    "objectID": "index.html#강의-개요",
    "href": "index.html#강의-개요",
    "title": "Welcome",
    "section": "강의 개요",
    "text": "강의 개요\n본 강의에서는 인터넷과 기술의 발전으로 풍부한 데이터들이 양산됨에 따라 그 안에 숨겨진 패턴을 찾고 분석하여 실증적 사실과 원리를 파악하는데 요구되는 기술들을 계발하는데 도움을 주고자 합니다. 이를 위해서는 1) 데이터 분석 툴을 자유자재로 다룰 수 있는 기술, 2) 주어진 데이터에 적절한 툴을 선택할 수 있는 판단력, 3) 파악한 패턴으로부터 현상의 본질을 추론할 수 있는 인과관계 추론의 원리들이 함께 필요합니다.\n수업은 크게 3부분을 나뉨\n\n데이터 시각화와 탐색적 분석 (exploratory data analysis)\n통계적 모델링 (statistical modelling)\n기술적 분석 (descriptive analysis)\n\n\n교재\n\n번역서: Pandas를 이용한 데이터 분석 실습 2/e\nHands-On Data Analysis with Pandas (2e) by Stefanie Molin: code in GitHub\nPython for Data Analysis (3e) by Wes McKinney: code in GitHub\n2판 번역서: 파이썬 라이브러리를 활용한 데이터 분석\nR for Data Science by Wickham & Grolemund: 2nd edition in progress"
  },
  {
    "objectID": "index.html#수업-활동",
    "href": "index.html#수업-활동",
    "title": "Welcome",
    "section": "수업 활동",
    "text": "수업 활동\n출석 (5%), 일반과제 (25%), 중간고사 (20%), 기말고사 (20%), 개별 프로젝트 (30%)"
  },
  {
    "objectID": "contents/intro.html#python-vs.-r",
    "href": "contents/intro.html#python-vs.-r",
    "title": "데이터 분석 및 시각화",
    "section": "Python vs. R",
    "text": "Python vs. R\nR\n\n통계학자들의 커뮤니티에서 발전\n\n통계학의 정교한 이론이 잘 구현된 패키지들\n데이터 분석에 특화되어 있고, 간결한 코드로 분석의 흐름과 아이디어에 집중\n전통 통계학의 특성\n\n작은 샘플로부터 일반화하기 위한 노력\n하나의 데이터 포인터도 소중히…\n통계적 파워를 높이는데 포커스\n\n통계적 분석의 장점\n변수의 통제\n변수들 간의 상호작용\n메커니즘의 판별"
  },
  {
    "objectID": "contents/intro.html#미래-데이터의-중요성",
    "href": "contents/intro.html#미래-데이터의-중요성",
    "title": "데이터 분석 및 시각화",
    "section": "미래 데이터의 중요성",
    "text": "미래 데이터의 중요성\n4차 산업혁명의 ‘원유’: 머신러닝, AI\n\n다양한 소스들로부터 데이터 생성: 전지구적 개인과 환경에 대한 상세한 정보 발생\n인터넷 & 통신 (SNS, 사진, 위치, 장소, 유동인구, 상품거래)\n사물인터넷 (IoT), CCTV\n스마트 팩토리, 파밍\n게놈프로젝트, 생체정보: 인류, 실시간\n의료서비스, 보건\n자율주행차량: 내부, 외부\n금융정보 및 흐름\n사회 지표, 설문 조사: 고용, 물류, 직업, 연봉, 만족도 조사, 우울\n\n\n유토피아 vs. 디스토피아?\n\n초연결성, 투명성\n완전한 감시와 통제\n\n개인정보의 가치\n\n정보의 주권, 매매, 웹3(Web3)"
  },
  {
    "objectID": "contents/intro.html#data-science",
    "href": "contents/intro.html#data-science",
    "title": "데이터 분석 및 시각화",
    "section": "Data Science",
    "text": "Data Science\n\n\n소프트웨어 개발\n데이터에 기반한 분석 위해 작동하도록 프로그래밍을 하여 운영되도록 하는 일\n\n유튜브의 영상 추천\n페이스북의 친구 매칭\n스팸메일 필터링\n자율주행\n\n\n데이터 분석\nDNA 질병의 예측 및 진단을 포함한 healthcare\n상권의 분석 여러 정책의 결정에 필요한 분석"
  }
]